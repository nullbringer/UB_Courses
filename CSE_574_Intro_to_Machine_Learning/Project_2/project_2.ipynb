{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "image_specs_df = pd.read_csv(\"HumanObserved-Dataset/HumanObserved-Features-Data/HumanObserved-Features-Data.csv\", index_col=0)\n",
    "\n",
    "same_pair_df = pd.read_csv(\"HumanObserved-Dataset/HumanObserved-Features-Data/same_pairs.csv\")\n",
    "\n",
    "diff_pair_df = pd.read_csv(\"HumanObserved-Dataset/HumanObserved-Features-Data/diffn_pairs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1026, 10)\n",
      "(791, 3)\n",
      "(293032, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image_specs_df.shape)\n",
    "print(same_pair_df.shape)\n",
    "print(diff_pair_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAcc = 0.0\n",
    "maxIter = 0\n",
    "C_Lambda = 0.03\n",
    "TrainingPercent = 80\n",
    "ValidationPercent = 10\n",
    "TestPercent = 10\n",
    "M = 10\n",
    "PHI = []\n",
    "IsSynthetic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes dataset containing pairs and \n",
    "# returns a dataframe of n*21 dimention containing their image specifications \n",
    "# It performs feature concatination, i.e. It takes two sets of 9 features for each image\n",
    "# and concats them into 18 features\n",
    "\n",
    "def merge_data_set_feature_concatenation(image_specs, pair_set):\n",
    "    df3 = pd.merge(pair_set, image_specs ,left_on = \"img_id_A\", right_on = \"img_id\",how=\"inner\")\n",
    "    df4 = pd.merge(df3, image_specs ,left_on = 'img_id_B', right_on = 'img_id',how=\"inner\")\n",
    "    df4 = df4.drop(['img_id_x', 'img_id_y'], axis=1)\n",
    "    \n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id_A</th>\n",
       "      <th>img_id_B</th>\n",
       "      <th>target</th>\n",
       "      <th>f1_x</th>\n",
       "      <th>f2_x</th>\n",
       "      <th>f3_x</th>\n",
       "      <th>f4_x</th>\n",
       "      <th>f5_x</th>\n",
       "      <th>f6_x</th>\n",
       "      <th>f7_x</th>\n",
       "      <th>...</th>\n",
       "      <th>f9_x</th>\n",
       "      <th>f1_y</th>\n",
       "      <th>f2_y</th>\n",
       "      <th>f3_y</th>\n",
       "      <th>f4_y</th>\n",
       "      <th>f5_y</th>\n",
       "      <th>f6_y</th>\n",
       "      <th>f7_y</th>\n",
       "      <th>f8_y</th>\n",
       "      <th>f9_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0359a</td>\n",
       "      <td>0359b</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0577a</td>\n",
       "      <td>0577b</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0577a</td>\n",
       "      <td>0577c</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0577b</td>\n",
       "      <td>0577c</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1120a</td>\n",
       "      <td>1120b</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  img_id_A img_id_B  target  f1_x  f2_x  f3_x  f4_x  f5_x  f6_x  f7_x  ...   \\\n",
       "0    0359a    0359b       1     2     1     1     0     2     2     0  ...    \n",
       "1    0577a    0577b       1     2     1     1     0     2     2     0  ...    \n",
       "2    0577a    0577c       1     2     1     1     0     2     2     0  ...    \n",
       "3    0577b    0577c       1     2     1     0     3     2     2     1  ...    \n",
       "4    1120a    1120b       1     2     1     1     3     2     2     0  ...    \n",
       "\n",
       "   f9_x  f1_y  f2_y  f3_y  f4_y  f5_y  f6_y  f7_y  f8_y  f9_y  \n",
       "0     2     3     2     1     0     2     2     3     0     2  \n",
       "1     2     2     1     0     3     2     2     1     2     2  \n",
       "2     2     1     1     1     1     2     3     0     0     2  \n",
       "3     2     1     1     1     1     2     3     0     0     2  \n",
       "4     2     1     1     1     0     2     2     0     2     2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe using the image specifications from same writers (matched pairs, 791 rows)\n",
    "\n",
    "matched_dataset = merge_data_set_feature_concatenation(image_specs_df, same_pair_df)\n",
    "print(matched_dataset.shape)\n",
    "matched_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id_A</th>\n",
       "      <th>img_id_B</th>\n",
       "      <th>target</th>\n",
       "      <th>f1_x</th>\n",
       "      <th>f2_x</th>\n",
       "      <th>f3_x</th>\n",
       "      <th>f4_x</th>\n",
       "      <th>f5_x</th>\n",
       "      <th>f6_x</th>\n",
       "      <th>f7_x</th>\n",
       "      <th>...</th>\n",
       "      <th>f9_x</th>\n",
       "      <th>f1_y</th>\n",
       "      <th>f2_y</th>\n",
       "      <th>f3_y</th>\n",
       "      <th>f4_y</th>\n",
       "      <th>f5_y</th>\n",
       "      <th>f6_y</th>\n",
       "      <th>f7_y</th>\n",
       "      <th>f8_y</th>\n",
       "      <th>f9_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0546b</td>\n",
       "      <td>0348c</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0950a</td>\n",
       "      <td>0348c</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1144c</td>\n",
       "      <td>0348c</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1286a</td>\n",
       "      <td>0324c</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0477a</td>\n",
       "      <td>1227b</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  img_id_A img_id_B  target  f1_x  f2_x  f3_x  f4_x  f5_x  f6_x  f7_x  ...   \\\n",
       "0    0546b    0348c       0     3     1     1     3     1     3     0  ...    \n",
       "1    0950a    0348c       0     2     1     1     3     0     2     2  ...    \n",
       "2    1144c    0348c       0     1     1     1     2     2     1     0  ...    \n",
       "3    1286a    0324c       0     1     2     1     3     2     1     1  ...    \n",
       "4    0477a    1227b       0     2     1     1     1     2     1     0  ...    \n",
       "\n",
       "   f9_x  f1_y  f2_y  f3_y  f4_y  f5_y  f6_y  f7_y  f8_y  f9_y  \n",
       "0     2     3     1     0     2     2     2     3     3     2  \n",
       "1     1     3     1     0     2     2     2     3     3     2  \n",
       "2     2     3     1     0     2     2     2     3     3     2  \n",
       "3     2     1     1     0     4     2     2     0     3     2  \n",
       "4     2     3     1     1     3     2     1     0     4     2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe using the image specifications from different writers (unmatched pairs)\n",
    "# Since unmatched dataset is huge we are randomly creating a sample with same data size (791 rows)\n",
    "# because if the amount of unmatched data overwhelms the matched data, the model may overfit\n",
    "\n",
    "chosen_idx = np.random.choice(diff_pair_df.shape[0]-1, replace=False, size = matched_dataset.shape[0])\n",
    "diff_pair_df_sample = diff_pair_df.iloc[chosen_idx]\n",
    "unmatched_dataset = merge_data_set_feature_concatenation(image_specs_df, diff_pair_df_sample)\n",
    "print(unmatched_dataset.shape)\n",
    "unmatched_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id_A</th>\n",
       "      <th>img_id_B</th>\n",
       "      <th>target</th>\n",
       "      <th>f1_x</th>\n",
       "      <th>f2_x</th>\n",
       "      <th>f3_x</th>\n",
       "      <th>f4_x</th>\n",
       "      <th>f5_x</th>\n",
       "      <th>f6_x</th>\n",
       "      <th>f7_x</th>\n",
       "      <th>...</th>\n",
       "      <th>f9_x</th>\n",
       "      <th>f1_y</th>\n",
       "      <th>f2_y</th>\n",
       "      <th>f3_y</th>\n",
       "      <th>f4_y</th>\n",
       "      <th>f5_y</th>\n",
       "      <th>f6_y</th>\n",
       "      <th>f7_y</th>\n",
       "      <th>f8_y</th>\n",
       "      <th>f9_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1567c</td>\n",
       "      <td>1567b</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1375a</td>\n",
       "      <td>0321b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1540b</td>\n",
       "      <td>1540c</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0456b</td>\n",
       "      <td>0336c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305a</td>\n",
       "      <td>1370c</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  img_id_A img_id_B  target  f1_x  f2_x  f3_x  f4_x  f5_x  f6_x  f7_x  ...   \\\n",
       "0    1567c    1567b       1     2     4     1     4     2     2     0  ...    \n",
       "1    1375a    0321b       0     1     0     1     1     2     2     0  ...    \n",
       "2    1540b    1540c       1     1     1     1     0     2     2     1  ...    \n",
       "3    0456b    0336c       0     0     1     1     1     2     2     0  ...    \n",
       "4    1305a    1370c       0     1     1     1     0     2     2     0  ...    \n",
       "\n",
       "   f9_x  f1_y  f2_y  f3_y  f4_y  f5_y  f6_y  f7_y  f8_y  f9_y  \n",
       "0     2     3     1     0     2     2     2     0     0     2  \n",
       "1     2     3     2     1     3     2     2     1     4     2  \n",
       "2     2     1     2     1     0     2     2     1     0     1  \n",
       "3     1     3     2     1     2     2     2     0     1     1  \n",
       "4     2     3     1     1     1     2     2     1     1     2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two dataset into one dataset containing 1582 entries and randomizing the order\n",
    "\n",
    "dataset = pd.concat([unmatched_dataset,matched_dataset])\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_target_vector(dset):\n",
    "#     targets = dset['target']\n",
    "#     dset = dset.drop(['img_id_A', 'img_id_B', 'target'], axis=1)\n",
    "#     return dset, targets\n",
    "\n",
    "# def generate_unseen_dataset(dataset):\n",
    "#     unique_imgs = np.union1d(dataset.img_id_A.unique(), dataset.img_id_B.unique())\n",
    "#     no_of_unique_imgs = unique_imgs.shape[0]\n",
    "\n",
    "#     training_range_index = int(no_of_unique_imgs*0.7)\n",
    "#     unseen_trainig_dataset = dataset[dataset.img_id_A.isin(unique_imgs[:training_range_index]) | dataset.img_id_B.isin(unique_imgs[:training_range_index])]\n",
    "#     unseen_trainig_dataset, unseen_training_dataset_targets = extract_target_vector(unseen_trainig_dataset)\n",
    "     \n",
    "\n",
    "#     rest_dataset = dataset[~dataset.isin(unseen_trainig_dataset)].dropna()\n",
    "\n",
    "\n",
    "#     testing_range_index = int(no_of_unique_imgs*0.85)\n",
    "#     unseen_testing_dataset = rest_dataset[rest_dataset.img_id_A.isin(unique_imgs[training_range_index:testing_range_index]) | rest_dataset.img_id_B.isin(unique_imgs[training_range_index:testing_range_index])]\n",
    "#     unseen_testing_dataset, unseen_testing_dataset_targets = extract_target_vector(unseen_testing_dataset)\n",
    "    \n",
    "    \n",
    "#     unseen_validation_dataset = rest_dataset[~rest_dataset.isin(unseen_testing_dataset)].dropna()\n",
    "#     unseen_validation_dataset, unseen_validation_dataset_targets = extract_target_vector(unseen_validation_dataset)\n",
    "\n",
    "\n",
    "#     print(\"total entires: \", dataset.shape[0])\n",
    "#     print(\"training entires (Unseen): \", unseen_trainig_dataset.shape[0])\n",
    "#     print(\"testing entires (Unseen): \", unseen_testing_dataset.shape[0])\n",
    "#     print(\"validation entires (Unseen): \", unseen_validation_dataset.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#generate_unseen_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTrainingTarget(rawTraining,TrainingPercent = 80):\n",
    "    TrainingLen = int(math.ceil(len(rawTraining)*(TrainingPercent*0.01)))\n",
    "    t           = rawTraining[:TrainingLen]\n",
    "    #print(str(TrainingPercent) + \"% Training Target Generated..\")\n",
    "    return t\n",
    "\n",
    "def GenerateTrainingDataMatrix(rawData, TrainingPercent = 80):\n",
    "    T_len = int(math.ceil(len(rawData[0])*0.01*TrainingPercent))\n",
    "    d2 = rawData[:,0:T_len]\n",
    "    #print(str(TrainingPercent) + \"% Training Data Generated..\")\n",
    "    return d2\n",
    "\n",
    "def GenerateValData(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData[0])*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    dataMatrix = rawData[:,TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Data Generated..\")  \n",
    "    return dataMatrix\n",
    "\n",
    "def GenerateValTargetVector(rawData, ValPercent, TrainingCount): \n",
    "    valSize = int(math.ceil(len(rawData)*ValPercent*0.01))\n",
    "    V_End = TrainingCount + valSize\n",
    "    t =rawData[TrainingCount+1:V_End]\n",
    "    #print (str(ValPercent) + \"% Val Target Data Generated..\")\n",
    "    return t\n",
    "\n",
    "def GenerateBigSigma(Data, MuMatrix,TrainingPercent,IsSynthetic):\n",
    "    # 1582 x 18, M x 18, \n",
    "    BigSigma    = np.zeros((len(Data),len(Data)))\n",
    "    DataT       = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))        \n",
    "    varVect     = []\n",
    "    for i in range(0,len(DataT[0])):\n",
    "        # 0 to 18\n",
    "        vct = []\n",
    "        for j in range(0,int(TrainingLen)):\n",
    "            #0 to 1200\n",
    "            vct.append(Data[i][j])    \n",
    "        varVect.append(np.var(vct))\n",
    "    \n",
    "    for j in range(len(Data)):\n",
    "        BigSigma[j][j] = varVect[j]\n",
    "    if IsSynthetic == True:\n",
    "        BigSigma = np.dot(3,BigSigma)\n",
    "    else:\n",
    "        BigSigma = np.dot(200,BigSigma)\n",
    "    ##print (\"BigSigma Generated..\")\n",
    "    return BigSigma\n",
    "\n",
    "def GetScalar(DataRow,MuRow, BigSigInv):  \n",
    "    R = np.subtract(DataRow,MuRow)\n",
    "    T = np.dot(BigSigInv,np.transpose(R))  \n",
    "    L = np.dot(R,T)\n",
    "    return L\n",
    "\n",
    "def GetRadialBasisOut(DataRow,MuRow, BigSigInv):    \n",
    "    phi_x = math.exp(-0.5*GetScalar(DataRow,MuRow,BigSigInv))\n",
    "    return phi_x\n",
    "\n",
    "def GetPhiMatrix(Data, MuMatrix, BigSigma, TrainingPercent = 80):\n",
    "    DataT = np.transpose(Data)\n",
    "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))         \n",
    "    PHI = np.zeros((int(TrainingLen),len(MuMatrix))) \n",
    "    BigSigInv = np.linalg.inv(BigSigma)\n",
    "    for  C in range(0,len(MuMatrix)):\n",
    "        for R in range(0,int(TrainingLen)):\n",
    "            PHI[R][C] = GetRadialBasisOut(DataT[R], MuMatrix[C], BigSigInv)\n",
    "    #print (\"PHI Generated..\")\n",
    "    return PHI\n",
    "\n",
    "def GetValTest(VAL_PHI,W):\n",
    "    Y = np.dot(W,np.transpose(VAL_PHI))\n",
    "    ##print (\"Test Out Generated..\")\n",
    "    return Y\n",
    "\n",
    "def GetErms(VAL_TEST_OUT,ValDataAct):\n",
    "    sum = 0.0\n",
    "    t=0\n",
    "    accuracy = 0.0\n",
    "    counter = 0\n",
    "    val = 0.0\n",
    "    for i in range (0,len(VAL_TEST_OUT)):\n",
    "        sum = sum + math.pow((ValDataAct[i] - VAL_TEST_OUT[i]),2)\n",
    "        if(int(np.around(VAL_TEST_OUT[i], 0)) == ValDataAct[i]):\n",
    "            counter+=1\n",
    "    accuracy = (float((counter*100))/float(len(VAL_TEST_OUT)))\n",
    "    ##print (\"Accuracy Generated..\")\n",
    "    ##print (\"Validation E_RMS : \" + str(math.sqrt(sum/len(VAL_TEST_OUT))))\n",
    "    return (str(accuracy) + ',' +  str(math.sqrt(sum/len(VAL_TEST_OUT))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266,)\n",
      "(18, 1266)\n",
      "(158,)\n",
      "(18, 158)\n",
      "(157,)\n",
      "(18, 157)\n"
     ]
    }
   ],
   "source": [
    "targets = dataset['target']\n",
    "\n",
    "RawTarget = targets.values\n",
    "datasetStriped = dataset.drop(['img_id_A', 'img_id_B', 'target'], axis=1)\n",
    "RawData = np.transpose(datasetStriped.values)\n",
    "\n",
    "TrainingTarget = GenerateTrainingTarget(RawTarget,TrainingPercent)\n",
    "TrainingData   = GenerateTrainingDataMatrix(RawData,TrainingPercent)\n",
    "print(TrainingTarget.shape)\n",
    "print(TrainingData.shape)\n",
    "\n",
    "ValDataAct = GenerateValTargetVector(RawTarget,ValidationPercent, (len(TrainingTarget)))\n",
    "ValData    = GenerateValData(RawData,ValidationPercent, (len(TrainingTarget)))\n",
    "print(ValDataAct.shape)\n",
    "print(ValData.shape)\n",
    "\n",
    "TestDataAct = GenerateValTargetVector(RawTarget,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "TestData = GenerateValData(RawData,TestPercent, (len(TrainingTarget)+len(ValDataAct)))\n",
    "print(TestDataAct.shape)\n",
    "print(TestData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 18)\n",
      "(1266, 10)\n",
      "(157, 10)\n",
      "(158, 10)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=M, random_state=0).fit(np.transpose(TrainingData))\n",
    "Mu = kmeans.cluster_centers_\n",
    "\n",
    "BigSigma     = GenerateBigSigma(RawData, Mu, TrainingPercent,IsSynthetic)\n",
    "TRAINING_PHI = GetPhiMatrix(RawData, Mu, BigSigma, TrainingPercent)\n",
    "# W            = GetWeightsClosedForm(TRAINING_PHI,TrainingTarget,(C_Lambda)) \n",
    "TEST_PHI     = GetPhiMatrix(TestData, Mu, BigSigma, 100) \n",
    "VAL_PHI      = GetPhiMatrix(ValData, Mu, BigSigma, 100)\n",
    "\n",
    "print(BigSigma.shape)\n",
    "print(TRAINING_PHI.shape)\n",
    "print(TEST_PHI.shape)\n",
    "print(VAL_PHI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_range = TrainingTarget.shape[0]\n",
    "\n",
    "W_Now        = np.ones(M)\n",
    "\n",
    "La           = 2\n",
    "learningRate = 0.01\n",
    "L_Erms_Val   = []\n",
    "L_Erms_TR    = []\n",
    "L_Erms_Test  = []\n",
    "W_Mat        = []\n",
    "\n",
    "\n",
    "# We are going to ananlyze only a small number of data, as the weights \n",
    "# are already close to optimized, and there are not much room for improvement, \n",
    "# so analying whole training set is redundant.\n",
    "for i in range(0,loop_range):\n",
    "    \n",
    "    # We are implementing Stochastic\n",
    "    \n",
    "    # here we are calculating the weight changes we have to get a more optimized solution\n",
    "    # for that we have to calculate the error changes first and combining with learning rate\n",
    "    # we decide what will be the new weights for next iteration.\n",
    "    \n",
    "    Delta_E_D     = -np.dot((TrainingTarget[i] - np.dot(np.transpose(W_Now),TRAINING_PHI[i])),TRAINING_PHI[i])\n",
    "    La_Delta_E_W  = np.dot(La,W_Now)\n",
    "    Delta_E       = np.add(Delta_E_D,La_Delta_E_W)    \n",
    "    Delta_W       = -np.dot(learningRate,Delta_E)\n",
    "    W_T_Next      = W_Now + Delta_W\n",
    "    W_Now         = W_T_Next\n",
    "    \n",
    "    \n",
    "    \n",
    "    #-----------------TrainingData Accuracy---------------------#\n",
    "    TR_TEST_OUT   = GetValTest(TRAINING_PHI,W_T_Next) \n",
    "    Erms_TR       = GetErms(TR_TEST_OUT,TrainingTarget)\n",
    "    L_Erms_TR.append(float(Erms_TR.split(',')[1]))\n",
    "    \n",
    "    #-----------------ValidationData Accuracy---------------------#\n",
    "    VAL_TEST_OUT  = GetValTest(VAL_PHI,W_T_Next) \n",
    "    Erms_Val      = GetErms(VAL_TEST_OUT,ValDataAct)\n",
    "    L_Erms_Val.append(float(Erms_Val.split(',')[1]))\n",
    "    \n",
    "    #-----------------TestingData Accuracy---------------------#\n",
    "    TEST_OUT      = GetValTest(TEST_PHI,W_T_Next) \n",
    "    Erms_Test = GetErms(TEST_OUT,TestDataAct)\n",
    "    L_Erms_Test.append(float(Erms_Test.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Gradient Descent Solution--------------------\n",
      "M = 15 \n",
      "Lambda  = 0.0001\n",
      "eta=0.01\n",
      "E_rms Training   = 0.49967\n",
      "E_rms Validation = 0.49892\n",
      "E_rms Testing    = 0.49789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4989191152741441"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('----------Gradient Descent Solution--------------------')\n",
    "print (\"M = 15 \\nLambda  = 0.0001\\neta=0.01\")\n",
    "print (\"E_rms Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "print (\"E_rms Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "print (\"E_rms Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "min(L_Erms_Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
