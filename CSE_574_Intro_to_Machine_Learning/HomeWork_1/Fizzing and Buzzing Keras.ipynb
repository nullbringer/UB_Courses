{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Based FizzBuzz Function [Software 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fizzbuzz(n):\n",
    "    \n",
    "    # Logic Explanation\n",
    "    if n % 3 == 0 and n % 5 == 0:\n",
    "        return 'FizzBuzz'\n",
    "    elif n % 3 == 0:\n",
    "        return 'Fizz'\n",
    "    elif n % 5 == 0:\n",
    "        return 'Buzz'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Testing Datasets in CSV Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInputCSV(start,end,filename):\n",
    "    \n",
    "    # Why list in Python?\n",
    "    # We have a number of data entries which must be fed to machine for training the model so that it can predict\n",
    "    # unseen data as correctly as possible. To hold muliple data entries we are using list.\n",
    "    inputData   = []\n",
    "    outputData  = []\n",
    "    \n",
    "    # Why do we need training Data?\n",
    "    # Just like human, machine must be fed enough data to formulate an understanding. In case of human child, only\n",
    "    # after seeing a fruit multiple times, they can recognize the fruit. Same is true for a machine, a model must be\n",
    "    # supplied multiple data points(i.e. pictures of fruit) to draw conclusion. This is what we call training.\n",
    "    \n",
    "    for i in range(start,end):\n",
    "        inputData.append(i)\n",
    "        outputData.append(fizzbuzz(i))\n",
    "    \n",
    "    # Why Dataframe?\n",
    "    # Pandas Dataframe is a n-dimentional datastructure, an in-memory data storage tool. \n",
    "    # This allows user to do rapid calculations over large amounts of data very quickly.\n",
    "    # Below example demonstrated an important feature in pandas, that all the data columns are labeled. So we do not\n",
    "    # need to access them by index. This is important, when the data set and dimention is large.\n",
    "    \n",
    "    dataset = {}\n",
    "    dataset[\"input\"]  = inputData\n",
    "    dataset[\"label\"] = outputData\n",
    "    \n",
    "    # Writing to csv\n",
    "    pd.DataFrame(dataset).to_csv(filename)\n",
    "    \n",
    "    print(filename, \"Created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Input and Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(dataset):\n",
    "    \n",
    "    # Why do we have to process?\n",
    "    data   = dataset['input'].values\n",
    "    labels = dataset['label'].values\n",
    "    \n",
    "    processedData  = encodeData(data)\n",
    "    processedLabel = encodeLabel(labels)\n",
    "    \n",
    "    return processedData, processedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeData(data):\n",
    "    \n",
    "    processedData = []\n",
    "    \n",
    "    for dataInstance in data:\n",
    "        \n",
    "        # Why do we have number 10?\n",
    "        processedData.append([dataInstance >> d & 1 for d in range(10)])\n",
    "    \n",
    "    return np.array(processedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "def encodeLabel(labels):\n",
    "    \n",
    "    processedLabel = []\n",
    "    \n",
    "    for labelInstance in labels:\n",
    "        if(labelInstance == \"FizzBuzz\"):\n",
    "            # Fizzbuzz\n",
    "            processedLabel.append([3])\n",
    "        elif(labelInstance == \"Fizz\"):\n",
    "            # Fizz\n",
    "            processedLabel.append([1])\n",
    "        elif(labelInstance == \"Buzz\"):\n",
    "            # Buzz\n",
    "            processedLabel.append([2])\n",
    "        else:\n",
    "            # Other\n",
    "            processedLabel.append([0])\n",
    "\n",
    "    return np_utils.to_categorical(np.array(processedLabel),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_size = 10\n",
    "drop_out = 0.2\n",
    "first_dense_layer_nodes  = 256\n",
    "second_dense_layer_nodes = 4\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    # Why do we need a model?\n",
    "    # -> In abstruct sense, a model tries to imitate human nervous system. It tries to emulate the way human\n",
    "    # understand it's surrounding. It takes information given to it, processes it, tries to add layers of\n",
    "    # understanding with time and come up with more accurate prediction system.\n",
    "    \n",
    "    # Why use Dense layer and then activation?\n",
    "    # -> A dense layer is just a regular layer of neurons in a neural network. \n",
    "    # Each neuron recieves input from all the neurons in the previous layer, thus densely connected.\n",
    "    # -> Activation is used to add non-linearity in the neural network. If we do not add activation after every\n",
    "    # dense layer, then multiple dense practically becomes one single layer of complex linear function.\n",
    "    \n",
    "    # Why use sequential model with layers?\n",
    "    # -> The sequential API allows users to create models layer-by-layer for most problems. It is limited in that,\n",
    "    # it does not allow us create models that share layers or have multiple inputs or outputs. In this model, one\n",
    "    # layer uses the previous layer's output as input and it's output feeds next layer only. This is great model for\n",
    "    # comparatively less complex problems.\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Why dropout?\n",
    "    # -> Dropout is a regularization technique, which aims to reduce the complexity of the model with the goal to \n",
    "    # prevent overfitting. The key idea is to randomly drop units (along with their connections) from the neural \n",
    "    # network during training. This prevents units from co-adapting too much. Another side effect is that \n",
    "    # training will be faster.\n",
    "\n",
    "        \n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Why Softmax?\n",
    "    # -> Softmax activation is basically the normalized exponential probability of class observations \n",
    "    # represented as neuron activations. The softmax function is often used in the final layer of a neural \n",
    "    # network-based classifier. It is uded because of the ease of differentiation and being in the range 0-1. \n",
    "    # The output of the function is also between 0 and 1 and therefore naturally a suitable choice for \n",
    "    # representing probability\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # Why use categorical_crossentropy?\n",
    "    # -> Since the problem we are solving is a multi-classification problem (i.e. 4 expected output classes) we have\n",
    "    # to use categorical_crossentropy as the loss function. \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Creating Training and Testing Datafiles</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.csv Created!\n",
      "testing.csv Created!\n"
     ]
    }
   ],
   "source": [
    "# Create datafiles\n",
    "createInputCSV(101,1001,'training.csv')\n",
    "createInputCSV(1,101,'testing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Creating Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,844\n",
      "Trainable params: 3,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue>Run Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 675 samples, validate on 225 samples\n",
      "Epoch 1/10000\n",
      "675/675 [==============================] - 0s 559us/step - loss: 1.3244 - acc: 0.4000 - val_loss: 1.1716 - val_acc: 0.5333\n",
      "Epoch 2/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 1.1855 - acc: 0.5304 - val_loss: 1.1482 - val_acc: 0.5333\n",
      "Epoch 3/10000\n",
      "675/675 [==============================] - 0s 127us/step - loss: 1.1641 - acc: 0.5333 - val_loss: 1.1489 - val_acc: 0.5333\n",
      "Epoch 4/10000\n",
      "675/675 [==============================] - 0s 113us/step - loss: 1.1494 - acc: 0.5348 - val_loss: 1.1488 - val_acc: 0.5333\n",
      "Epoch 5/10000\n",
      "675/675 [==============================] - 0s 114us/step - loss: 1.1464 - acc: 0.5333 - val_loss: 1.1560 - val_acc: 0.5333\n",
      "Epoch 6/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 1.1508 - acc: 0.5333 - val_loss: 1.1601 - val_acc: 0.5333\n",
      "Epoch 7/10000\n",
      "675/675 [==============================] - 0s 132us/step - loss: 1.1502 - acc: 0.5333 - val_loss: 1.1589 - val_acc: 0.5333\n",
      "Epoch 8/10000\n",
      "675/675 [==============================] - 0s 109us/step - loss: 1.1451 - acc: 0.5333 - val_loss: 1.1567 - val_acc: 0.5333\n",
      "Epoch 9/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 1.1493 - acc: 0.5333 - val_loss: 1.1530 - val_acc: 0.5333\n",
      "Epoch 10/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 1.1439 - acc: 0.5333 - val_loss: 1.1481 - val_acc: 0.5333\n",
      "Epoch 11/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 1.1414 - acc: 0.5333 - val_loss: 1.1532 - val_acc: 0.5333\n",
      "Epoch 12/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 1.1427 - acc: 0.5333 - val_loss: 1.1494 - val_acc: 0.5333\n",
      "Epoch 13/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 1.1397 - acc: 0.5333 - val_loss: 1.1582 - val_acc: 0.5333\n",
      "Epoch 14/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 1.1385 - acc: 0.5333 - val_loss: 1.1513 - val_acc: 0.5333\n",
      "Epoch 15/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 1.1330 - acc: 0.5333 - val_loss: 1.1506 - val_acc: 0.5333\n",
      "Epoch 16/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 1.1329 - acc: 0.5333 - val_loss: 1.1525 - val_acc: 0.5333\n",
      "Epoch 17/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 1.1340 - acc: 0.5333 - val_loss: 1.1506 - val_acc: 0.5333\n",
      "Epoch 18/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 1.1371 - acc: 0.5333 - val_loss: 1.1595 - val_acc: 0.5333\n",
      "Epoch 19/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 1.1395 - acc: 0.5333 - val_loss: 1.1573 - val_acc: 0.5333\n",
      "Epoch 20/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 1.1310 - acc: 0.5333 - val_loss: 1.1523 - val_acc: 0.5333\n",
      "Epoch 21/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 1.1355 - acc: 0.5333 - val_loss: 1.1504 - val_acc: 0.5333\n",
      "Epoch 22/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 1.1308 - acc: 0.5333 - val_loss: 1.1466 - val_acc: 0.5333\n",
      "Epoch 23/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 1.1320 - acc: 0.5333 - val_loss: 1.1468 - val_acc: 0.5333\n",
      "Epoch 24/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 1.1347 - acc: 0.5333 - val_loss: 1.1463 - val_acc: 0.5333\n",
      "Epoch 25/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 1.1257 - acc: 0.5333 - val_loss: 1.1530 - val_acc: 0.5333\n",
      "Epoch 26/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 1.1277 - acc: 0.5333 - val_loss: 1.1476 - val_acc: 0.5333\n",
      "Epoch 27/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 1.1259 - acc: 0.5333 - val_loss: 1.1494 - val_acc: 0.5333\n",
      "Epoch 28/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 1.1222 - acc: 0.5333 - val_loss: 1.1489 - val_acc: 0.5333\n",
      "Epoch 29/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 1.1224 - acc: 0.5333 - val_loss: 1.1460 - val_acc: 0.5333\n",
      "Epoch 30/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 1.1193 - acc: 0.5333 - val_loss: 1.1448 - val_acc: 0.5333\n",
      "Epoch 31/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 1.1186 - acc: 0.5333 - val_loss: 1.1458 - val_acc: 0.5333\n",
      "Epoch 32/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 1.1168 - acc: 0.5333 - val_loss: 1.1466 - val_acc: 0.5333\n",
      "Epoch 33/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 1.1231 - acc: 0.5333 - val_loss: 1.1456 - val_acc: 0.5333\n",
      "Epoch 34/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 1.1098 - acc: 0.5333 - val_loss: 1.1524 - val_acc: 0.5333\n",
      "Epoch 35/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 1.1230 - acc: 0.5333 - val_loss: 1.1471 - val_acc: 0.5333\n",
      "Epoch 36/10000\n",
      "675/675 [==============================] - 0s 125us/step - loss: 1.1140 - acc: 0.5333 - val_loss: 1.1456 - val_acc: 0.5333\n",
      "Epoch 37/10000\n",
      "675/675 [==============================] - 0s 134us/step - loss: 1.1090 - acc: 0.5333 - val_loss: 1.1468 - val_acc: 0.5333\n",
      "Epoch 38/10000\n",
      "675/675 [==============================] - 0s 131us/step - loss: 1.1117 - acc: 0.5333 - val_loss: 1.1453 - val_acc: 0.5333\n",
      "Epoch 39/10000\n",
      "675/675 [==============================] - 0s 132us/step - loss: 1.1123 - acc: 0.5333 - val_loss: 1.1478 - val_acc: 0.5333\n",
      "Epoch 40/10000\n",
      "675/675 [==============================] - 0s 133us/step - loss: 1.1073 - acc: 0.5333 - val_loss: 1.1475 - val_acc: 0.5333\n",
      "Epoch 41/10000\n",
      "675/675 [==============================] - 0s 140us/step - loss: 1.1094 - acc: 0.5333 - val_loss: 1.1436 - val_acc: 0.5333\n",
      "Epoch 42/10000\n",
      "675/675 [==============================] - 0s 135us/step - loss: 1.1083 - acc: 0.5348 - val_loss: 1.1461 - val_acc: 0.5333\n",
      "Epoch 43/10000\n",
      "675/675 [==============================] - 0s 139us/step - loss: 1.1055 - acc: 0.5333 - val_loss: 1.1468 - val_acc: 0.5333\n",
      "Epoch 44/10000\n",
      "675/675 [==============================] - 0s 158us/step - loss: 1.1010 - acc: 0.5333 - val_loss: 1.1495 - val_acc: 0.5333\n",
      "Epoch 45/10000\n",
      "675/675 [==============================] - 0s 124us/step - loss: 1.1047 - acc: 0.5333 - val_loss: 1.1478 - val_acc: 0.5333\n",
      "Epoch 46/10000\n",
      "675/675 [==============================] - 0s 139us/step - loss: 1.1012 - acc: 0.5333 - val_loss: 1.1428 - val_acc: 0.5333\n",
      "Epoch 47/10000\n",
      "675/675 [==============================] - 0s 129us/step - loss: 1.1002 - acc: 0.5333 - val_loss: 1.1414 - val_acc: 0.5333\n",
      "Epoch 48/10000\n",
      "675/675 [==============================] - 0s 128us/step - loss: 1.0947 - acc: 0.5304 - val_loss: 1.1424 - val_acc: 0.5333\n",
      "Epoch 49/10000\n",
      "675/675 [==============================] - 0s 141us/step - loss: 1.1002 - acc: 0.5333 - val_loss: 1.1432 - val_acc: 0.5333\n",
      "Epoch 50/10000\n",
      "675/675 [==============================] - 0s 128us/step - loss: 1.0914 - acc: 0.5319 - val_loss: 1.1434 - val_acc: 0.5333\n",
      "Epoch 51/10000\n",
      "675/675 [==============================] - 0s 122us/step - loss: 1.0854 - acc: 0.5319 - val_loss: 1.1421 - val_acc: 0.5333\n",
      "Epoch 52/10000\n",
      "675/675 [==============================] - 0s 133us/step - loss: 1.0927 - acc: 0.5333 - val_loss: 1.1420 - val_acc: 0.5333\n",
      "Epoch 53/10000\n",
      "675/675 [==============================] - 0s 128us/step - loss: 1.0905 - acc: 0.5333 - val_loss: 1.1405 - val_acc: 0.5333\n",
      "Epoch 54/10000\n",
      "675/675 [==============================] - 0s 125us/step - loss: 1.0877 - acc: 0.5348 - val_loss: 1.1390 - val_acc: 0.5333\n",
      "Epoch 55/10000\n",
      "675/675 [==============================] - 0s 107us/step - loss: 1.0825 - acc: 0.5333 - val_loss: 1.1380 - val_acc: 0.5333\n",
      "Epoch 56/10000\n",
      "675/675 [==============================] - 0s 114us/step - loss: 1.0875 - acc: 0.5333 - val_loss: 1.1382 - val_acc: 0.5333\n",
      "Epoch 57/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 1.0845 - acc: 0.5348 - val_loss: 1.1363 - val_acc: 0.5333\n",
      "Epoch 58/10000\n",
      "675/675 [==============================] - 0s 114us/step - loss: 1.0774 - acc: 0.5348 - val_loss: 1.1371 - val_acc: 0.5333\n",
      "Epoch 59/10000\n",
      "675/675 [==============================] - 0s 118us/step - loss: 1.0704 - acc: 0.5378 - val_loss: 1.1392 - val_acc: 0.5333\n",
      "Epoch 60/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 105us/step - loss: 1.0717 - acc: 0.5363 - val_loss: 1.1359 - val_acc: 0.5333\n",
      "Epoch 61/10000\n",
      "675/675 [==============================] - 0s 126us/step - loss: 1.0724 - acc: 0.5363 - val_loss: 1.1393 - val_acc: 0.5333\n",
      "Epoch 62/10000\n",
      "675/675 [==============================] - 0s 133us/step - loss: 1.0765 - acc: 0.5363 - val_loss: 1.1341 - val_acc: 0.5333\n",
      "Epoch 63/10000\n",
      "675/675 [==============================] - 0s 151us/step - loss: 1.0711 - acc: 0.5363 - val_loss: 1.1351 - val_acc: 0.5333\n",
      "Epoch 64/10000\n",
      "675/675 [==============================] - 0s 141us/step - loss: 1.0739 - acc: 0.5378 - val_loss: 1.1342 - val_acc: 0.5333\n",
      "Epoch 65/10000\n",
      "675/675 [==============================] - 0s 140us/step - loss: 1.0689 - acc: 0.5333 - val_loss: 1.1340 - val_acc: 0.5333\n",
      "Epoch 66/10000\n",
      "675/675 [==============================] - 0s 145us/step - loss: 1.0711 - acc: 0.5348 - val_loss: 1.1307 - val_acc: 0.5333\n",
      "Epoch 67/10000\n",
      "675/675 [==============================] - 0s 136us/step - loss: 1.0583 - acc: 0.5348 - val_loss: 1.1325 - val_acc: 0.5333\n",
      "Epoch 68/10000\n",
      "675/675 [==============================] - 0s 131us/step - loss: 1.0597 - acc: 0.5378 - val_loss: 1.1292 - val_acc: 0.5333\n",
      "Epoch 69/10000\n",
      "675/675 [==============================] - 0s 149us/step - loss: 1.0599 - acc: 0.5348 - val_loss: 1.1294 - val_acc: 0.5333\n",
      "Epoch 70/10000\n",
      "675/675 [==============================] - 0s 147us/step - loss: 1.0590 - acc: 0.5378 - val_loss: 1.1298 - val_acc: 0.5333\n",
      "Epoch 71/10000\n",
      "675/675 [==============================] - 0s 133us/step - loss: 1.0533 - acc: 0.5378 - val_loss: 1.1296 - val_acc: 0.5333\n",
      "Epoch 72/10000\n",
      "675/675 [==============================] - 0s 145us/step - loss: 1.0469 - acc: 0.5363 - val_loss: 1.1288 - val_acc: 0.5333\n",
      "Epoch 73/10000\n",
      "675/675 [==============================] - 0s 118us/step - loss: 1.0454 - acc: 0.5378 - val_loss: 1.1272 - val_acc: 0.5333\n",
      "Epoch 74/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 1.0446 - acc: 0.5393 - val_loss: 1.1263 - val_acc: 0.5333\n",
      "Epoch 75/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 1.0505 - acc: 0.5378 - val_loss: 1.1282 - val_acc: 0.5378\n",
      "Epoch 76/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 1.0466 - acc: 0.5407 - val_loss: 1.1279 - val_acc: 0.5333\n",
      "Epoch 77/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 1.0485 - acc: 0.5363 - val_loss: 1.1259 - val_acc: 0.5378\n",
      "Epoch 78/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 1.0411 - acc: 0.5467 - val_loss: 1.1228 - val_acc: 0.5333\n",
      "Epoch 79/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 1.0422 - acc: 0.5378 - val_loss: 1.1217 - val_acc: 0.5333\n",
      "Epoch 80/10000\n",
      "675/675 [==============================] - 0s 119us/step - loss: 1.0411 - acc: 0.5452 - val_loss: 1.1227 - val_acc: 0.5333\n",
      "Epoch 81/10000\n",
      "675/675 [==============================] - 0s 131us/step - loss: 1.0430 - acc: 0.5363 - val_loss: 1.1236 - val_acc: 0.5378\n",
      "Epoch 82/10000\n",
      "675/675 [==============================] - 0s 148us/step - loss: 1.0366 - acc: 0.5481 - val_loss: 1.1208 - val_acc: 0.5333\n",
      "Epoch 83/10000\n",
      "675/675 [==============================] - 0s 129us/step - loss: 1.0310 - acc: 0.5452 - val_loss: 1.1211 - val_acc: 0.5289\n",
      "Epoch 84/10000\n",
      "675/675 [==============================] - 0s 120us/step - loss: 1.0322 - acc: 0.5452 - val_loss: 1.1174 - val_acc: 0.5333\n",
      "Epoch 85/10000\n",
      "675/675 [==============================] - 0s 115us/step - loss: 1.0235 - acc: 0.5511 - val_loss: 1.1201 - val_acc: 0.5289\n",
      "Epoch 86/10000\n",
      "675/675 [==============================] - 0s 115us/step - loss: 1.0242 - acc: 0.5437 - val_loss: 1.1138 - val_acc: 0.5378\n",
      "Epoch 87/10000\n",
      "675/675 [==============================] - 0s 134us/step - loss: 1.0260 - acc: 0.5393 - val_loss: 1.1129 - val_acc: 0.5333\n",
      "Epoch 88/10000\n",
      "675/675 [==============================] - 0s 131us/step - loss: 1.0187 - acc: 0.5437 - val_loss: 1.1143 - val_acc: 0.5378\n",
      "Epoch 89/10000\n",
      "675/675 [==============================] - 0s 144us/step - loss: 1.0141 - acc: 0.5467 - val_loss: 1.1170 - val_acc: 0.5200\n",
      "Epoch 90/10000\n",
      "675/675 [==============================] - 0s 130us/step - loss: 1.0142 - acc: 0.5541 - val_loss: 1.1154 - val_acc: 0.5333\n",
      "Epoch 91/10000\n",
      "675/675 [==============================] - 0s 144us/step - loss: 1.0159 - acc: 0.5437 - val_loss: 1.1114 - val_acc: 0.5378\n",
      "Epoch 92/10000\n",
      "675/675 [==============================] - 0s 132us/step - loss: 1.0142 - acc: 0.5422 - val_loss: 1.1152 - val_acc: 0.5156\n",
      "Epoch 93/10000\n",
      "675/675 [==============================] - 0s 128us/step - loss: 1.0150 - acc: 0.5467 - val_loss: 1.1136 - val_acc: 0.5156\n",
      "Epoch 94/10000\n",
      "675/675 [==============================] - 0s 115us/step - loss: 1.0080 - acc: 0.5496 - val_loss: 1.1096 - val_acc: 0.5200\n",
      "Epoch 95/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 1.0076 - acc: 0.5481 - val_loss: 1.1080 - val_acc: 0.5378\n",
      "Epoch 96/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 1.0085 - acc: 0.5452 - val_loss: 1.1110 - val_acc: 0.5244\n",
      "Epoch 97/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 1.0112 - acc: 0.5526 - val_loss: 1.1147 - val_acc: 0.5156\n",
      "Epoch 98/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 1.0026 - acc: 0.5452 - val_loss: 1.1138 - val_acc: 0.5156\n",
      "Epoch 99/10000\n",
      "675/675 [==============================] - 0s 132us/step - loss: 1.0041 - acc: 0.5496 - val_loss: 1.1141 - val_acc: 0.5156\n",
      "Epoch 100/10000\n",
      "675/675 [==============================] - 0s 141us/step - loss: 1.0034 - acc: 0.5496 - val_loss: 1.1116 - val_acc: 0.5200\n",
      "Epoch 101/10000\n",
      "675/675 [==============================] - 0s 119us/step - loss: 0.9947 - acc: 0.5570 - val_loss: 1.1084 - val_acc: 0.5200\n",
      "Epoch 102/10000\n",
      "675/675 [==============================] - 0s 111us/step - loss: 0.9962 - acc: 0.5585 - val_loss: 1.1059 - val_acc: 0.5200\n",
      "Epoch 103/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 1.0019 - acc: 0.5481 - val_loss: 1.1097 - val_acc: 0.4933\n",
      "Epoch 104/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.9880 - acc: 0.5437 - val_loss: 1.1045 - val_acc: 0.5289\n",
      "Epoch 105/10000\n",
      "675/675 [==============================] - 0s 114us/step - loss: 0.9822 - acc: 0.5570 - val_loss: 1.1100 - val_acc: 0.5022\n",
      "Epoch 106/10000\n",
      "675/675 [==============================] - 0s 113us/step - loss: 0.9928 - acc: 0.5511 - val_loss: 1.1059 - val_acc: 0.5200\n",
      "Epoch 107/10000\n",
      "675/675 [==============================] - 0s 139us/step - loss: 0.9779 - acc: 0.5570 - val_loss: 1.1014 - val_acc: 0.5289\n",
      "Epoch 108/10000\n",
      "675/675 [==============================] - 0s 141us/step - loss: 0.9710 - acc: 0.5585 - val_loss: 1.1022 - val_acc: 0.5244\n",
      "Epoch 109/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 0.9797 - acc: 0.5585 - val_loss: 1.0979 - val_acc: 0.5244\n",
      "Epoch 110/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 0.9714 - acc: 0.5659 - val_loss: 1.1014 - val_acc: 0.5289\n",
      "Epoch 111/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.9775 - acc: 0.5585 - val_loss: 1.1064 - val_acc: 0.4978\n",
      "Epoch 112/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.9762 - acc: 0.5585 - val_loss: 1.1032 - val_acc: 0.4933\n",
      "Epoch 113/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.9708 - acc: 0.5585 - val_loss: 1.0981 - val_acc: 0.5244\n",
      "Epoch 114/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.9710 - acc: 0.5615 - val_loss: 1.1028 - val_acc: 0.5022\n",
      "Epoch 115/10000\n",
      "675/675 [==============================] - 0s 116us/step - loss: 0.9763 - acc: 0.5600 - val_loss: 1.0969 - val_acc: 0.5067\n",
      "Epoch 116/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 0.9720 - acc: 0.5467 - val_loss: 1.0984 - val_acc: 0.5067\n",
      "Epoch 117/10000\n",
      "675/675 [==============================] - 0s 123us/step - loss: 0.9647 - acc: 0.5704 - val_loss: 1.0912 - val_acc: 0.5244\n",
      "Epoch 118/10000\n",
      "675/675 [==============================] - 0s 133us/step - loss: 0.9640 - acc: 0.5526 - val_loss: 1.0983 - val_acc: 0.4978\n",
      "Epoch 119/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 141us/step - loss: 0.9496 - acc: 0.5719 - val_loss: 1.1062 - val_acc: 0.5156\n",
      "Epoch 120/10000\n",
      "675/675 [==============================] - 0s 116us/step - loss: 0.9530 - acc: 0.5689 - val_loss: 1.0910 - val_acc: 0.5200\n",
      "Epoch 121/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.9656 - acc: 0.5615 - val_loss: 1.0924 - val_acc: 0.5244\n",
      "Epoch 122/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.9567 - acc: 0.5674 - val_loss: 1.0986 - val_acc: 0.4933\n",
      "Epoch 123/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.9518 - acc: 0.5778 - val_loss: 1.0932 - val_acc: 0.4933\n",
      "Epoch 124/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.9490 - acc: 0.5733 - val_loss: 1.0861 - val_acc: 0.5244\n",
      "Epoch 125/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.9491 - acc: 0.5570 - val_loss: 1.0920 - val_acc: 0.5067\n",
      "Epoch 126/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.9431 - acc: 0.5704 - val_loss: 1.0904 - val_acc: 0.4978\n",
      "Epoch 127/10000\n",
      "675/675 [==============================] - 0s 109us/step - loss: 0.9383 - acc: 0.5748 - val_loss: 1.0879 - val_acc: 0.5022\n",
      "Epoch 128/10000\n",
      "675/675 [==============================] - 0s 120us/step - loss: 0.9378 - acc: 0.5585 - val_loss: 1.0895 - val_acc: 0.5067\n",
      "Epoch 129/10000\n",
      "675/675 [==============================] - 0s 124us/step - loss: 0.9367 - acc: 0.5644 - val_loss: 1.0869 - val_acc: 0.5156\n",
      "Epoch 130/10000\n",
      "675/675 [==============================] - 0s 105us/step - loss: 0.9328 - acc: 0.5689 - val_loss: 1.0797 - val_acc: 0.5244\n",
      "Epoch 131/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.9249 - acc: 0.5659 - val_loss: 1.0849 - val_acc: 0.5067\n",
      "Epoch 132/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.9327 - acc: 0.5659 - val_loss: 1.0964 - val_acc: 0.5200\n",
      "Epoch 133/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.9413 - acc: 0.5748 - val_loss: 1.0825 - val_acc: 0.5200\n",
      "Epoch 134/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.9268 - acc: 0.5674 - val_loss: 1.0781 - val_acc: 0.5244\n",
      "Epoch 135/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.9250 - acc: 0.5733 - val_loss: 1.0797 - val_acc: 0.5289\n",
      "Epoch 136/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.9333 - acc: 0.5600 - val_loss: 1.0792 - val_acc: 0.5244\n",
      "Epoch 137/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.9308 - acc: 0.5630 - val_loss: 1.0788 - val_acc: 0.5111\n",
      "Epoch 138/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.9166 - acc: 0.5719 - val_loss: 1.0816 - val_acc: 0.5067\n",
      "Epoch 139/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.9098 - acc: 0.5778 - val_loss: 1.0859 - val_acc: 0.5111\n",
      "Epoch 140/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.9111 - acc: 0.5867 - val_loss: 1.0779 - val_acc: 0.5200\n",
      "Epoch 141/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.9204 - acc: 0.5748 - val_loss: 1.0730 - val_acc: 0.5289\n",
      "Epoch 142/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.9043 - acc: 0.5659 - val_loss: 1.0757 - val_acc: 0.5244\n",
      "Epoch 143/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.9158 - acc: 0.5763 - val_loss: 1.0819 - val_acc: 0.5200\n",
      "Epoch 144/10000\n",
      "675/675 [==============================] - 0s 112us/step - loss: 0.9174 - acc: 0.5763 - val_loss: 1.0750 - val_acc: 0.5156\n",
      "Epoch 145/10000\n",
      "675/675 [==============================] - 0s 127us/step - loss: 0.9143 - acc: 0.5541 - val_loss: 1.0793 - val_acc: 0.5200\n",
      "Epoch 146/10000\n",
      "675/675 [==============================] - 0s 129us/step - loss: 0.9142 - acc: 0.5763 - val_loss: 1.0738 - val_acc: 0.5244\n",
      "Epoch 147/10000\n",
      "675/675 [==============================] - 0s 153us/step - loss: 0.8967 - acc: 0.5881 - val_loss: 1.0722 - val_acc: 0.5156\n",
      "Epoch 148/10000\n",
      "675/675 [==============================] - 0s 109us/step - loss: 0.8928 - acc: 0.5763 - val_loss: 1.0726 - val_acc: 0.5156\n",
      "Epoch 149/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 0.8898 - acc: 0.5911 - val_loss: 1.0788 - val_acc: 0.5289\n",
      "Epoch 150/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.8968 - acc: 0.5896 - val_loss: 1.0680 - val_acc: 0.5244\n",
      "Epoch 151/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.8877 - acc: 0.5970 - val_loss: 1.0726 - val_acc: 0.5244\n",
      "Epoch 152/10000\n",
      "675/675 [==============================] - 0s 143us/step - loss: 0.8844 - acc: 0.5644 - val_loss: 1.0728 - val_acc: 0.5244\n",
      "Epoch 153/10000\n",
      "675/675 [==============================] - 0s 141us/step - loss: 0.8981 - acc: 0.5822 - val_loss: 1.0878 - val_acc: 0.5200\n",
      "Epoch 154/10000\n",
      "675/675 [==============================] - 0s 121us/step - loss: 0.8802 - acc: 0.6015 - val_loss: 1.0672 - val_acc: 0.5200\n",
      "Epoch 155/10000\n",
      "675/675 [==============================] - 0s 135us/step - loss: 0.8796 - acc: 0.5941 - val_loss: 1.0638 - val_acc: 0.5289\n",
      "Epoch 156/10000\n",
      "675/675 [==============================] - 0s 126us/step - loss: 0.8815 - acc: 0.5778 - val_loss: 1.0746 - val_acc: 0.5333\n",
      "Epoch 157/10000\n",
      "675/675 [==============================] - 0s 105us/step - loss: 0.8737 - acc: 0.5985 - val_loss: 1.0647 - val_acc: 0.5244\n",
      "Epoch 158/10000\n",
      "675/675 [==============================] - 0s 114us/step - loss: 0.8831 - acc: 0.5881 - val_loss: 1.0649 - val_acc: 0.5200\n",
      "Epoch 159/10000\n",
      "675/675 [==============================] - 0s 137us/step - loss: 0.8719 - acc: 0.6030 - val_loss: 1.0648 - val_acc: 0.5244\n",
      "Epoch 160/10000\n",
      "675/675 [==============================] - 0s 119us/step - loss: 0.8764 - acc: 0.5852 - val_loss: 1.0666 - val_acc: 0.5244\n",
      "Epoch 161/10000\n",
      "675/675 [==============================] - 0s 114us/step - loss: 0.8708 - acc: 0.5926 - val_loss: 1.0603 - val_acc: 0.5156\n",
      "Epoch 162/10000\n",
      "675/675 [==============================] - 0s 126us/step - loss: 0.8689 - acc: 0.5881 - val_loss: 1.0672 - val_acc: 0.5244\n",
      "Epoch 163/10000\n",
      "675/675 [==============================] - 0s 131us/step - loss: 0.8700 - acc: 0.5970 - val_loss: 1.0646 - val_acc: 0.5200\n",
      "Epoch 164/10000\n",
      "675/675 [==============================] - 0s 115us/step - loss: 0.8751 - acc: 0.5970 - val_loss: 1.0707 - val_acc: 0.5244\n",
      "Epoch 165/10000\n",
      "675/675 [==============================] - 0s 131us/step - loss: 0.8621 - acc: 0.6119 - val_loss: 1.0657 - val_acc: 0.5200\n",
      "Epoch 166/10000\n",
      "675/675 [==============================] - 0s 138us/step - loss: 0.8596 - acc: 0.6222 - val_loss: 1.0732 - val_acc: 0.5289\n",
      "Epoch 167/10000\n",
      "675/675 [==============================] - 0s 127us/step - loss: 0.8658 - acc: 0.6089 - val_loss: 1.0637 - val_acc: 0.5289\n",
      "Epoch 168/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.8628 - acc: 0.5926 - val_loss: 1.0590 - val_acc: 0.5200\n",
      "Epoch 169/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.8532 - acc: 0.6015 - val_loss: 1.0664 - val_acc: 0.5289\n",
      "Epoch 170/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.8619 - acc: 0.6104 - val_loss: 1.0521 - val_acc: 0.5156\n",
      "Epoch 171/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.8447 - acc: 0.6000 - val_loss: 1.0500 - val_acc: 0.5244\n",
      "Epoch 172/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.8512 - acc: 0.6089 - val_loss: 1.0634 - val_acc: 0.5200\n",
      "Epoch 173/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 0.8436 - acc: 0.6193 - val_loss: 1.0480 - val_acc: 0.5333\n",
      "Epoch 174/10000\n",
      "675/675 [==============================] - 0s 141us/step - loss: 0.8576 - acc: 0.6015 - val_loss: 1.0502 - val_acc: 0.5200\n",
      "Epoch 175/10000\n",
      "675/675 [==============================] - 0s 156us/step - loss: 0.8398 - acc: 0.6119 - val_loss: 1.0507 - val_acc: 0.5289\n",
      "Epoch 176/10000\n",
      "675/675 [==============================] - 0s 119us/step - loss: 0.8369 - acc: 0.6252 - val_loss: 1.0489 - val_acc: 0.5244\n",
      "Epoch 177/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 0.8482 - acc: 0.5985 - val_loss: 1.0485 - val_acc: 0.5289\n",
      "Epoch 178/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 100us/step - loss: 0.8401 - acc: 0.6207 - val_loss: 1.0610 - val_acc: 0.5378\n",
      "Epoch 179/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.8337 - acc: 0.6030 - val_loss: 1.0458 - val_acc: 0.5244\n",
      "Epoch 180/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.8370 - acc: 0.6222 - val_loss: 1.0485 - val_acc: 0.5333\n",
      "Epoch 181/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.8376 - acc: 0.6311 - val_loss: 1.0458 - val_acc: 0.5333\n",
      "Epoch 182/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.8347 - acc: 0.6148 - val_loss: 1.0496 - val_acc: 0.5289\n",
      "Epoch 183/10000\n",
      "675/675 [==============================] - 0s 131us/step - loss: 0.8329 - acc: 0.6133 - val_loss: 1.0499 - val_acc: 0.5289\n",
      "Epoch 184/10000\n",
      "675/675 [==============================] - 0s 145us/step - loss: 0.8411 - acc: 0.6133 - val_loss: 1.0471 - val_acc: 0.5200\n",
      "Epoch 185/10000\n",
      "675/675 [==============================] - 0s 142us/step - loss: 0.8105 - acc: 0.6415 - val_loss: 1.0549 - val_acc: 0.5289\n",
      "Epoch 186/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.8293 - acc: 0.6207 - val_loss: 1.0365 - val_acc: 0.5378\n",
      "Epoch 187/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.8143 - acc: 0.6356 - val_loss: 1.0445 - val_acc: 0.5200\n",
      "Epoch 188/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.8305 - acc: 0.6222 - val_loss: 1.0396 - val_acc: 0.5244\n",
      "Epoch 189/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.8057 - acc: 0.6370 - val_loss: 1.0373 - val_acc: 0.5289\n",
      "Epoch 190/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.8125 - acc: 0.6430 - val_loss: 1.0353 - val_acc: 0.5289\n",
      "Epoch 191/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.8111 - acc: 0.6311 - val_loss: 1.0394 - val_acc: 0.5378\n",
      "Epoch 192/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.8055 - acc: 0.6519 - val_loss: 1.0342 - val_acc: 0.5378\n",
      "Epoch 193/10000\n",
      "675/675 [==============================] - 0s 119us/step - loss: 0.8124 - acc: 0.6311 - val_loss: 1.0378 - val_acc: 0.5200\n",
      "Epoch 194/10000\n",
      "675/675 [==============================] - 0s 120us/step - loss: 0.8097 - acc: 0.6163 - val_loss: 1.0454 - val_acc: 0.5422\n",
      "Epoch 195/10000\n",
      "675/675 [==============================] - 0s 123us/step - loss: 0.8118 - acc: 0.6400 - val_loss: 1.0312 - val_acc: 0.5333\n",
      "Epoch 196/10000\n",
      "675/675 [==============================] - 0s 113us/step - loss: 0.8107 - acc: 0.6622 - val_loss: 1.0335 - val_acc: 0.5244\n",
      "Epoch 197/10000\n",
      "675/675 [==============================] - 0s 153us/step - loss: 0.8125 - acc: 0.6400 - val_loss: 1.0287 - val_acc: 0.5333\n",
      "Epoch 198/10000\n",
      "675/675 [==============================] - 0s 144us/step - loss: 0.7816 - acc: 0.6578 - val_loss: 1.0337 - val_acc: 0.5244\n",
      "Epoch 199/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.8030 - acc: 0.6548 - val_loss: 1.0265 - val_acc: 0.5422\n",
      "Epoch 200/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.8099 - acc: 0.6267 - val_loss: 1.0246 - val_acc: 0.5422\n",
      "Epoch 201/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.7944 - acc: 0.6533 - val_loss: 1.0319 - val_acc: 0.5244\n",
      "Epoch 202/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.7920 - acc: 0.6385 - val_loss: 1.0235 - val_acc: 0.5378\n",
      "Epoch 203/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.7826 - acc: 0.6874 - val_loss: 1.0253 - val_acc: 0.5422\n",
      "Epoch 204/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.7879 - acc: 0.6548 - val_loss: 1.0207 - val_acc: 0.5333\n",
      "Epoch 205/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.7881 - acc: 0.6400 - val_loss: 1.0355 - val_acc: 0.5378\n",
      "Epoch 206/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 0.7728 - acc: 0.6933 - val_loss: 1.0207 - val_acc: 0.5333\n",
      "Epoch 207/10000\n",
      "675/675 [==============================] - 0s 121us/step - loss: 0.7974 - acc: 0.6459 - val_loss: 1.0176 - val_acc: 0.5422\n",
      "Epoch 208/10000\n",
      "675/675 [==============================] - 0s 133us/step - loss: 0.7725 - acc: 0.6637 - val_loss: 1.0192 - val_acc: 0.5244\n",
      "Epoch 209/10000\n",
      "675/675 [==============================] - 0s 138us/step - loss: 0.7870 - acc: 0.6474 - val_loss: 1.0184 - val_acc: 0.5333\n",
      "Epoch 210/10000\n",
      "675/675 [==============================] - 0s 107us/step - loss: 0.7694 - acc: 0.6696 - val_loss: 1.0147 - val_acc: 0.5467\n",
      "Epoch 211/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.7699 - acc: 0.6459 - val_loss: 1.0317 - val_acc: 0.5556\n",
      "Epoch 212/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.7747 - acc: 0.6889 - val_loss: 1.0131 - val_acc: 0.5333\n",
      "Epoch 213/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.7782 - acc: 0.6681 - val_loss: 1.0139 - val_acc: 0.5422\n",
      "Epoch 214/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.7606 - acc: 0.6889 - val_loss: 1.0118 - val_acc: 0.5333\n",
      "Epoch 215/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.7672 - acc: 0.6741 - val_loss: 1.0088 - val_acc: 0.5333\n",
      "Epoch 216/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.7687 - acc: 0.6741 - val_loss: 1.0080 - val_acc: 0.5378\n",
      "Epoch 217/10000\n",
      "675/675 [==============================] - 0s 115us/step - loss: 0.7553 - acc: 0.6622 - val_loss: 1.0076 - val_acc: 0.5289\n",
      "Epoch 218/10000\n",
      "675/675 [==============================] - 0s 120us/step - loss: 0.7600 - acc: 0.6756 - val_loss: 1.0072 - val_acc: 0.5289\n",
      "Epoch 219/10000\n",
      "675/675 [==============================] - 0s 134us/step - loss: 0.7563 - acc: 0.6889 - val_loss: 1.0066 - val_acc: 0.5378\n",
      "Epoch 220/10000\n",
      "675/675 [==============================] - 0s 139us/step - loss: 0.7544 - acc: 0.6741 - val_loss: 1.0052 - val_acc: 0.5289\n",
      "Epoch 221/10000\n",
      "675/675 [==============================] - 0s 128us/step - loss: 0.7513 - acc: 0.6785 - val_loss: 1.0164 - val_acc: 0.5689\n",
      "Epoch 222/10000\n",
      "675/675 [==============================] - 0s 114us/step - loss: 0.7662 - acc: 0.6859 - val_loss: 0.9999 - val_acc: 0.5378\n",
      "Epoch 223/10000\n",
      "675/675 [==============================] - 0s 105us/step - loss: 0.7516 - acc: 0.6978 - val_loss: 0.9961 - val_acc: 0.5422\n",
      "Epoch 224/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.7499 - acc: 0.6815 - val_loss: 0.9984 - val_acc: 0.5378\n",
      "Epoch 225/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.7649 - acc: 0.6874 - val_loss: 0.9962 - val_acc: 0.5333\n",
      "Epoch 226/10000\n",
      "675/675 [==============================] - 0s 109us/step - loss: 0.7590 - acc: 0.6830 - val_loss: 0.9996 - val_acc: 0.5422\n",
      "Epoch 227/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.7391 - acc: 0.6948 - val_loss: 0.9976 - val_acc: 0.5511\n",
      "Epoch 228/10000\n",
      "675/675 [==============================] - 0s 109us/step - loss: 0.7535 - acc: 0.6874 - val_loss: 0.9930 - val_acc: 0.5467\n",
      "Epoch 229/10000\n",
      "675/675 [==============================] - 0s 128us/step - loss: 0.7512 - acc: 0.6756 - val_loss: 0.9990 - val_acc: 0.5422\n",
      "Epoch 230/10000\n",
      "675/675 [==============================] - 0s 136us/step - loss: 0.7492 - acc: 0.6681 - val_loss: 1.0144 - val_acc: 0.5689\n",
      "Epoch 231/10000\n",
      "675/675 [==============================] - 0s 139us/step - loss: 0.7285 - acc: 0.7244 - val_loss: 0.9907 - val_acc: 0.5422\n",
      "Epoch 232/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 0.7498 - acc: 0.6874 - val_loss: 0.9903 - val_acc: 0.5467\n",
      "Epoch 233/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.7288 - acc: 0.6993 - val_loss: 1.0109 - val_acc: 0.5822\n",
      "Epoch 234/10000\n",
      "675/675 [==============================] - 0s 105us/step - loss: 0.7472 - acc: 0.7096 - val_loss: 0.9895 - val_acc: 0.5378\n",
      "Epoch 235/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.7245 - acc: 0.6948 - val_loss: 0.9943 - val_acc: 0.5422\n",
      "Epoch 236/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.7290 - acc: 0.6948 - val_loss: 0.9909 - val_acc: 0.5333\n",
      "Epoch 237/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 105us/step - loss: 0.7232 - acc: 0.7037 - val_loss: 0.9894 - val_acc: 0.5511\n",
      "Epoch 238/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.7277 - acc: 0.7111 - val_loss: 0.9949 - val_acc: 0.5556\n",
      "Epoch 239/10000\n",
      "675/675 [==============================] - 0s 109us/step - loss: 0.7184 - acc: 0.7141 - val_loss: 0.9909 - val_acc: 0.5422\n",
      "Epoch 240/10000\n",
      "675/675 [==============================] - 0s 149us/step - loss: 0.7272 - acc: 0.6904 - val_loss: 0.9866 - val_acc: 0.5422\n",
      "Epoch 241/10000\n",
      "675/675 [==============================] - 0s 148us/step - loss: 0.7255 - acc: 0.7200 - val_loss: 0.9842 - val_acc: 0.5467\n",
      "Epoch 242/10000\n",
      "675/675 [==============================] - 0s 107us/step - loss: 0.6948 - acc: 0.7215 - val_loss: 0.9827 - val_acc: 0.5422\n",
      "Epoch 243/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.7215 - acc: 0.6963 - val_loss: 0.9921 - val_acc: 0.5644\n",
      "Epoch 244/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.7364 - acc: 0.7037 - val_loss: 0.9974 - val_acc: 0.5733\n",
      "Epoch 245/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.7058 - acc: 0.7244 - val_loss: 0.9821 - val_acc: 0.5333\n",
      "Epoch 246/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.7121 - acc: 0.7081 - val_loss: 0.9842 - val_acc: 0.5556\n",
      "Epoch 247/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.7168 - acc: 0.7067 - val_loss: 0.9781 - val_acc: 0.5467\n",
      "Epoch 248/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.7015 - acc: 0.7185 - val_loss: 0.9962 - val_acc: 0.5644\n",
      "Epoch 249/10000\n",
      "675/675 [==============================] - 0s 119us/step - loss: 0.6957 - acc: 0.7304 - val_loss: 0.9774 - val_acc: 0.5422\n",
      "Epoch 250/10000\n",
      "675/675 [==============================] - 0s 131us/step - loss: 0.7104 - acc: 0.7067 - val_loss: 0.9733 - val_acc: 0.5378\n",
      "Epoch 251/10000\n",
      "675/675 [==============================] - 0s 124us/step - loss: 0.7261 - acc: 0.7022 - val_loss: 0.9827 - val_acc: 0.5644\n",
      "Epoch 252/10000\n",
      "675/675 [==============================] - 0s 111us/step - loss: 0.7023 - acc: 0.7230 - val_loss: 0.9695 - val_acc: 0.5422\n",
      "Epoch 253/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.7049 - acc: 0.7319 - val_loss: 0.9743 - val_acc: 0.5467\n",
      "Epoch 254/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.6995 - acc: 0.7289 - val_loss: 0.9689 - val_acc: 0.5467\n",
      "Epoch 255/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.6965 - acc: 0.7185 - val_loss: 0.9685 - val_acc: 0.5467\n",
      "Epoch 256/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.6840 - acc: 0.7363 - val_loss: 0.9659 - val_acc: 0.5422\n",
      "Epoch 257/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.6931 - acc: 0.7289 - val_loss: 0.9740 - val_acc: 0.5556\n",
      "Epoch 258/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.6737 - acc: 0.7481 - val_loss: 0.9708 - val_acc: 0.5467\n",
      "Epoch 259/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.6915 - acc: 0.7244 - val_loss: 0.9762 - val_acc: 0.5822\n",
      "Epoch 260/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.7084 - acc: 0.7259 - val_loss: 0.9643 - val_acc: 0.5511\n",
      "Epoch 261/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.6722 - acc: 0.7511 - val_loss: 0.9714 - val_acc: 0.5600\n",
      "Epoch 262/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.6838 - acc: 0.7185 - val_loss: 0.9651 - val_acc: 0.5644\n",
      "Epoch 263/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.6927 - acc: 0.7289 - val_loss: 0.9623 - val_acc: 0.5556\n",
      "Epoch 264/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.6905 - acc: 0.7333 - val_loss: 0.9744 - val_acc: 0.5822\n",
      "Epoch 265/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.6817 - acc: 0.7615 - val_loss: 0.9587 - val_acc: 0.5733\n",
      "Epoch 266/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.6918 - acc: 0.7333 - val_loss: 0.9565 - val_acc: 0.5689\n",
      "Epoch 267/10000\n",
      "675/675 [==============================] - 0s 122us/step - loss: 0.6831 - acc: 0.7407 - val_loss: 0.9673 - val_acc: 0.5867\n",
      "Epoch 268/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.6931 - acc: 0.7274 - val_loss: 0.9622 - val_acc: 0.5600\n",
      "Epoch 269/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.6940 - acc: 0.7259 - val_loss: 0.9517 - val_acc: 0.5511\n",
      "Epoch 270/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.6770 - acc: 0.7437 - val_loss: 0.9702 - val_acc: 0.5733\n",
      "Epoch 271/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.6659 - acc: 0.7630 - val_loss: 0.9675 - val_acc: 0.5689\n",
      "Epoch 272/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.6863 - acc: 0.7304 - val_loss: 0.9601 - val_acc: 0.5689\n",
      "Epoch 273/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.6756 - acc: 0.7348 - val_loss: 0.9881 - val_acc: 0.5822\n",
      "Epoch 274/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.6808 - acc: 0.7704 - val_loss: 0.9526 - val_acc: 0.5556\n",
      "Epoch 275/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.6620 - acc: 0.7585 - val_loss: 0.9594 - val_acc: 0.5600\n",
      "Epoch 276/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.6776 - acc: 0.7659 - val_loss: 0.9556 - val_acc: 0.5689\n",
      "Epoch 277/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.6817 - acc: 0.7333 - val_loss: 0.9711 - val_acc: 0.5822\n",
      "Epoch 278/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.6621 - acc: 0.7689 - val_loss: 0.9493 - val_acc: 0.5600\n",
      "Epoch 279/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.6444 - acc: 0.7659 - val_loss: 0.9600 - val_acc: 0.5778\n",
      "Epoch 280/10000\n",
      "675/675 [==============================] - 0s 132us/step - loss: 0.6740 - acc: 0.7319 - val_loss: 0.9501 - val_acc: 0.5778\n",
      "Epoch 281/10000\n",
      "675/675 [==============================] - 0s 105us/step - loss: 0.6585 - acc: 0.7541 - val_loss: 0.9529 - val_acc: 0.5822\n",
      "Epoch 282/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.6547 - acc: 0.7333 - val_loss: 0.9826 - val_acc: 0.6000\n",
      "Epoch 283/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.6548 - acc: 0.7630 - val_loss: 0.9589 - val_acc: 0.5822\n",
      "Epoch 284/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.6458 - acc: 0.7585 - val_loss: 0.9578 - val_acc: 0.5778\n",
      "Epoch 285/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.6746 - acc: 0.7481 - val_loss: 0.9646 - val_acc: 0.5911\n",
      "Epoch 286/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.6553 - acc: 0.7704 - val_loss: 0.9423 - val_acc: 0.5644\n",
      "Epoch 287/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.6592 - acc: 0.7556 - val_loss: 0.9453 - val_acc: 0.5822\n",
      "Epoch 288/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.6473 - acc: 0.7615 - val_loss: 0.9387 - val_acc: 0.5689\n",
      "Epoch 289/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.6534 - acc: 0.7600 - val_loss: 0.9409 - val_acc: 0.5556\n",
      "Epoch 290/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.6539 - acc: 0.7437 - val_loss: 0.9419 - val_acc: 0.5822\n",
      "Epoch 291/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.6452 - acc: 0.7644 - val_loss: 0.9576 - val_acc: 0.5911\n",
      "Epoch 292/10000\n",
      "675/675 [==============================] - 0s 113us/step - loss: 0.6745 - acc: 0.7348 - val_loss: 0.9441 - val_acc: 0.5733\n",
      "Epoch 293/10000\n",
      "675/675 [==============================] - 0s 132us/step - loss: 0.6551 - acc: 0.7526 - val_loss: 0.9611 - val_acc: 0.5956\n",
      "Epoch 294/10000\n",
      "675/675 [==============================] - 0s 113us/step - loss: 0.6487 - acc: 0.7511 - val_loss: 0.9428 - val_acc: 0.5867\n",
      "Epoch 295/10000\n",
      "675/675 [==============================] - 0s 122us/step - loss: 0.6454 - acc: 0.7674 - val_loss: 0.9393 - val_acc: 0.5467\n",
      "Epoch 296/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 129us/step - loss: 0.6368 - acc: 0.7481 - val_loss: 0.9604 - val_acc: 0.5867\n",
      "Epoch 297/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.6420 - acc: 0.7600 - val_loss: 0.9427 - val_acc: 0.5511\n",
      "Epoch 298/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.6616 - acc: 0.7437 - val_loss: 0.9532 - val_acc: 0.6133\n",
      "Epoch 299/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.6479 - acc: 0.7615 - val_loss: 0.9550 - val_acc: 0.6000\n",
      "Epoch 300/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.6461 - acc: 0.7615 - val_loss: 0.9345 - val_acc: 0.5733\n",
      "Epoch 301/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 0.6200 - acc: 0.7689 - val_loss: 0.9359 - val_acc: 0.5822\n",
      "Epoch 302/10000\n",
      "675/675 [==============================] - 0s 112us/step - loss: 0.6522 - acc: 0.7496 - val_loss: 0.9292 - val_acc: 0.5822\n",
      "Epoch 303/10000\n",
      "675/675 [==============================] - 0s 110us/step - loss: 0.6404 - acc: 0.7585 - val_loss: 0.9407 - val_acc: 0.5911\n",
      "Epoch 304/10000\n",
      "675/675 [==============================] - 0s 144us/step - loss: 0.6353 - acc: 0.7659 - val_loss: 0.9547 - val_acc: 0.6178\n",
      "Epoch 305/10000\n",
      "675/675 [==============================] - 0s 140us/step - loss: 0.6220 - acc: 0.7837 - val_loss: 0.9548 - val_acc: 0.6133\n",
      "Epoch 306/10000\n",
      "675/675 [==============================] - 0s 133us/step - loss: 0.6306 - acc: 0.7748 - val_loss: 0.9364 - val_acc: 0.5822\n",
      "Epoch 307/10000\n",
      "675/675 [==============================] - 0s 111us/step - loss: 0.6292 - acc: 0.7837 - val_loss: 0.9360 - val_acc: 0.5956\n",
      "Epoch 308/10000\n",
      "675/675 [==============================] - 0s 114us/step - loss: 0.6314 - acc: 0.7748 - val_loss: 0.9263 - val_acc: 0.5733\n",
      "Epoch 309/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.6339 - acc: 0.7719 - val_loss: 0.9290 - val_acc: 0.5689\n",
      "Epoch 310/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.6331 - acc: 0.7600 - val_loss: 0.9299 - val_acc: 0.5733\n",
      "Epoch 311/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.6313 - acc: 0.7630 - val_loss: 0.9296 - val_acc: 0.5689\n",
      "Epoch 312/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.6218 - acc: 0.7689 - val_loss: 0.9375 - val_acc: 0.5822\n",
      "Epoch 313/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.6271 - acc: 0.7793 - val_loss: 0.9414 - val_acc: 0.6000\n",
      "Epoch 314/10000\n",
      "675/675 [==============================] - 0s 125us/step - loss: 0.6278 - acc: 0.7689 - val_loss: 0.9487 - val_acc: 0.6089\n",
      "Epoch 315/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 0.6072 - acc: 0.7822 - val_loss: 0.9408 - val_acc: 0.5778\n",
      "Epoch 316/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.6165 - acc: 0.7926 - val_loss: 0.9297 - val_acc: 0.5867\n",
      "Epoch 317/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.6023 - acc: 0.7867 - val_loss: 0.9304 - val_acc: 0.6044\n",
      "Epoch 318/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.5776 - acc: 0.8000 - val_loss: 0.9202 - val_acc: 0.5867\n",
      "Epoch 319/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.6162 - acc: 0.7822 - val_loss: 0.9288 - val_acc: 0.5867\n",
      "Epoch 320/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.6174 - acc: 0.7689 - val_loss: 0.9151 - val_acc: 0.5778\n",
      "Epoch 321/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.6054 - acc: 0.7956 - val_loss: 0.9510 - val_acc: 0.6267\n",
      "Epoch 322/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.6050 - acc: 0.8104 - val_loss: 0.9102 - val_acc: 0.5911\n",
      "Epoch 323/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.6130 - acc: 0.7630 - val_loss: 0.9386 - val_acc: 0.6222\n",
      "Epoch 324/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.5950 - acc: 0.7822 - val_loss: 0.9252 - val_acc: 0.6178\n",
      "Epoch 325/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.5906 - acc: 0.8044 - val_loss: 0.9226 - val_acc: 0.5822\n",
      "Epoch 326/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 0.6045 - acc: 0.8074 - val_loss: 0.9232 - val_acc: 0.6000\n",
      "Epoch 327/10000\n",
      "675/675 [==============================] - 0s 127us/step - loss: 0.5891 - acc: 0.8015 - val_loss: 0.9412 - val_acc: 0.6178\n",
      "Epoch 328/10000\n",
      "675/675 [==============================] - 0s 119us/step - loss: 0.6203 - acc: 0.7807 - val_loss: 0.9245 - val_acc: 0.5867\n",
      "Epoch 329/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 0.5736 - acc: 0.8119 - val_loss: 0.9331 - val_acc: 0.6133\n",
      "Epoch 330/10000\n",
      "675/675 [==============================] - 0s 128us/step - loss: 0.5954 - acc: 0.8044 - val_loss: 0.9162 - val_acc: 0.5867\n",
      "Epoch 331/10000\n",
      "675/675 [==============================] - 0s 119us/step - loss: 0.5951 - acc: 0.7941 - val_loss: 0.9124 - val_acc: 0.5911\n",
      "Epoch 332/10000\n",
      "675/675 [==============================] - 0s 120us/step - loss: 0.5843 - acc: 0.8015 - val_loss: 0.9092 - val_acc: 0.5956\n",
      "Epoch 333/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.5901 - acc: 0.7881 - val_loss: 0.9048 - val_acc: 0.5911\n",
      "Epoch 334/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.5936 - acc: 0.7941 - val_loss: 0.9064 - val_acc: 0.5956\n",
      "Epoch 335/10000\n",
      "675/675 [==============================] - 0s 105us/step - loss: 0.5700 - acc: 0.8104 - val_loss: 0.9073 - val_acc: 0.5689\n",
      "Epoch 336/10000\n",
      "675/675 [==============================] - 0s 113us/step - loss: 0.6041 - acc: 0.7748 - val_loss: 0.9249 - val_acc: 0.6178\n",
      "Epoch 337/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.5821 - acc: 0.7822 - val_loss: 0.9074 - val_acc: 0.5733\n",
      "Epoch 338/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.5950 - acc: 0.7822 - val_loss: 0.9078 - val_acc: 0.5778\n",
      "Epoch 339/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.5800 - acc: 0.8059 - val_loss: 0.9034 - val_acc: 0.5911\n",
      "Epoch 340/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.5769 - acc: 0.7896 - val_loss: 0.9033 - val_acc: 0.5689\n",
      "Epoch 341/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.5741 - acc: 0.8030 - val_loss: 0.9083 - val_acc: 0.5778\n",
      "Epoch 342/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.5778 - acc: 0.7970 - val_loss: 0.9053 - val_acc: 0.5911\n",
      "Epoch 343/10000\n",
      "675/675 [==============================] - 0s 124us/step - loss: 0.5943 - acc: 0.7807 - val_loss: 0.9142 - val_acc: 0.6222\n",
      "Epoch 344/10000\n",
      "675/675 [==============================] - 0s 132us/step - loss: 0.5773 - acc: 0.8059 - val_loss: 0.9069 - val_acc: 0.6044\n",
      "Epoch 345/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 0.5766 - acc: 0.7911 - val_loss: 0.9009 - val_acc: 0.5956\n",
      "Epoch 346/10000\n",
      "675/675 [==============================] - 0s 115us/step - loss: 0.5620 - acc: 0.8104 - val_loss: 0.9383 - val_acc: 0.6444\n",
      "Epoch 347/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 0.5887 - acc: 0.7867 - val_loss: 0.9111 - val_acc: 0.5956\n",
      "Epoch 348/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.5965 - acc: 0.7748 - val_loss: 0.9039 - val_acc: 0.6222\n",
      "Epoch 349/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.5587 - acc: 0.8000 - val_loss: 0.8993 - val_acc: 0.5956\n",
      "Epoch 350/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.5748 - acc: 0.8044 - val_loss: 0.8959 - val_acc: 0.6000\n",
      "Epoch 351/10000\n",
      "675/675 [==============================] - 0s 113us/step - loss: 0.5672 - acc: 0.7985 - val_loss: 0.9078 - val_acc: 0.5600\n",
      "Epoch 352/10000\n",
      "675/675 [==============================] - 0s 132us/step - loss: 0.5766 - acc: 0.7763 - val_loss: 0.9069 - val_acc: 0.6133\n",
      "Epoch 353/10000\n",
      "675/675 [==============================] - 0s 121us/step - loss: 0.5756 - acc: 0.8119 - val_loss: 0.9064 - val_acc: 0.6000\n",
      "Epoch 354/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.5664 - acc: 0.8000 - val_loss: 0.8980 - val_acc: 0.5644\n",
      "Epoch 355/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 115us/step - loss: 0.5886 - acc: 0.7881 - val_loss: 0.8939 - val_acc: 0.5822\n",
      "Epoch 356/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.5776 - acc: 0.7748 - val_loss: 0.9422 - val_acc: 0.6400\n",
      "Epoch 357/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5842 - acc: 0.7926 - val_loss: 0.9022 - val_acc: 0.5867\n",
      "Epoch 358/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.5752 - acc: 0.7778 - val_loss: 0.8953 - val_acc: 0.5911\n",
      "Epoch 359/10000\n",
      "675/675 [==============================] - 0s 121us/step - loss: 0.5542 - acc: 0.8119 - val_loss: 0.8970 - val_acc: 0.6311\n",
      "Epoch 360/10000\n",
      "675/675 [==============================] - 0s 120us/step - loss: 0.5391 - acc: 0.8252 - val_loss: 0.8994 - val_acc: 0.5778\n",
      "Epoch 361/10000\n",
      "675/675 [==============================] - 0s 105us/step - loss: 0.5720 - acc: 0.7941 - val_loss: 0.8949 - val_acc: 0.5867\n",
      "Epoch 362/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.5621 - acc: 0.7956 - val_loss: 0.9049 - val_acc: 0.6178\n",
      "Epoch 363/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.5397 - acc: 0.8222 - val_loss: 0.8946 - val_acc: 0.5867\n",
      "Epoch 364/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.5293 - acc: 0.8178 - val_loss: 0.8963 - val_acc: 0.5956\n",
      "Epoch 365/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.5494 - acc: 0.8133 - val_loss: 0.9144 - val_acc: 0.6000\n",
      "Epoch 366/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.5707 - acc: 0.8000 - val_loss: 0.8935 - val_acc: 0.5733\n",
      "Epoch 367/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.5475 - acc: 0.7926 - val_loss: 0.8945 - val_acc: 0.6089\n",
      "Epoch 368/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.5386 - acc: 0.8163 - val_loss: 0.8997 - val_acc: 0.6311\n",
      "Epoch 369/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5569 - acc: 0.8015 - val_loss: 0.8901 - val_acc: 0.5778\n",
      "Epoch 370/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.5324 - acc: 0.8370 - val_loss: 0.8966 - val_acc: 0.5911\n",
      "Epoch 371/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5583 - acc: 0.8059 - val_loss: 0.8898 - val_acc: 0.6000\n",
      "Epoch 372/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.5514 - acc: 0.8207 - val_loss: 0.8931 - val_acc: 0.5911\n",
      "Epoch 373/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.5459 - acc: 0.8163 - val_loss: 0.9024 - val_acc: 0.6133\n",
      "Epoch 374/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5677 - acc: 0.7941 - val_loss: 0.8965 - val_acc: 0.6489\n",
      "Epoch 375/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5324 - acc: 0.8341 - val_loss: 0.8963 - val_acc: 0.6267\n",
      "Epoch 376/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.5467 - acc: 0.8133 - val_loss: 0.8988 - val_acc: 0.6089\n",
      "Epoch 377/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.5425 - acc: 0.8133 - val_loss: 0.8785 - val_acc: 0.6178\n",
      "Epoch 378/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5517 - acc: 0.8030 - val_loss: 0.8764 - val_acc: 0.5822\n",
      "Epoch 379/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.5168 - acc: 0.8237 - val_loss: 0.8990 - val_acc: 0.6356\n",
      "Epoch 380/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.5526 - acc: 0.8133 - val_loss: 0.8768 - val_acc: 0.5956\n",
      "Epoch 381/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5463 - acc: 0.8059 - val_loss: 0.8938 - val_acc: 0.6356\n",
      "Epoch 382/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.5094 - acc: 0.8341 - val_loss: 0.8849 - val_acc: 0.5911\n",
      "Epoch 383/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.5519 - acc: 0.8000 - val_loss: 0.8925 - val_acc: 0.5956\n",
      "Epoch 384/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.5352 - acc: 0.8193 - val_loss: 0.8994 - val_acc: 0.6133\n",
      "Epoch 385/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.5521 - acc: 0.8074 - val_loss: 0.9024 - val_acc: 0.6400\n",
      "Epoch 386/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.5259 - acc: 0.8281 - val_loss: 0.8757 - val_acc: 0.5956\n",
      "Epoch 387/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.5409 - acc: 0.8207 - val_loss: 0.8826 - val_acc: 0.6178\n",
      "Epoch 388/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.5255 - acc: 0.8059 - val_loss: 0.8777 - val_acc: 0.6222\n",
      "Epoch 389/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.5275 - acc: 0.8296 - val_loss: 0.8876 - val_acc: 0.6533\n",
      "Epoch 390/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.5573 - acc: 0.8030 - val_loss: 0.8854 - val_acc: 0.6356\n",
      "Epoch 391/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.5308 - acc: 0.8237 - val_loss: 0.8793 - val_acc: 0.6044\n",
      "Epoch 392/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.5105 - acc: 0.8267 - val_loss: 0.8776 - val_acc: 0.6044\n",
      "Epoch 393/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.5354 - acc: 0.8163 - val_loss: 0.8759 - val_acc: 0.6000\n",
      "Epoch 394/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.5306 - acc: 0.8267 - val_loss: 0.8778 - val_acc: 0.6000\n",
      "Epoch 395/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.5250 - acc: 0.8030 - val_loss: 0.8701 - val_acc: 0.5911\n",
      "Epoch 396/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.5183 - acc: 0.8222 - val_loss: 0.8724 - val_acc: 0.6089\n",
      "Epoch 397/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.5372 - acc: 0.7970 - val_loss: 0.8834 - val_acc: 0.5778\n",
      "Epoch 398/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.5209 - acc: 0.8074 - val_loss: 0.8752 - val_acc: 0.6267\n",
      "Epoch 399/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.5107 - acc: 0.8237 - val_loss: 0.8717 - val_acc: 0.6178\n",
      "Epoch 400/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5241 - acc: 0.8385 - val_loss: 0.8813 - val_acc: 0.6222\n",
      "Epoch 401/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.5334 - acc: 0.8104 - val_loss: 0.8700 - val_acc: 0.6222\n",
      "Epoch 402/10000\n",
      "675/675 [==============================] - 0s 164us/step - loss: 0.5182 - acc: 0.8296 - val_loss: 0.8794 - val_acc: 0.6178\n",
      "Epoch 403/10000\n",
      "675/675 [==============================] - 0s 136us/step - loss: 0.5264 - acc: 0.8252 - val_loss: 0.8778 - val_acc: 0.6267\n",
      "Epoch 404/10000\n",
      "675/675 [==============================] - 0s 124us/step - loss: 0.5451 - acc: 0.8044 - val_loss: 0.8689 - val_acc: 0.6311\n",
      "Epoch 405/10000\n",
      "675/675 [==============================] - 0s 125us/step - loss: 0.5341 - acc: 0.8193 - val_loss: 0.8804 - val_acc: 0.6622\n",
      "Epoch 406/10000\n",
      "675/675 [==============================] - 0s 125us/step - loss: 0.5136 - acc: 0.8252 - val_loss: 0.8730 - val_acc: 0.5911\n",
      "Epoch 407/10000\n",
      "675/675 [==============================] - 0s 125us/step - loss: 0.5415 - acc: 0.8133 - val_loss: 0.8648 - val_acc: 0.6000\n",
      "Epoch 408/10000\n",
      "675/675 [==============================] - 0s 118us/step - loss: 0.5207 - acc: 0.8104 - val_loss: 0.8810 - val_acc: 0.6444\n",
      "Epoch 409/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 0.5362 - acc: 0.8237 - val_loss: 0.8803 - val_acc: 0.6000\n",
      "Epoch 410/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.4960 - acc: 0.8400 - val_loss: 0.8849 - val_acc: 0.6444\n",
      "Epoch 411/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.5381 - acc: 0.7970 - val_loss: 0.8733 - val_acc: 0.6311\n",
      "Epoch 412/10000\n",
      "675/675 [==============================] - 0s 110us/step - loss: 0.5159 - acc: 0.8104 - val_loss: 0.8827 - val_acc: 0.6622\n",
      "Epoch 413/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.5104 - acc: 0.8104 - val_loss: 0.8685 - val_acc: 0.6044\n",
      "Epoch 414/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 102us/step - loss: 0.4994 - acc: 0.8370 - val_loss: 0.8724 - val_acc: 0.6533\n",
      "Epoch 415/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.5380 - acc: 0.8044 - val_loss: 0.8820 - val_acc: 0.6356\n",
      "Epoch 416/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.5274 - acc: 0.8207 - val_loss: 0.8908 - val_acc: 0.6578\n",
      "Epoch 417/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.5223 - acc: 0.8089 - val_loss: 0.8731 - val_acc: 0.6356\n",
      "Epoch 418/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.5081 - acc: 0.8222 - val_loss: 0.8817 - val_acc: 0.6489\n",
      "Epoch 419/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5185 - acc: 0.8089 - val_loss: 0.8690 - val_acc: 0.6489\n",
      "Epoch 420/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.5112 - acc: 0.8311 - val_loss: 0.8616 - val_acc: 0.6089\n",
      "Epoch 421/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.5083 - acc: 0.8267 - val_loss: 0.8669 - val_acc: 0.6044\n",
      "Epoch 422/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 0.5226 - acc: 0.8207 - val_loss: 0.8950 - val_acc: 0.6533\n",
      "Epoch 423/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 0.5010 - acc: 0.8385 - val_loss: 0.8807 - val_acc: 0.6667\n",
      "Epoch 424/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.5159 - acc: 0.8281 - val_loss: 0.8682 - val_acc: 0.6667\n",
      "Epoch 425/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.5102 - acc: 0.8281 - val_loss: 0.8731 - val_acc: 0.6533\n",
      "Epoch 426/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.5153 - acc: 0.8178 - val_loss: 0.8725 - val_acc: 0.5911\n",
      "Epoch 427/10000\n",
      "675/675 [==============================] - 0s 111us/step - loss: 0.5082 - acc: 0.8148 - val_loss: 0.8799 - val_acc: 0.6489\n",
      "Epoch 428/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.5099 - acc: 0.8178 - val_loss: 0.8665 - val_acc: 0.6489\n",
      "Epoch 429/10000\n",
      "675/675 [==============================] - 0s 96us/step - loss: 0.4889 - acc: 0.8341 - val_loss: 0.8855 - val_acc: 0.6889\n",
      "Epoch 430/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.4976 - acc: 0.8207 - val_loss: 0.8630 - val_acc: 0.6133\n",
      "Epoch 431/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.4973 - acc: 0.8281 - val_loss: 0.8696 - val_acc: 0.6356\n",
      "Epoch 432/10000\n",
      "675/675 [==============================] - 0s 154us/step - loss: 0.5035 - acc: 0.8356 - val_loss: 0.8555 - val_acc: 0.6133\n",
      "Epoch 433/10000\n",
      "675/675 [==============================] - 0s 130us/step - loss: 0.5102 - acc: 0.8311 - val_loss: 0.8986 - val_acc: 0.6578\n",
      "Epoch 434/10000\n",
      "675/675 [==============================] - 0s 123us/step - loss: 0.5008 - acc: 0.8326 - val_loss: 0.8703 - val_acc: 0.6356\n",
      "Epoch 435/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 0.4821 - acc: 0.8356 - val_loss: 0.8670 - val_acc: 0.6400\n",
      "Epoch 436/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.4899 - acc: 0.8207 - val_loss: 0.8638 - val_acc: 0.6533\n",
      "Epoch 437/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.4877 - acc: 0.8504 - val_loss: 0.8596 - val_acc: 0.6578\n",
      "Epoch 438/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 0.4939 - acc: 0.8400 - val_loss: 0.8620 - val_acc: 0.6267\n",
      "Epoch 439/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 0.4880 - acc: 0.8370 - val_loss: 0.8653 - val_acc: 0.6489\n",
      "Epoch 440/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.4966 - acc: 0.8370 - val_loss: 0.8611 - val_acc: 0.6089\n",
      "Epoch 441/10000\n",
      "675/675 [==============================] - 0s 113us/step - loss: 0.5047 - acc: 0.8104 - val_loss: 0.8512 - val_acc: 0.6356\n",
      "Epoch 442/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.4830 - acc: 0.8370 - val_loss: 0.8510 - val_acc: 0.6578\n",
      "Epoch 443/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 0.4577 - acc: 0.8533 - val_loss: 0.8627 - val_acc: 0.6133\n",
      "Epoch 444/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.4859 - acc: 0.8311 - val_loss: 0.8564 - val_acc: 0.6356\n",
      "Epoch 445/10000\n",
      "675/675 [==============================] - 0s 116us/step - loss: 0.4940 - acc: 0.8237 - val_loss: 0.8713 - val_acc: 0.6933\n",
      "Epoch 446/10000\n",
      "675/675 [==============================] - 0s 111us/step - loss: 0.4979 - acc: 0.8267 - val_loss: 0.8683 - val_acc: 0.6533\n",
      "Epoch 447/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.4905 - acc: 0.8311 - val_loss: 0.8850 - val_acc: 0.6311\n",
      "Epoch 448/10000\n",
      "675/675 [==============================] - 0s 108us/step - loss: 0.4915 - acc: 0.8356 - val_loss: 0.8630 - val_acc: 0.5867\n",
      "Epoch 449/10000\n",
      "675/675 [==============================] - 0s 114us/step - loss: 0.5026 - acc: 0.8044 - val_loss: 0.8549 - val_acc: 0.6489\n",
      "Epoch 450/10000\n",
      "675/675 [==============================] - 0s 109us/step - loss: 0.4774 - acc: 0.8519 - val_loss: 0.8540 - val_acc: 0.6267\n",
      "Epoch 451/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.4859 - acc: 0.8400 - val_loss: 0.8567 - val_acc: 0.6311\n",
      "Epoch 452/10000\n",
      "675/675 [==============================] - 0s 104us/step - loss: 0.5292 - acc: 0.7837 - val_loss: 0.8545 - val_acc: 0.6311\n",
      "Epoch 453/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 0.4834 - acc: 0.8281 - val_loss: 0.8588 - val_acc: 0.6267\n",
      "Epoch 454/10000\n",
      "675/675 [==============================] - 0s 123us/step - loss: 0.4883 - acc: 0.8252 - val_loss: 0.8538 - val_acc: 0.6444\n",
      "Epoch 455/10000\n",
      "675/675 [==============================] - 0s 123us/step - loss: 0.4839 - acc: 0.8267 - val_loss: 0.8568 - val_acc: 0.6533\n",
      "Epoch 456/10000\n",
      "675/675 [==============================] - 0s 125us/step - loss: 0.4944 - acc: 0.8400 - val_loss: 0.8535 - val_acc: 0.6400\n",
      "Epoch 457/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 0.4849 - acc: 0.8296 - val_loss: 0.8507 - val_acc: 0.6756\n",
      "Epoch 458/10000\n",
      "675/675 [==============================] - 0s 111us/step - loss: 0.5011 - acc: 0.8207 - val_loss: 0.8578 - val_acc: 0.6356\n",
      "Epoch 459/10000\n",
      "675/675 [==============================] - 0s 119us/step - loss: 0.4729 - acc: 0.8267 - val_loss: 0.8704 - val_acc: 0.6756\n",
      "Epoch 460/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 0.4930 - acc: 0.8400 - val_loss: 0.8508 - val_acc: 0.6400\n",
      "Epoch 461/10000\n",
      "675/675 [==============================] - 0s 106us/step - loss: 0.4861 - acc: 0.8385 - val_loss: 0.8606 - val_acc: 0.6889\n",
      "Epoch 462/10000\n",
      "675/675 [==============================] - 0s 118us/step - loss: 0.4864 - acc: 0.8296 - val_loss: 0.8715 - val_acc: 0.6844\n",
      "Epoch 463/10000\n",
      "675/675 [==============================] - 0s 117us/step - loss: 0.4937 - acc: 0.8252 - val_loss: 0.8486 - val_acc: 0.6400\n",
      "Epoch 464/10000\n",
      "675/675 [==============================] - 0s 121us/step - loss: 0.4638 - acc: 0.8400 - val_loss: 0.8427 - val_acc: 0.6489\n",
      "Epoch 465/10000\n",
      "675/675 [==============================] - 0s 116us/step - loss: 0.4890 - acc: 0.8341 - val_loss: 0.8687 - val_acc: 0.6800\n",
      "Epoch 466/10000\n",
      "675/675 [==============================] - 0s 115us/step - loss: 0.4916 - acc: 0.8281 - val_loss: 0.8604 - val_acc: 0.6356\n",
      "Epoch 467/10000\n",
      "675/675 [==============================] - 0s 109us/step - loss: 0.4961 - acc: 0.8222 - val_loss: 0.8470 - val_acc: 0.6444\n",
      "Epoch 468/10000\n",
      "675/675 [==============================] - 0s 100us/step - loss: 0.4601 - acc: 0.8533 - val_loss: 0.8453 - val_acc: 0.6356\n",
      "Epoch 469/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.4953 - acc: 0.8296 - val_loss: 0.8462 - val_acc: 0.6533\n",
      "Epoch 470/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.4743 - acc: 0.8400 - val_loss: 0.8564 - val_acc: 0.6578\n",
      "Epoch 471/10000\n",
      "675/675 [==============================] - 0s 256us/step - loss: 0.4674 - acc: 0.8341 - val_loss: 0.8521 - val_acc: 0.6444\n",
      "Epoch 472/10000\n",
      "675/675 [==============================] - 0s 165us/step - loss: 0.4872 - acc: 0.8252 - val_loss: 0.8529 - val_acc: 0.6222\n",
      "Epoch 473/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 141us/step - loss: 0.4623 - acc: 0.8444 - val_loss: 0.8610 - val_acc: 0.6978\n",
      "Epoch 474/10000\n",
      "675/675 [==============================] - 0s 137us/step - loss: 0.4518 - acc: 0.8444 - val_loss: 0.8423 - val_acc: 0.6622\n",
      "Epoch 475/10000\n",
      "675/675 [==============================] - 0s 123us/step - loss: 0.4766 - acc: 0.8326 - val_loss: 0.8501 - val_acc: 0.6311\n",
      "Epoch 476/10000\n",
      "675/675 [==============================] - 0s 158us/step - loss: 0.4790 - acc: 0.8474 - val_loss: 0.8540 - val_acc: 0.6800\n",
      "Epoch 477/10000\n",
      "675/675 [==============================] - 0s 125us/step - loss: 0.4975 - acc: 0.8311 - val_loss: 0.8556 - val_acc: 0.6978\n",
      "Epoch 478/10000\n",
      "675/675 [==============================] - 0s 157us/step - loss: 0.4829 - acc: 0.8385 - val_loss: 0.8535 - val_acc: 0.7022\n",
      "Epoch 479/10000\n",
      "675/675 [==============================] - 0s 113us/step - loss: 0.4489 - acc: 0.8444 - val_loss: 0.8667 - val_acc: 0.6933\n",
      "Epoch 480/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.4738 - acc: 0.8281 - val_loss: 0.8587 - val_acc: 0.6889\n",
      "Epoch 481/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4925 - acc: 0.8237 - val_loss: 0.8469 - val_acc: 0.6311\n",
      "Epoch 482/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4684 - acc: 0.8489 - val_loss: 0.8346 - val_acc: 0.6667\n",
      "Epoch 483/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4505 - acc: 0.8400 - val_loss: 0.8501 - val_acc: 0.6889\n",
      "Epoch 484/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4689 - acc: 0.8489 - val_loss: 0.8476 - val_acc: 0.6489\n",
      "Epoch 485/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4444 - acc: 0.8474 - val_loss: 0.8576 - val_acc: 0.6533\n",
      "Epoch 486/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4511 - acc: 0.8489 - val_loss: 0.8493 - val_acc: 0.6756\n",
      "Epoch 487/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4528 - acc: 0.8533 - val_loss: 0.8504 - val_acc: 0.6756\n",
      "Epoch 488/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4475 - acc: 0.8474 - val_loss: 0.8462 - val_acc: 0.6222\n",
      "Epoch 489/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4511 - acc: 0.8578 - val_loss: 0.8431 - val_acc: 0.6489\n",
      "Epoch 490/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.4664 - acc: 0.8296 - val_loss: 0.8446 - val_acc: 0.6800\n",
      "Epoch 491/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.4810 - acc: 0.8267 - val_loss: 0.8364 - val_acc: 0.6267\n",
      "Epoch 492/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4562 - acc: 0.8444 - val_loss: 0.8602 - val_acc: 0.6978\n",
      "Epoch 493/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.4522 - acc: 0.8548 - val_loss: 0.8466 - val_acc: 0.6933\n",
      "Epoch 494/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.4748 - acc: 0.8385 - val_loss: 0.8513 - val_acc: 0.7067\n",
      "Epoch 495/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4768 - acc: 0.8237 - val_loss: 0.8478 - val_acc: 0.6889\n",
      "Epoch 496/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4699 - acc: 0.8370 - val_loss: 0.8564 - val_acc: 0.7067\n",
      "Epoch 497/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4722 - acc: 0.8474 - val_loss: 0.8367 - val_acc: 0.6578\n",
      "Epoch 498/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4522 - acc: 0.8370 - val_loss: 0.8319 - val_acc: 0.6444\n",
      "Epoch 499/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.4789 - acc: 0.8326 - val_loss: 0.8413 - val_acc: 0.6844\n",
      "Epoch 500/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4478 - acc: 0.8311 - val_loss: 0.8506 - val_acc: 0.6933\n",
      "Epoch 501/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4382 - acc: 0.8489 - val_loss: 0.8571 - val_acc: 0.6133\n",
      "Epoch 502/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4512 - acc: 0.8370 - val_loss: 0.8427 - val_acc: 0.6756\n",
      "Epoch 503/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4580 - acc: 0.8430 - val_loss: 0.8382 - val_acc: 0.6578\n",
      "Epoch 504/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4632 - acc: 0.8267 - val_loss: 0.8415 - val_acc: 0.6933\n",
      "Epoch 505/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4436 - acc: 0.8400 - val_loss: 0.8337 - val_acc: 0.6622\n",
      "Epoch 506/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.4626 - acc: 0.8326 - val_loss: 0.8317 - val_acc: 0.6844\n",
      "Epoch 507/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4749 - acc: 0.8370 - val_loss: 0.8291 - val_acc: 0.6800\n",
      "Epoch 508/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4498 - acc: 0.8326 - val_loss: 0.8480 - val_acc: 0.6889\n",
      "Epoch 509/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4539 - acc: 0.8459 - val_loss: 0.8702 - val_acc: 0.7067\n",
      "Epoch 510/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4739 - acc: 0.8267 - val_loss: 0.8445 - val_acc: 0.6800\n",
      "Epoch 511/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4299 - acc: 0.8578 - val_loss: 0.8328 - val_acc: 0.6933\n",
      "Epoch 512/10000\n",
      "675/675 [==============================] - 0s 81us/step - loss: 0.4297 - acc: 0.8548 - val_loss: 0.8353 - val_acc: 0.6400\n",
      "Epoch 513/10000\n",
      "675/675 [==============================] - 0s 81us/step - loss: 0.4488 - acc: 0.8430 - val_loss: 0.8299 - val_acc: 0.6622\n",
      "Epoch 514/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4514 - acc: 0.8356 - val_loss: 0.8309 - val_acc: 0.6978\n",
      "Epoch 515/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4676 - acc: 0.8296 - val_loss: 0.8356 - val_acc: 0.7022\n",
      "Epoch 516/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4618 - acc: 0.8593 - val_loss: 0.8221 - val_acc: 0.6711\n",
      "Epoch 517/10000\n",
      "675/675 [==============================] - 0s 81us/step - loss: 0.4553 - acc: 0.8400 - val_loss: 0.8396 - val_acc: 0.7022\n",
      "Epoch 518/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4474 - acc: 0.8563 - val_loss: 0.8365 - val_acc: 0.6889\n",
      "Epoch 519/10000\n",
      "675/675 [==============================] - 0s 81us/step - loss: 0.4513 - acc: 0.8237 - val_loss: 0.8369 - val_acc: 0.6533\n",
      "Epoch 520/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4319 - acc: 0.8578 - val_loss: 0.8343 - val_acc: 0.6667\n",
      "Epoch 521/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4325 - acc: 0.8504 - val_loss: 0.8271 - val_acc: 0.6978\n",
      "Epoch 522/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4370 - acc: 0.8444 - val_loss: 0.8419 - val_acc: 0.7022\n",
      "Epoch 523/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4443 - acc: 0.8533 - val_loss: 0.8417 - val_acc: 0.6889\n",
      "Epoch 524/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4476 - acc: 0.8385 - val_loss: 0.8342 - val_acc: 0.6800\n",
      "Epoch 525/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4390 - acc: 0.8400 - val_loss: 0.8369 - val_acc: 0.6711\n",
      "Epoch 526/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4398 - acc: 0.8444 - val_loss: 0.8417 - val_acc: 0.7022\n",
      "Epoch 527/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4284 - acc: 0.8578 - val_loss: 0.8293 - val_acc: 0.6978\n",
      "Epoch 528/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.4627 - acc: 0.8385 - val_loss: 0.8126 - val_acc: 0.6889\n",
      "Epoch 529/10000\n",
      "675/675 [==============================] - 0s 116us/step - loss: 0.4162 - acc: 0.8726 - val_loss: 0.8212 - val_acc: 0.6578\n",
      "Epoch 530/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4349 - acc: 0.8681 - val_loss: 0.8267 - val_acc: 0.6489\n",
      "Epoch 531/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.4373 - acc: 0.8519 - val_loss: 0.8260 - val_acc: 0.6711\n",
      "Epoch 532/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 84us/step - loss: 0.4337 - acc: 0.8326 - val_loss: 0.8543 - val_acc: 0.6933\n",
      "Epoch 533/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4469 - acc: 0.8444 - val_loss: 0.8275 - val_acc: 0.6667\n",
      "Epoch 534/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4336 - acc: 0.8548 - val_loss: 0.8183 - val_acc: 0.6711\n",
      "Epoch 535/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.4113 - acc: 0.8533 - val_loss: 0.8269 - val_acc: 0.6933\n",
      "Epoch 536/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.4252 - acc: 0.8504 - val_loss: 0.8455 - val_acc: 0.7067\n",
      "Epoch 537/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.4426 - acc: 0.8504 - val_loss: 0.8151 - val_acc: 0.6800\n",
      "Epoch 538/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.4333 - acc: 0.8489 - val_loss: 0.8282 - val_acc: 0.6933\n",
      "Epoch 539/10000\n",
      "675/675 [==============================] - 0s 102us/step - loss: 0.4340 - acc: 0.8519 - val_loss: 0.8292 - val_acc: 0.6756\n",
      "Epoch 540/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.4411 - acc: 0.8563 - val_loss: 0.8293 - val_acc: 0.6844\n",
      "Epoch 541/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.4379 - acc: 0.8356 - val_loss: 0.8375 - val_acc: 0.7156\n",
      "Epoch 542/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.4215 - acc: 0.8519 - val_loss: 0.8233 - val_acc: 0.6667\n",
      "Epoch 543/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.4510 - acc: 0.8430 - val_loss: 0.8410 - val_acc: 0.7022\n",
      "Epoch 544/10000\n",
      "675/675 [==============================] - 0s 99us/step - loss: 0.4378 - acc: 0.8519 - val_loss: 0.8407 - val_acc: 0.6889\n",
      "Epoch 545/10000\n",
      "675/675 [==============================] - 0s 101us/step - loss: 0.4395 - acc: 0.8430 - val_loss: 0.8111 - val_acc: 0.6533\n",
      "Epoch 546/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4463 - acc: 0.8444 - val_loss: 0.8180 - val_acc: 0.7067\n",
      "Epoch 547/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4289 - acc: 0.8415 - val_loss: 0.8146 - val_acc: 0.6711\n",
      "Epoch 548/10000\n",
      "675/675 [==============================] - 0s 98us/step - loss: 0.4077 - acc: 0.8593 - val_loss: 0.8275 - val_acc: 0.7022\n",
      "Epoch 549/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.4483 - acc: 0.8474 - val_loss: 0.8204 - val_acc: 0.6800\n",
      "Epoch 550/10000\n",
      "675/675 [==============================] - 0s 97us/step - loss: 0.4238 - acc: 0.8607 - val_loss: 0.8338 - val_acc: 0.7022\n",
      "Epoch 551/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.4337 - acc: 0.8607 - val_loss: 0.8254 - val_acc: 0.6933\n",
      "Epoch 552/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.4475 - acc: 0.8311 - val_loss: 0.8251 - val_acc: 0.7022\n",
      "Epoch 553/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3927 - acc: 0.8800 - val_loss: 0.8339 - val_acc: 0.6978\n",
      "Epoch 554/10000\n",
      "675/675 [==============================] - 0s 107us/step - loss: 0.4514 - acc: 0.8370 - val_loss: 0.8275 - val_acc: 0.6667\n",
      "Epoch 555/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.4091 - acc: 0.8607 - val_loss: 0.8170 - val_acc: 0.6711\n",
      "Epoch 556/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.4297 - acc: 0.8326 - val_loss: 0.8326 - val_acc: 0.6533\n",
      "Epoch 557/10000\n",
      "675/675 [==============================] - 0s 103us/step - loss: 0.4231 - acc: 0.8593 - val_loss: 0.8400 - val_acc: 0.7022\n",
      "Epoch 558/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.4071 - acc: 0.8815 - val_loss: 0.8179 - val_acc: 0.7156\n",
      "Epoch 559/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.4302 - acc: 0.8519 - val_loss: 0.8306 - val_acc: 0.7022\n",
      "Epoch 560/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.4147 - acc: 0.8622 - val_loss: 0.8260 - val_acc: 0.7111\n",
      "Epoch 561/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.4188 - acc: 0.8400 - val_loss: 0.8155 - val_acc: 0.7111\n",
      "Epoch 562/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4634 - acc: 0.8163 - val_loss: 0.8453 - val_acc: 0.6889\n",
      "Epoch 563/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4366 - acc: 0.8489 - val_loss: 0.8173 - val_acc: 0.6844\n",
      "Epoch 564/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4108 - acc: 0.8696 - val_loss: 0.8175 - val_acc: 0.6578\n",
      "Epoch 565/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4296 - acc: 0.8681 - val_loss: 0.8379 - val_acc: 0.6889\n",
      "Epoch 566/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4468 - acc: 0.8430 - val_loss: 0.8199 - val_acc: 0.6711\n",
      "Epoch 567/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4257 - acc: 0.8370 - val_loss: 0.8347 - val_acc: 0.6978\n",
      "Epoch 568/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4179 - acc: 0.8444 - val_loss: 0.8204 - val_acc: 0.7022\n",
      "Epoch 569/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4211 - acc: 0.8548 - val_loss: 0.8255 - val_acc: 0.6400\n",
      "Epoch 570/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4199 - acc: 0.8296 - val_loss: 0.8172 - val_acc: 0.6889\n",
      "Epoch 571/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4080 - acc: 0.8652 - val_loss: 0.8312 - val_acc: 0.6933\n",
      "Epoch 572/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4275 - acc: 0.8370 - val_loss: 0.8369 - val_acc: 0.6622\n",
      "Epoch 573/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4272 - acc: 0.8489 - val_loss: 0.8272 - val_acc: 0.6800\n",
      "Epoch 574/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4327 - acc: 0.8385 - val_loss: 0.8350 - val_acc: 0.6889\n",
      "Epoch 575/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4246 - acc: 0.8356 - val_loss: 0.8211 - val_acc: 0.6844\n",
      "Epoch 576/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4134 - acc: 0.8504 - val_loss: 0.8232 - val_acc: 0.6533\n",
      "Epoch 577/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4168 - acc: 0.8563 - val_loss: 0.8255 - val_acc: 0.6756\n",
      "Epoch 578/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4189 - acc: 0.8519 - val_loss: 0.8177 - val_acc: 0.6933\n",
      "Epoch 579/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4205 - acc: 0.8459 - val_loss: 0.8397 - val_acc: 0.6933\n",
      "Epoch 580/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.4111 - acc: 0.8563 - val_loss: 0.8091 - val_acc: 0.6756\n",
      "Epoch 581/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4271 - acc: 0.8415 - val_loss: 0.8200 - val_acc: 0.7067\n",
      "Epoch 582/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4424 - acc: 0.8459 - val_loss: 0.8440 - val_acc: 0.6844\n",
      "Epoch 583/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4166 - acc: 0.8489 - val_loss: 0.8473 - val_acc: 0.6800\n",
      "Epoch 584/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4384 - acc: 0.8370 - val_loss: 0.8170 - val_acc: 0.6533\n",
      "Epoch 585/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4339 - acc: 0.8341 - val_loss: 0.8181 - val_acc: 0.6578\n",
      "Epoch 586/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.4014 - acc: 0.8459 - val_loss: 0.8052 - val_acc: 0.6889\n",
      "Epoch 587/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.4166 - acc: 0.8519 - val_loss: 0.8082 - val_acc: 0.6978\n",
      "Epoch 588/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4263 - acc: 0.8637 - val_loss: 0.8177 - val_acc: 0.6489\n",
      "Epoch 589/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4466 - acc: 0.8341 - val_loss: 0.8107 - val_acc: 0.6756\n",
      "Epoch 590/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4205 - acc: 0.8489 - val_loss: 0.8107 - val_acc: 0.6889\n",
      "Epoch 591/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 86us/step - loss: 0.4182 - acc: 0.8637 - val_loss: 0.8077 - val_acc: 0.7022\n",
      "Epoch 592/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3958 - acc: 0.8726 - val_loss: 0.8130 - val_acc: 0.6578\n",
      "Epoch 593/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.4095 - acc: 0.8489 - val_loss: 0.8061 - val_acc: 0.6533\n",
      "Epoch 594/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4004 - acc: 0.8622 - val_loss: 0.8058 - val_acc: 0.6800\n",
      "Epoch 595/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4049 - acc: 0.8667 - val_loss: 0.8128 - val_acc: 0.6622\n",
      "Epoch 596/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.4031 - acc: 0.8785 - val_loss: 0.8189 - val_acc: 0.7067\n",
      "Epoch 597/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3973 - acc: 0.8563 - val_loss: 0.8121 - val_acc: 0.6933\n",
      "Epoch 598/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4189 - acc: 0.8489 - val_loss: 0.8166 - val_acc: 0.7067\n",
      "Epoch 599/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3915 - acc: 0.8741 - val_loss: 0.8318 - val_acc: 0.7111\n",
      "Epoch 600/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4187 - acc: 0.8548 - val_loss: 0.8170 - val_acc: 0.6844\n",
      "Epoch 601/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4295 - acc: 0.8267 - val_loss: 0.8259 - val_acc: 0.6978\n",
      "Epoch 602/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3888 - acc: 0.8622 - val_loss: 0.8178 - val_acc: 0.6489\n",
      "Epoch 603/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3922 - acc: 0.8607 - val_loss: 0.8149 - val_acc: 0.7067\n",
      "Epoch 604/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4391 - acc: 0.8252 - val_loss: 0.8198 - val_acc: 0.7022\n",
      "Epoch 605/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3960 - acc: 0.8652 - val_loss: 0.8041 - val_acc: 0.7111\n",
      "Epoch 606/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.4092 - acc: 0.8533 - val_loss: 0.8032 - val_acc: 0.7111\n",
      "Epoch 607/10000\n",
      "675/675 [==============================] - 0s 132us/step - loss: 0.3934 - acc: 0.8770 - val_loss: 0.8129 - val_acc: 0.7200\n",
      "Epoch 608/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4339 - acc: 0.8504 - val_loss: 0.8312 - val_acc: 0.6844\n",
      "Epoch 609/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4334 - acc: 0.8385 - val_loss: 0.8048 - val_acc: 0.7111\n",
      "Epoch 610/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3839 - acc: 0.8637 - val_loss: 0.8021 - val_acc: 0.7111\n",
      "Epoch 611/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4083 - acc: 0.8489 - val_loss: 0.8113 - val_acc: 0.7067\n",
      "Epoch 612/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3904 - acc: 0.8593 - val_loss: 0.8303 - val_acc: 0.6978\n",
      "Epoch 613/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3961 - acc: 0.8533 - val_loss: 0.8012 - val_acc: 0.6978\n",
      "Epoch 614/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4005 - acc: 0.8785 - val_loss: 0.8019 - val_acc: 0.6978\n",
      "Epoch 615/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4117 - acc: 0.8474 - val_loss: 0.8203 - val_acc: 0.7022\n",
      "Epoch 616/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.4047 - acc: 0.8622 - val_loss: 0.8171 - val_acc: 0.6933\n",
      "Epoch 617/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3976 - acc: 0.8711 - val_loss: 0.8030 - val_acc: 0.7022\n",
      "Epoch 618/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4047 - acc: 0.8444 - val_loss: 0.7997 - val_acc: 0.6844\n",
      "Epoch 619/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3935 - acc: 0.8696 - val_loss: 0.8387 - val_acc: 0.6978\n",
      "Epoch 620/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.4207 - acc: 0.8563 - val_loss: 0.8291 - val_acc: 0.6756\n",
      "Epoch 621/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4022 - acc: 0.8593 - val_loss: 0.8160 - val_acc: 0.6711\n",
      "Epoch 622/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.4019 - acc: 0.8593 - val_loss: 0.8159 - val_acc: 0.7111\n",
      "Epoch 623/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.3985 - acc: 0.8711 - val_loss: 0.8110 - val_acc: 0.7022\n",
      "Epoch 624/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4077 - acc: 0.8548 - val_loss: 0.8057 - val_acc: 0.6578\n",
      "Epoch 625/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4001 - acc: 0.8578 - val_loss: 0.8264 - val_acc: 0.6622\n",
      "Epoch 626/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4062 - acc: 0.8444 - val_loss: 0.8267 - val_acc: 0.6756\n",
      "Epoch 627/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4197 - acc: 0.8400 - val_loss: 0.8245 - val_acc: 0.6978\n",
      "Epoch 628/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4258 - acc: 0.8444 - val_loss: 0.8214 - val_acc: 0.6978\n",
      "Epoch 629/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4017 - acc: 0.8548 - val_loss: 0.8171 - val_acc: 0.6533\n",
      "Epoch 630/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3978 - acc: 0.8637 - val_loss: 0.8168 - val_acc: 0.6711\n",
      "Epoch 631/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4606 - acc: 0.8296 - val_loss: 0.8129 - val_acc: 0.6933\n",
      "Epoch 632/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3824 - acc: 0.8696 - val_loss: 0.8052 - val_acc: 0.7200\n",
      "Epoch 633/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3904 - acc: 0.8622 - val_loss: 0.8139 - val_acc: 0.6578\n",
      "Epoch 634/10000\n",
      "675/675 [==============================] - 0s 95us/step - loss: 0.3973 - acc: 0.8622 - val_loss: 0.8037 - val_acc: 0.6711\n",
      "Epoch 635/10000\n",
      "675/675 [==============================] - 0s 105us/step - loss: 0.3907 - acc: 0.8681 - val_loss: 0.8005 - val_acc: 0.6800\n",
      "Epoch 636/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3913 - acc: 0.8519 - val_loss: 0.8014 - val_acc: 0.7067\n",
      "Epoch 637/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.3711 - acc: 0.8859 - val_loss: 0.7925 - val_acc: 0.7022\n",
      "Epoch 638/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3807 - acc: 0.8681 - val_loss: 0.7954 - val_acc: 0.7111\n",
      "Epoch 639/10000\n",
      "675/675 [==============================] - 0s 94us/step - loss: 0.4048 - acc: 0.8504 - val_loss: 0.8071 - val_acc: 0.7111\n",
      "Epoch 640/10000\n",
      "675/675 [==============================] - 0s 124us/step - loss: 0.4143 - acc: 0.8356 - val_loss: 0.7946 - val_acc: 0.7289\n",
      "Epoch 641/10000\n",
      "675/675 [==============================] - 0s 116us/step - loss: 0.4082 - acc: 0.8667 - val_loss: 0.8091 - val_acc: 0.7111\n",
      "Epoch 642/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3918 - acc: 0.8726 - val_loss: 0.8060 - val_acc: 0.7156\n",
      "Epoch 643/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3760 - acc: 0.8681 - val_loss: 0.7904 - val_acc: 0.7156\n",
      "Epoch 644/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3763 - acc: 0.8770 - val_loss: 0.8009 - val_acc: 0.6578\n",
      "Epoch 645/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3857 - acc: 0.8667 - val_loss: 0.8053 - val_acc: 0.6711\n",
      "Epoch 646/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.3763 - acc: 0.8800 - val_loss: 0.8115 - val_acc: 0.6578\n",
      "Epoch 647/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3912 - acc: 0.8533 - val_loss: 0.8093 - val_acc: 0.7156\n",
      "Epoch 648/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.3898 - acc: 0.8756 - val_loss: 0.8234 - val_acc: 0.7111\n",
      "Epoch 649/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.3961 - acc: 0.8593 - val_loss: 0.8155 - val_acc: 0.7156\n",
      "Epoch 650/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 89us/step - loss: 0.3861 - acc: 0.8578 - val_loss: 0.8135 - val_acc: 0.7022\n",
      "Epoch 651/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.4195 - acc: 0.8400 - val_loss: 0.8231 - val_acc: 0.6978\n",
      "Epoch 652/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3913 - acc: 0.8667 - val_loss: 0.8084 - val_acc: 0.6844\n",
      "Epoch 653/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3581 - acc: 0.8770 - val_loss: 0.8131 - val_acc: 0.7111\n",
      "Epoch 654/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4142 - acc: 0.8459 - val_loss: 0.8194 - val_acc: 0.7067\n",
      "Epoch 655/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3737 - acc: 0.8681 - val_loss: 0.8077 - val_acc: 0.7022\n",
      "Epoch 656/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.4028 - acc: 0.8726 - val_loss: 0.8405 - val_acc: 0.6356\n",
      "Epoch 657/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3768 - acc: 0.8652 - val_loss: 0.8104 - val_acc: 0.6844\n",
      "Epoch 658/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.4123 - acc: 0.8400 - val_loss: 0.8206 - val_acc: 0.6711\n",
      "Epoch 659/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4006 - acc: 0.8400 - val_loss: 0.8177 - val_acc: 0.7022\n",
      "Epoch 660/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4005 - acc: 0.8607 - val_loss: 0.7881 - val_acc: 0.7067\n",
      "Epoch 661/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4368 - acc: 0.8281 - val_loss: 0.8063 - val_acc: 0.6889\n",
      "Epoch 662/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3797 - acc: 0.8607 - val_loss: 0.8041 - val_acc: 0.7156\n",
      "Epoch 663/10000\n",
      "675/675 [==============================] - 0s 81us/step - loss: 0.3785 - acc: 0.8652 - val_loss: 0.7986 - val_acc: 0.7156\n",
      "Epoch 664/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3903 - acc: 0.8519 - val_loss: 0.8249 - val_acc: 0.6578\n",
      "Epoch 665/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3945 - acc: 0.8563 - val_loss: 0.8100 - val_acc: 0.7200\n",
      "Epoch 666/10000\n",
      "675/675 [==============================] - 0s 81us/step - loss: 0.3963 - acc: 0.8415 - val_loss: 0.8150 - val_acc: 0.7111\n",
      "Epoch 667/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.4112 - acc: 0.8356 - val_loss: 0.8080 - val_acc: 0.7022\n",
      "Epoch 668/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3842 - acc: 0.8622 - val_loss: 0.8282 - val_acc: 0.6844\n",
      "Epoch 669/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.3985 - acc: 0.8652 - val_loss: 0.8082 - val_acc: 0.6533\n",
      "Epoch 670/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3786 - acc: 0.8711 - val_loss: 0.8135 - val_acc: 0.7156\n",
      "Epoch 671/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.4066 - acc: 0.8667 - val_loss: 0.8103 - val_acc: 0.6978\n",
      "Epoch 672/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3906 - acc: 0.8607 - val_loss: 0.8083 - val_acc: 0.7111\n",
      "Epoch 673/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3905 - acc: 0.8504 - val_loss: 0.7867 - val_acc: 0.7111\n",
      "Epoch 674/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3954 - acc: 0.8593 - val_loss: 0.7855 - val_acc: 0.7200\n",
      "Epoch 675/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3812 - acc: 0.8667 - val_loss: 0.7921 - val_acc: 0.6844\n",
      "Epoch 676/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3933 - acc: 0.8533 - val_loss: 0.7940 - val_acc: 0.6978\n",
      "Epoch 677/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3778 - acc: 0.8711 - val_loss: 0.7984 - val_acc: 0.7200\n",
      "Epoch 678/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3922 - acc: 0.8533 - val_loss: 0.8178 - val_acc: 0.7156\n",
      "Epoch 679/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3669 - acc: 0.8726 - val_loss: 0.7947 - val_acc: 0.7067\n",
      "Epoch 680/10000\n",
      "675/675 [==============================] - 0s 81us/step - loss: 0.3765 - acc: 0.8741 - val_loss: 0.8033 - val_acc: 0.7067\n",
      "Epoch 681/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3920 - acc: 0.8637 - val_loss: 0.8045 - val_acc: 0.7067\n",
      "Epoch 682/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3853 - acc: 0.8519 - val_loss: 0.7903 - val_acc: 0.7022\n",
      "Epoch 683/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4065 - acc: 0.8385 - val_loss: 0.8052 - val_acc: 0.7111\n",
      "Epoch 684/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3659 - acc: 0.8815 - val_loss: 0.7978 - val_acc: 0.6711\n",
      "Epoch 685/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3908 - acc: 0.8533 - val_loss: 0.8017 - val_acc: 0.7022\n",
      "Epoch 686/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3869 - acc: 0.8770 - val_loss: 0.8095 - val_acc: 0.7022\n",
      "Epoch 687/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3678 - acc: 0.8667 - val_loss: 0.8219 - val_acc: 0.6444\n",
      "Epoch 688/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4003 - acc: 0.8474 - val_loss: 0.8025 - val_acc: 0.6711\n",
      "Epoch 689/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3809 - acc: 0.8578 - val_loss: 0.8281 - val_acc: 0.7244\n",
      "Epoch 690/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3745 - acc: 0.8711 - val_loss: 0.8081 - val_acc: 0.7200\n",
      "Epoch 691/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3750 - acc: 0.8622 - val_loss: 0.8167 - val_acc: 0.7111\n",
      "Epoch 692/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3820 - acc: 0.8519 - val_loss: 0.7922 - val_acc: 0.6978\n",
      "Epoch 693/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3816 - acc: 0.8622 - val_loss: 0.8030 - val_acc: 0.6978\n",
      "Epoch 694/10000\n",
      "675/675 [==============================] - 0s 81us/step - loss: 0.3601 - acc: 0.8578 - val_loss: 0.7942 - val_acc: 0.6844\n",
      "Epoch 695/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3993 - acc: 0.8563 - val_loss: 0.8042 - val_acc: 0.7200\n",
      "Epoch 696/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4023 - acc: 0.8578 - val_loss: 0.7868 - val_acc: 0.7022\n",
      "Epoch 697/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4015 - acc: 0.8593 - val_loss: 0.7993 - val_acc: 0.6978\n",
      "Epoch 698/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3959 - acc: 0.8489 - val_loss: 0.7990 - val_acc: 0.7156\n",
      "Epoch 699/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3752 - acc: 0.8622 - val_loss: 0.7976 - val_acc: 0.7244\n",
      "Epoch 700/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4011 - acc: 0.8563 - val_loss: 0.8111 - val_acc: 0.6444\n",
      "Epoch 701/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3740 - acc: 0.8800 - val_loss: 0.8095 - val_acc: 0.7067\n",
      "Epoch 702/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3863 - acc: 0.8652 - val_loss: 0.8080 - val_acc: 0.6844\n",
      "Epoch 703/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3909 - acc: 0.8489 - val_loss: 0.8009 - val_acc: 0.6978\n",
      "Epoch 704/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.4038 - acc: 0.8607 - val_loss: 0.8011 - val_acc: 0.7022\n",
      "Epoch 705/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3887 - acc: 0.8430 - val_loss: 0.7902 - val_acc: 0.7067\n",
      "Epoch 706/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3825 - acc: 0.8548 - val_loss: 0.8158 - val_acc: 0.7067\n",
      "Epoch 707/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.4035 - acc: 0.8444 - val_loss: 0.8271 - val_acc: 0.6889\n",
      "Epoch 708/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3951 - acc: 0.8563 - val_loss: 0.7994 - val_acc: 0.7022\n",
      "Epoch 709/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 93us/step - loss: 0.3905 - acc: 0.8681 - val_loss: 0.8036 - val_acc: 0.7111\n",
      "Epoch 710/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3893 - acc: 0.8607 - val_loss: 0.8184 - val_acc: 0.7067\n",
      "Epoch 711/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3878 - acc: 0.8504 - val_loss: 0.8230 - val_acc: 0.6667\n",
      "Epoch 712/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3852 - acc: 0.8696 - val_loss: 0.7946 - val_acc: 0.7111\n",
      "Epoch 713/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3956 - acc: 0.8622 - val_loss: 0.8136 - val_acc: 0.7067\n",
      "Epoch 714/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3505 - acc: 0.8726 - val_loss: 0.8065 - val_acc: 0.6844\n",
      "Epoch 715/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3911 - acc: 0.8415 - val_loss: 0.8097 - val_acc: 0.7067\n",
      "Epoch 716/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3622 - acc: 0.8726 - val_loss: 0.8036 - val_acc: 0.7200\n",
      "Epoch 717/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3984 - acc: 0.8504 - val_loss: 0.8003 - val_acc: 0.7289\n",
      "Epoch 718/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3648 - acc: 0.8696 - val_loss: 0.8095 - val_acc: 0.6978\n",
      "Epoch 719/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3328 - acc: 0.9037 - val_loss: 0.8075 - val_acc: 0.6889\n",
      "Epoch 720/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3679 - acc: 0.8770 - val_loss: 0.8263 - val_acc: 0.7022\n",
      "Epoch 721/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3569 - acc: 0.8815 - val_loss: 0.8125 - val_acc: 0.7022\n",
      "Epoch 722/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3912 - acc: 0.8726 - val_loss: 0.8010 - val_acc: 0.7022\n",
      "Epoch 723/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3813 - acc: 0.8681 - val_loss: 0.7938 - val_acc: 0.6800\n",
      "Epoch 724/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3805 - acc: 0.8504 - val_loss: 0.8003 - val_acc: 0.7200\n",
      "Epoch 725/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.4005 - acc: 0.8533 - val_loss: 0.8140 - val_acc: 0.7067\n",
      "Epoch 726/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3554 - acc: 0.8815 - val_loss: 0.8105 - val_acc: 0.7022\n",
      "Epoch 727/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3436 - acc: 0.8741 - val_loss: 0.7993 - val_acc: 0.7156\n",
      "Epoch 728/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3875 - acc: 0.8548 - val_loss: 0.8070 - val_acc: 0.7067\n",
      "Epoch 729/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3589 - acc: 0.8741 - val_loss: 0.8286 - val_acc: 0.7067\n",
      "Epoch 730/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3610 - acc: 0.8830 - val_loss: 0.7861 - val_acc: 0.7244\n",
      "Epoch 731/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3660 - acc: 0.8741 - val_loss: 0.7945 - val_acc: 0.7200\n",
      "Epoch 732/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3767 - acc: 0.8548 - val_loss: 0.8103 - val_acc: 0.7022\n",
      "Epoch 733/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3996 - acc: 0.8430 - val_loss: 0.8035 - val_acc: 0.6711\n",
      "Epoch 734/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3696 - acc: 0.8563 - val_loss: 0.7986 - val_acc: 0.7067\n",
      "Epoch 735/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3681 - acc: 0.8681 - val_loss: 0.7934 - val_acc: 0.6978\n",
      "Epoch 736/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3662 - acc: 0.8844 - val_loss: 0.7967 - val_acc: 0.6889\n",
      "Epoch 737/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.4110 - acc: 0.8593 - val_loss: 0.7876 - val_acc: 0.7067\n",
      "Epoch 738/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3877 - acc: 0.8533 - val_loss: 0.8028 - val_acc: 0.7111\n",
      "Epoch 739/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3966 - acc: 0.8548 - val_loss: 0.7930 - val_acc: 0.7156\n",
      "Epoch 740/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3875 - acc: 0.8652 - val_loss: 0.7879 - val_acc: 0.7156\n",
      "Epoch 741/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3604 - acc: 0.8726 - val_loss: 0.7786 - val_acc: 0.7022\n",
      "Epoch 742/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3983 - acc: 0.8504 - val_loss: 0.8025 - val_acc: 0.7244\n",
      "Epoch 743/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3709 - acc: 0.8593 - val_loss: 0.8178 - val_acc: 0.7022\n",
      "Epoch 744/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3582 - acc: 0.8800 - val_loss: 0.7870 - val_acc: 0.7156\n",
      "Epoch 745/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3622 - acc: 0.8696 - val_loss: 0.8077 - val_acc: 0.7156\n",
      "Epoch 746/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3588 - acc: 0.8741 - val_loss: 0.8004 - val_acc: 0.7289\n",
      "Epoch 747/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3855 - acc: 0.8593 - val_loss: 0.7866 - val_acc: 0.7244\n",
      "Epoch 748/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3384 - acc: 0.8770 - val_loss: 0.7979 - val_acc: 0.7111\n",
      "Epoch 749/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3774 - acc: 0.8667 - val_loss: 0.8146 - val_acc: 0.6978\n",
      "Epoch 750/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3942 - acc: 0.8489 - val_loss: 0.8052 - val_acc: 0.7067\n",
      "Epoch 751/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3620 - acc: 0.8800 - val_loss: 0.8011 - val_acc: 0.7067\n",
      "Epoch 752/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3664 - acc: 0.8681 - val_loss: 0.8024 - val_acc: 0.7022\n",
      "Epoch 753/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3659 - acc: 0.8711 - val_loss: 0.7946 - val_acc: 0.7200\n",
      "Epoch 754/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3859 - acc: 0.8637 - val_loss: 0.8019 - val_acc: 0.7156\n",
      "Epoch 755/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3847 - acc: 0.8563 - val_loss: 0.7838 - val_acc: 0.7244\n",
      "Epoch 756/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3468 - acc: 0.8889 - val_loss: 0.7868 - val_acc: 0.7244\n",
      "Epoch 757/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3723 - acc: 0.8637 - val_loss: 0.8119 - val_acc: 0.7244\n",
      "Epoch 758/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3804 - acc: 0.8593 - val_loss: 0.7877 - val_acc: 0.7244\n",
      "Epoch 759/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3793 - acc: 0.8578 - val_loss: 0.8141 - val_acc: 0.6622\n",
      "Epoch 760/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3639 - acc: 0.8681 - val_loss: 0.7913 - val_acc: 0.7289\n",
      "Epoch 761/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3636 - acc: 0.8815 - val_loss: 0.8042 - val_acc: 0.6978\n",
      "Epoch 762/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3871 - acc: 0.8711 - val_loss: 0.8046 - val_acc: 0.7244\n",
      "Epoch 763/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3635 - acc: 0.8667 - val_loss: 0.8005 - val_acc: 0.7200\n",
      "Epoch 764/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3701 - acc: 0.8696 - val_loss: 0.7978 - val_acc: 0.7156\n",
      "Epoch 765/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3791 - acc: 0.8563 - val_loss: 0.7966 - val_acc: 0.7156\n",
      "Epoch 766/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3526 - acc: 0.8844 - val_loss: 0.8064 - val_acc: 0.7111\n",
      "Epoch 767/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3897 - acc: 0.8667 - val_loss: 0.8076 - val_acc: 0.7111\n",
      "Epoch 768/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 90us/step - loss: 0.3704 - acc: 0.8578 - val_loss: 0.7918 - val_acc: 0.6800\n",
      "Epoch 769/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.3588 - acc: 0.8815 - val_loss: 0.7939 - val_acc: 0.7200\n",
      "Epoch 770/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.3700 - acc: 0.8637 - val_loss: 0.8191 - val_acc: 0.6667\n",
      "Epoch 771/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.3695 - acc: 0.8607 - val_loss: 0.7949 - val_acc: 0.7156\n",
      "Epoch 772/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3865 - acc: 0.8563 - val_loss: 0.7987 - val_acc: 0.7067\n",
      "Epoch 773/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3727 - acc: 0.8563 - val_loss: 0.7959 - val_acc: 0.7067\n",
      "Epoch 774/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.3308 - acc: 0.8741 - val_loss: 0.7973 - val_acc: 0.7200\n",
      "Epoch 775/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3713 - acc: 0.8563 - val_loss: 0.7962 - val_acc: 0.7067\n",
      "Epoch 776/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3512 - acc: 0.8859 - val_loss: 0.8014 - val_acc: 0.7111\n",
      "Epoch 777/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3367 - acc: 0.8815 - val_loss: 0.7974 - val_acc: 0.7111\n",
      "Epoch 778/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3448 - acc: 0.8770 - val_loss: 0.7938 - val_acc: 0.7156\n",
      "Epoch 779/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3577 - acc: 0.8770 - val_loss: 0.7911 - val_acc: 0.7022\n",
      "Epoch 780/10000\n",
      "675/675 [==============================] - 0s 81us/step - loss: 0.3701 - acc: 0.8696 - val_loss: 0.7984 - val_acc: 0.6800\n",
      "Epoch 781/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3621 - acc: 0.8593 - val_loss: 0.7985 - val_acc: 0.6933\n",
      "Epoch 782/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3887 - acc: 0.8489 - val_loss: 0.8058 - val_acc: 0.7200\n",
      "Epoch 783/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3869 - acc: 0.8519 - val_loss: 0.8024 - val_acc: 0.6800\n",
      "Epoch 784/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3477 - acc: 0.8770 - val_loss: 0.8028 - val_acc: 0.6889\n",
      "Epoch 785/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3481 - acc: 0.8593 - val_loss: 0.7970 - val_acc: 0.7022\n",
      "Epoch 786/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3719 - acc: 0.8696 - val_loss: 0.8270 - val_acc: 0.6889\n",
      "Epoch 787/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3671 - acc: 0.8711 - val_loss: 0.8091 - val_acc: 0.7022\n",
      "Epoch 788/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3714 - acc: 0.8607 - val_loss: 0.8263 - val_acc: 0.6622\n",
      "Epoch 789/10000\n",
      "675/675 [==============================] - 0s 136us/step - loss: 0.3705 - acc: 0.8563 - val_loss: 0.8326 - val_acc: 0.6489\n",
      "Epoch 790/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3588 - acc: 0.8637 - val_loss: 0.8177 - val_acc: 0.7200\n",
      "Epoch 791/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3577 - acc: 0.8785 - val_loss: 0.8122 - val_acc: 0.6933\n",
      "Epoch 792/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3624 - acc: 0.8696 - val_loss: 0.8183 - val_acc: 0.7156\n",
      "Epoch 793/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3395 - acc: 0.8785 - val_loss: 0.8034 - val_acc: 0.7244\n",
      "Epoch 794/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3255 - acc: 0.8889 - val_loss: 0.8032 - val_acc: 0.7111\n",
      "Epoch 795/10000\n",
      "675/675 [==============================] - 0s 82us/step - loss: 0.3718 - acc: 0.8741 - val_loss: 0.8078 - val_acc: 0.6889\n",
      "Epoch 796/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.4026 - acc: 0.8622 - val_loss: 0.8225 - val_acc: 0.6933\n",
      "Epoch 797/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3424 - acc: 0.9007 - val_loss: 0.7998 - val_acc: 0.7111\n",
      "Epoch 798/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3711 - acc: 0.8696 - val_loss: 0.8222 - val_acc: 0.7067\n",
      "Epoch 799/10000\n",
      "675/675 [==============================] - 0s 83us/step - loss: 0.3620 - acc: 0.8563 - val_loss: 0.8181 - val_acc: 0.6711\n",
      "Epoch 800/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.3856 - acc: 0.8622 - val_loss: 0.7957 - val_acc: 0.7244\n",
      "Epoch 801/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3356 - acc: 0.8948 - val_loss: 0.7994 - val_acc: 0.6667\n",
      "Epoch 802/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.3399 - acc: 0.8711 - val_loss: 0.7996 - val_acc: 0.7244\n",
      "Epoch 803/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.3509 - acc: 0.8785 - val_loss: 0.8047 - val_acc: 0.7244\n",
      "Epoch 804/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.3791 - acc: 0.8622 - val_loss: 0.7937 - val_acc: 0.7067\n",
      "Epoch 805/10000\n",
      "675/675 [==============================] - 0s 92us/step - loss: 0.3775 - acc: 0.8519 - val_loss: 0.8078 - val_acc: 0.7200\n",
      "Epoch 806/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3428 - acc: 0.8919 - val_loss: 0.8016 - val_acc: 0.7289\n",
      "Epoch 807/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.3699 - acc: 0.8711 - val_loss: 0.8148 - val_acc: 0.7022\n",
      "Epoch 808/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3798 - acc: 0.8504 - val_loss: 0.7968 - val_acc: 0.6844\n",
      "Epoch 809/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3726 - acc: 0.8667 - val_loss: 0.8218 - val_acc: 0.6711\n",
      "Epoch 810/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.3576 - acc: 0.8607 - val_loss: 0.7985 - val_acc: 0.7156\n",
      "Epoch 811/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3329 - acc: 0.8904 - val_loss: 0.8203 - val_acc: 0.6978\n",
      "Epoch 812/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3438 - acc: 0.8756 - val_loss: 0.7891 - val_acc: 0.7156\n",
      "Epoch 813/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3692 - acc: 0.8593 - val_loss: 0.8014 - val_acc: 0.7200\n",
      "Epoch 814/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3519 - acc: 0.8548 - val_loss: 0.7971 - val_acc: 0.7289\n",
      "Epoch 815/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3509 - acc: 0.8726 - val_loss: 0.8034 - val_acc: 0.7022\n",
      "Epoch 816/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3705 - acc: 0.8519 - val_loss: 0.8177 - val_acc: 0.6622\n",
      "Epoch 817/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3508 - acc: 0.8770 - val_loss: 0.8113 - val_acc: 0.6667\n",
      "Epoch 818/10000\n",
      "675/675 [==============================] - 0s 93us/step - loss: 0.3843 - acc: 0.8607 - val_loss: 0.8188 - val_acc: 0.7067\n",
      "Epoch 819/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3582 - acc: 0.8741 - val_loss: 0.8020 - val_acc: 0.7200\n",
      "Epoch 820/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3488 - acc: 0.8756 - val_loss: 0.7936 - val_acc: 0.7244\n",
      "Epoch 821/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3487 - acc: 0.8681 - val_loss: 0.7955 - val_acc: 0.7067\n",
      "Epoch 822/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3561 - acc: 0.8667 - val_loss: 0.7859 - val_acc: 0.7244\n",
      "Epoch 823/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3598 - acc: 0.8637 - val_loss: 0.8165 - val_acc: 0.7067\n",
      "Epoch 824/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3480 - acc: 0.8681 - val_loss: 0.8402 - val_acc: 0.6400\n",
      "Epoch 825/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3317 - acc: 0.8815 - val_loss: 0.7992 - val_acc: 0.7289\n",
      "Epoch 826/10000\n",
      "675/675 [==============================] - 0s 88us/step - loss: 0.3406 - acc: 0.8844 - val_loss: 0.8177 - val_acc: 0.7289\n",
      "Epoch 827/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 90us/step - loss: 0.3303 - acc: 0.8844 - val_loss: 0.8018 - val_acc: 0.7200\n",
      "Epoch 828/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3772 - acc: 0.8756 - val_loss: 0.8260 - val_acc: 0.6667\n",
      "Epoch 829/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3424 - acc: 0.8711 - val_loss: 0.8102 - val_acc: 0.7156\n",
      "Epoch 830/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3372 - acc: 0.9037 - val_loss: 0.8089 - val_acc: 0.6978\n",
      "Epoch 831/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3765 - acc: 0.8607 - val_loss: 0.8017 - val_acc: 0.6711\n",
      "Epoch 832/10000\n",
      "675/675 [==============================] - 0s 84us/step - loss: 0.3779 - acc: 0.8474 - val_loss: 0.8223 - val_acc: 0.6756\n",
      "Epoch 833/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3561 - acc: 0.8741 - val_loss: 0.7853 - val_acc: 0.7200\n",
      "Epoch 834/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3365 - acc: 0.8726 - val_loss: 0.7889 - val_acc: 0.6933\n",
      "Epoch 835/10000\n",
      "675/675 [==============================] - 0s 91us/step - loss: 0.3912 - acc: 0.8622 - val_loss: 0.7984 - val_acc: 0.7156\n",
      "Epoch 836/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3418 - acc: 0.8711 - val_loss: 0.7892 - val_acc: 0.7156\n",
      "Epoch 837/10000\n",
      "675/675 [==============================] - 0s 90us/step - loss: 0.3514 - acc: 0.8830 - val_loss: 0.8132 - val_acc: 0.6978\n",
      "Epoch 838/10000\n",
      "675/675 [==============================] - 0s 85us/step - loss: 0.3428 - acc: 0.8741 - val_loss: 0.8130 - val_acc: 0.7333\n",
      "Epoch 839/10000\n",
      "675/675 [==============================] - 0s 86us/step - loss: 0.3566 - acc: 0.8741 - val_loss: 0.7939 - val_acc: 0.7244\n",
      "Epoch 840/10000\n",
      "675/675 [==============================] - 0s 87us/step - loss: 0.3679 - acc: 0.8667 - val_loss: 0.7930 - val_acc: 0.6978\n",
      "Epoch 841/10000\n",
      "675/675 [==============================] - 0s 89us/step - loss: 0.3821 - acc: 0.8459 - val_loss: 0.7962 - val_acc: 0.6800\n",
      "Epoch 00841: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Validation split is the data, that will be used for validation of the model. If we set validation_data_split = 0.1,\n",
    "# it means first 90% data will be used for training and last 10% data will be used for validation.\n",
    "\n",
    "validation_data_split = 0.25\n",
    "\n",
    "# Epoch is the time duration needed for an entire dataset to be passed forward and backward \n",
    "# through the neural network once.\n",
    "\n",
    "num_epochs = 10000  \n",
    "\n",
    "# we should not pass the whole dataset in the neural network at the same time. \n",
    "#Rather we should feed it batch by batch.\n",
    "model_batch_size = 128\n",
    "\n",
    "tb_batch_size = 32\n",
    "\n",
    "# early_patience parameter will be used in EarlyStopping function. If set the value as 100, that means, system will\n",
    "# check if the monitored value has stopped imroving over last 100 epochs. If no improvemnet followed, it will stop\n",
    "# the training.\n",
    "early_patience = 100\n",
    "\n",
    "\n",
    "# TensorBoard is a visualization tool. This callback writes a log for TensorBoard, which allows the user to \n",
    "# visualize dynamic graphs of the training and test metrics, as well as activation histograms for the \n",
    "# different layers in the model.\n",
    "\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "\n",
    "# In EarlyStopping callback a monitored quantiry is specified. If it stops improving after certain time, \n",
    "# this callback stops the training.\n",
    "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "\n",
    "# Read Dataset\n",
    "dataset = pd.read_csv('training.csv')\n",
    "\n",
    "# Process Dataset\n",
    "processedData, processedLabel = processData(dataset)\n",
    "\n",
    "# model fit trains the data according to the parameters given to it.\n",
    "history = model.fit(processedData\n",
    "                    , processedLabel\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb,earlystopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue>Training and Validation Graphs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0xb3af560f0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0xb3ba9e710>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0xb3ba518d0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0xb3b9e7a90>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAMJCAYAAAA56oN+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xd4VFX6wPHvzWTSK6mEhCT0XkNvQVQQC3axYC+Ia++7FnSxra5rXRTrT2VFdHUtIAhC6C303kJIgfReJpnM3N8fUzKTmUAgyaS9n+fxYebec+89MyeQ11Peo6iqihBCCCGEaF5uLV0BIYQQQoiOQIIuIYQQQggXkKBLCCGEEMIFJOgSQgghhHABCbqEEEIIIVxAgi4hhBBCCBeQoEsIIYQQwgUk6BJCCCGEcAEJuoQQQgghXMC9pStQV2hoqBoXF9fszykvL8fX17fZnyNajrRx+ybt2/5JG7d/7aGNt2/fnqeqalhDyra6oCsuLo7k5ORmf05SUhKJiYnN/hzRcqSN2zdp3/ZP2rj9aw9trCjKyYaWleFFIYQQQggXkKBLCCGEEMIFJOgSQgghhHCBVjenSwghhBCuo9frycjIQKfTufzZgYGBHDx40OXPPR9eXl5ER0ej1WrP+x4dMug6nFVKfqWxpashhBBCtLiMjAz8/f2Ji4tDURSXPru0tBR/f3+XPvN8qKpKfn4+GRkZxMfHn/d9OuTw4jXzN7I8Vd/S1RBCCCFanE6nIyQkxOUBV1uiKAohISGN7g3skEFXoLeWcom5hBBCCAAJuBqgKb6jDhl0BfloKdOrLV0NIYQQQnQgHTboKpegSwghhBAu1DGDLm8PKvQqRqPKLZ9u4bHvdlFVYwCguEJPbmkVAEv2nOaDVUdbsqpCCCGEsOHn51fvudTUVAYMGODC2pybDrl6McBbS5keNqfks/5YHgBBPh68cHk/Ln5nDdklVaS+fikPL9pJjVGld2QAF/WLaOFaCyGEEKIt65BBl2V4cem+0/h6aLi4fyTfbD7J2O4hZJeYernSCyqwzJlbnJzORf0i0OkNHMspY0CXQLv76fQGPDRuuLnJREQhhBBt10u/7ufAqZImvWe/qABevLx/veeffvppYmNjmTNnDgBz585FURTWrl1LYWEher2eefPmMWPGjHN6rk6n4/777yc5ORl3d3fefvttJk+ezP79+7njjjuorq7GaDTy3//+l6ioKK6//noyMjIwGAw8//zz3HDDDY363M500OFFLQYV1h3NY1hsMA9N6Um1wcjdX9VutD3hH6vRG1R8PDSsOZzLgVMlzP1lP5e9v56MwgprOZ3eQJ/nl/GP5YcdnqOqMm9MCCGEOJOZM2fy3XffWd8vXryYO+64g59++okdO3awevVqHn/88XP+nfrhhx8CsHfvXr799ltuu+02dDodH330EQ8//DC7du0iOTmZ6Oholi1bRlRUFLt372bfvn1MmzatST+jRYft6QI4mV/BlUO6EB/qW2/Zz24bwcOLdvL8z/s4VVQJwPg3VjNzRAyvXT2Q3elFAHy05jhPT+vNxuP5+Hq6Ex/qy1X/3sCEHqHMvaK/LMcVQgjR6p2pR6q5DB06lJycHE6dOkVubi7BwcF07tyZRx99lLVr1+Lm5kZmZibZ2dlERkY2+L7r16/nwQcfBKBPnz7ExsZy5MgRxowZwyuvvEJGRgZXX301PXv2ZODAgTzxxBM8/fTTXHbZZUyYMKFZPmuHDLoGxwQR6avQJzqUGUOiAPjHNYN4f/VR7hoXz6wxcVhCJDc3hXsndmPeEvttChZtSyclt5ytqQXWY/HPLnV4VkpuOVcM6cLw2OBm+zxCCCFEW3bttdfyww8/kJWVxcyZM1m4cCG5ubls374drVZLXFzcOScmra9n7KabbmLUqFEsWbKEqVOn8umnn3LBBRewfft2li5dyrPPPsvFF1/MCy+80BQfzU6HDLr6RAbw+gQfEhNHWo9dPyKG60fEOC1/86hYqmqMFJRXc+3waLqH+XH7F1vZeDyf2BAf+kT6Y1RhxYFsIgO8yCox/WC8etVA5v6yn3dWHiHc34vCimpuGtmVxN5huGs65MiuEEII4WDmzJncc8895OXlsWbNGhYvXkx4eDharZbVq1dz8uTJc77nxIkTWbhwIRdccAFHjhwhLS2N3r17k5KSQrdu3XjooYdISUlhz5499OnTh06dOnHLLbfg5+fHl19+2fQfkg4adJ0rbw8ND0zuYXfs67tGkVdWRUSAl0P5/+3MRKtx49JBndmRVsgP2zPw1mpwU2DVoRym9Annw5uH4aXVkFdWhcGoogDhTu4lhBBCtHf9+/entLSULl260LlzZ26++WYuv/xyEhISGDJkCH369Dnne86ZM4fZs2czcOBA3N3d+fLLL/H09OS7777jm2++QavVEhkZyQsvvMC2bdt48skncXNzQ6vVMn/+/Gb4lKC0tsneCQkJanJy8tkLNlJSUhKJiYnN/hy9wciSPacZ2yMEL62GhZvT+MfyQwR6a4kL8WWXeU6Yu5vCsVenN3t9OhJXtbFoGdK+7Z+0sWscPHiQvn37tsiz28qG1xbOvitFUbarqprQkOtljKuZaTVuXDm0C+H+XgR4abk/sTtf3zmKHmF+1oALoMaocuOCzaw/mteCtRVCCCFEc5HhxRYwvmco43qEsDmlgPhQX77dmsb8pONsSslnU0o+/p7ufHffGPpFBbR0VYUQQohWZ+/evcyaNcvumKenJ1u2bGmhGjWMBF0tRFEUxnQPAeDRi3oxe1J3qg1Gxr2+itKqGu77JplhXYOJCPDigcQelFXXEOHvKRPwhRBCNDlVVdtUaqOBAweya9culz6zKaZjSdDVSnh7aPBGw7JHJvB/G1P5bls6yamFnC6uZMHaFAB6Rfjx/X1jCTTnGRNCCCEay8vLi/z8fEJCQtpU4OVKqqqSn5+Pl1fjFrxJ0NXKRAf78LdL+/G3S/sBsOFYHk/9sAcPdzdScst5Y/khrhnWhbIqA5N6hbVwbYUQQrR10dHRZGRkkJub6/Jn63S6RgcyruLl5UV0dHSj7iFBVys3rkco65+eDMCLv+znq00n+c+WNABmT+rOXePjCfP3bMkqCiGEaMO0Wi3x8fEt8uykpCSGDh3aIs9uCTJBqA1QFAVFUXjmkj7cPjaOOYndAdPWQyNeWcm6o7myz6MQQgjRyklPVxvi4+HO3CtM+2I9eEFP+r6wDIA/9mfz8ZoUFMU0Kb97qB+BPlqKK/V4azV4uEtsLYQQQrQ0CbraKG8PDeufnsydX27j68212yOsO5qHv6c7fz4+ianvrKWwQs/lg6N4b+YQmSAphBBCtCDpAmnDooN9ePHy/nQO9OLOcfF4mnu0SqtqmPnJZgor9AD8uvsUv+05zc60QpbtO01ltaElqy2EEEJ0SI3q6VIU5XPgMiBHVdUBTs73Ab4AhgF/U1X1rcY8Tzga1yOUTc9OAWDmyBiO55Txwepj7D9VwphuIXxz9yimvrOWB7/dab3muuHRvHndYFRVparGiJdW01LVF0IIITqMxvZ0fQlMO8P5AuAhQIItF+gV4c8lAzvz4U3DuLhfBC/P6I/GTeGZafYbhS7fn4XRqPLvpOP0eX4ZheXV1nMv/bqfe75q/r0vhRBCiI6mUUGXqqprMQVW9Z3PUVV1G6BvzHPEuYkL9WXBrQn0jDBtInphvwjeuWEIoX6m1BIluhpu+WwLby4/DMDF76xlftJxAFYcyGbHycKWqbgQQgjRjslE+g7iyqFduHxwFFU1Bvq/uJyNx/Ot53JLq3hj2SEu7BtORmElAFnFOgK83fHxkB8RIYQQoikojc3vpChKHPCbszldNmXmAmX1zelSFOVe4F6AiIiI4YsWLWpUnRqirKwMPz+/Zn9Oa1RSpfLQ6goApsVpWZbqvCMyPsCNF8d62x1LLTbg5a4Q6dv612B05DbuCKR92z9p4/avPbTx5MmTt6uqmtCQsq2iG0NV1QXAAoCEhAQ1MTGx2Z+ZlJSEK57TWnXpU0iV3sDwuGB+3JHJsz/udShzosTI2PET7fJ8xT2zBIDU1y91WV3PV0dv4/ZO2rf9kzZu/zpaG7f+7grRLIbHBjO2Ryie7hpuHNmVHc9f5LTc5LeSWLbvNADVNUZXVlEIIYRoVxqbMuJbIBEIVRQlA3gR0AKoqvqRoiiRQDIQABgVRXkE6Keqakmjai2aXCdfDxJigxkeG8zCLWkM7RrEuqN5ZBZVMvubHXhp3XjnhiHnde/MokqiAr0kOasQQogOrVFBl6qqN57lfBbQuC25hcv8cP9YAJ6Y2hutxs06lOjp7oZOb2T2NzusZUt1evy9tBw8XcLJ/AqmDYh0es8j2aVc/K+1vHh5P+4Y1zIbqgohhBCtgQwvCgdajenH4u8z+nP72Di2/vVC7p3Yza7M6WIdAJe8u47Z32ynxuB86PFYThkAm2xWSwohhBAdkQRdol6zxsQx94r+BPpoGds9xO7cigPZbDyWZ33/x4Fs4p5ZwupDORiNtStiy6tqAPCUrPdCCCE6uFaxelG0fkO7BgNw7fBoft6VaU2samF5f8eX23hgcneigrxZfSjHep1WI/O5hBBCdGwSdIkGCfTWsu6pyUQGejGuRwjL92XTLyqAoV2DePS7XZzIK7eW/XD1cetrP0/Tj1iproYNx/IY1yPU5XUXQgghWgMZXhQNFtPJB63GjauGRvPRrOE8NKUnE3qGMSreNPRoCbBs/W/XKcA0HHnzp1vYnGI/t+tkfjnXfbSR/LKq5v8AQgghRAuSoEs02qMX9WLmiBi2/m0Ke+dezJhuIfWWTcuvsL5euvc0k95MYltqIb/vy3JFVYUQQogWI0GXaLQe4X68fs0gfDzc8ffS8u29ozk8b5r1/E2julpfn8gvZ0daId8npzNnYW0KivSCCvZlFru03kIIIYQryZwu0Sw83TW8ff1gBnYJZPOJAuvx77alMz/puEP5j9em8PHaFLY/dyHubm4E+mhdWV0hhBCi2UlPl2g2Vw+LpmeEP9cOM+XH7eTrQfcwX7syf79yAEO7BlnfD5+3ksEv/2F9vzOtkIrqGtdUWAghhGhG0tMlmp23h4ajr1yCu5uCoii8u/Io/1p5hC9uH8HkPuH4emjYmVbkcF1heTVX/Xsjlw7szIc3D2uBmgshhBBNR3q6hEtoNW7WvRfnTO7OJ7cmkNg7DIBpAyKJ6eRtV768qob0QtOk+x1phdbjeoPRLvmqEEII0VZI0CVcTqtx46J+EdYgzMfDnZWPTbIrk1WiI72gEgB3m8SqA15czqzPt7iuskIIIUQTkeFF0Sp4uttvE/TqkoO4uZmCLa3GjRqDkW2phVTVGNlwTPZxFEII0fZI0CVajdmTuvPRGtPKxj8P5ViPp+SWM+ilP6ioNrRU1YQQQohGk+FF0Wo8c0kfVj0+iUHRgTw5tTfXmFc9Ag4B1+niSuvrvLIqFqw9jqrKXC8hhBCtl/R0iValW5gfv/xlvPX97WPjeH3ZQby17sy9oh9vLj/Mz7tOMea1VRx75RLcNW48smgX64/lMaFnGH07B7Rg7YUQQoj6SdAlWrWB0YEsvHu09f3obiH8bN7PcXNKAYoCu9NN6SZyS6vo27lFqimEEEKclQRdok3x1tZOuL/v62TKbYYdbYcchRBCiNZG5nSJNiU+1JTR/qqhXewCLoCdaUVkFlWi09cef+qH3Ty2eJdL6yiEEEI4Iz1dok0ZHBNE8nMXEurnyaReYXy1KZXCCj0n8spZtC2dRdvSmT4wkr6RAcQbVBYnZwDw9vVDUFWV/2xN47KBUbK3oxBCCJeToEu0OaF+ngBcObQLVw7tAsA18zey/aQpc/3SvVks3ZtFYnTtj7eqquzOKOZvP+1j0/F8PrhJthUSQgjhWjK8KNqFhXeP4qZRXe2OZZYZra9Lq2oo05k2zs4pqXJp3YQQQgiQoEu0E15aDa9cOYDF942xHjtaVBt0ZRXrKKioBsBNfuqFEEK0APn1I9oNRVEYGd+JD28axmTzZtoWp4oqySnRAeCmKM4uF0IIIZqVzOkS7c6lgzpz6aDOvLVoJR/sMg0l3v7FNut5vcFY36VCCCFEs5GeLtFuJUS6k/r6pdw6JtbueH5Ztd17nd7ANfM3si21wO643mCkqkb2exRCCNE0JOgS7d6Ll/dn9wsXW9+n5JXzxrJD1veHs0rZfrKQ537aZ3fdDR9vovdzy1xWTyGEEO2bBF2i3dO4KQT6aNn9wsW8O3MIAPOTjrPhWB4AmUWmTPa+nhq763akmbYX+vtvB/hqU6rL6iuEEKJ9atScLkVRPgcuA3JUVR3g5LwCvAtMByqA21VV3dGYZwpxvgJ9tMwY0oWp/SOZ8s813P/Ndq4eFs3RnFIAfDyc/3X4bP0JAG4dE+eqqgohhGiHGtvT9SUw7QznLwF6mv+7F5jfyOcJ0WheWg2f3pbAqG4hfLs1jQ3H8gEoq6qxllFVtaWqJ4QQop1qVNClqupaoOAMRWYAX6kmm4EgRVE6N+aZQjSFvp0D+OTWBHa/eDHPXtIHwJpSAqCksqa+S4UQQojz0twpI7oA6TbvM8zHTjfzc4VoEC+thvsmdaeoUs+n61JIy69gcXI63cJ8W7pqQggh2pnmDrqcZaF0GLdRFOVeTMOPREREkJSU1MzVgrKyMpc8R7Scc2ljbXENeoPKxDdX11tm5arVuLvV/kiXVKt8vFvH7f09qTKARoHOfrI2xVXk73D7J23c/nW0Nm7uoCsDiLF5Hw2cqltIVdUFwAKAhIQENTExsZmrBUlJSbjiOaLlnEsbTzCqLD+1jsPZpfWWWVUcSpXeSHiAJ09P68MrSw6wP/8E6dpo3lt7FIDU1y9tiqqLBpC/w+2ftHH719HauLmDrl+AvyiKsggYBRSrqipDi6LV0bgp/PrgeLQaBb1BpddzvxPi60F+eW0i1f9sSbO+vj+xO3sziwHQusm2QkIIIc6usSkjvgUSgVBFUTKAFwEtgKqqHwFLMaWLOIYpZcQdjXmeEM3Jw93N/KfClr9Owd1NYfi8lU7L/rzrFIezTL1ip20m4J+P1LxyyqpqGNAlsFH3EUII0bo1KuhSVfXGs5xXgQca8wwhWkJEgBcAO5+/iNyyKjYeyyMhrhPJqQUs2pbOv1YcobBCD8BRmyHJGoMRd825zetKfCsJkKFJIYRo72TDayHOINjXg2BfD3pF+AMwoEsgof6e/OU/O61ltqUWWl8v3ZfF6PhOhJuDtvOlqirrj+UxvkcophzDQggh2jpZaiXEObp0YGduHRNL50AvLuwbYXfuoW93cvOnWxr9jJ93nWLWZ1v5blv62QsLIYRoEyToEuIcKYrCyzMGsPGZC/jn9YMdzh/NKWv0Myz7QZ7IL2/0vYQQQrQOEnQJcZ4URSHQW8vKxyYxMr6T3bnMokpUVWXriQLinlnCmiO5AGw/WUBVjcHp/fQGo/W1xrwi0miU7YiEEKK9kKBLiEbqEe7H4vvG2B0b9/oqft51ius/3gTAh6uPsTu9iGvmb+KN3w9by9nu8VhRbaDcvP+jxjyPq0aCLiGEaDck6BKiiax4dCL+nrVrUz5dn2J9vfVEATM+3ADA/lOm/F6bU/K59+vt1jLL92fR/8XlJKcWUG3u9ZKeLiGEaD8k6BKiifSM8Oebu0dZ3+/LLHFarkRXwxPf7+b9VUdZcSDbenzpXlPe4B1phZTqTD1elXrnQ5FCCCHaHgm6hGhCg2OCSH39Un5+YBwA1ydEO5Q5eLqEH7ZnsOFYvt3xQnP2ew+NG2VVphxgW08U8Nz/9kqPlxBCtAOSp0uIZjA4Joh1T00mxM+Di/pFsmDtcbt8Xs4UVJiCrqoaI2Xmnq7U/ApS89N4YHIPOgd6A6ZJ+lnFlfSK8MdNUfD1lL/GQgjRFsi/1kI0k5hOPgBc1C+Ci/pFsPpwDn/9cS+ni51vG5ReYEoT8drvhxzOFVXo6RzojU5vYPwbq7DMvw/wcmfP3KnN8wGEEEI0KRleFMJFJvcO5/GLe9sdu7hfBH+b3ves1xaae8H6v7gcmwWPlOhqyCursqab0OkNlOj0TVdpIYQQTUaCLiFc6OqhXbhvUjduHtUVgFJdDdMHdXZadkqfcD6eNRww9XQBGJzM7UqYt5KP1xwHYPwbqxg09w9yShu3CbcQQoimJ0GXEC7k5qbw7CV9uWV0LABh/p4EemsBuGt8vF3ZqCBvBkcHAaaeLtvkqXXtP1VCiU5PXpmpRyy9oOKM9Vi69zQLt5w8788hhBDi3MmcLiFaQN/OAbw7cwiJvcLx83Rn+3MX0snXg8/Wn7CWuXdiN4J8TAFZUYWenNKqeu9nMKqcMm8dBJBbWm13/pFFO5nQM4xrhptWU85ZuAOAm0fFNtlnEkIIcWYSdAnRQmYM6WJ9HeLnCcD6pydTUllDtzBfvLQa6/k3lx+mX1RAvfcqrKi2C7ryyqrsXv9v1yn+t+uUNegSQgjhehJ0CdGKRAf7QLDzc++sOFLvdQXl1WQW1c7jsg26dqYVWV+rqopi3mLIlsGo4qbg9FxDZRZVkpJbxoSeYed9DyGEaM9kTpcQrdzlg6MA2J1RjI+Hhm/vGW09FxXoRWLvMFPQVViJVqMQ4OVuF3StP5prfX0y336uV2W1gVKdnu5/Xcqn607QGNPfXcesz7Y26h5CCNGeSdAlRCv3/o1DmdTL1Hu08O5RjOkewtPT+gDw+yMTGRQdRGGFnmM5pUQH+xAe4MWOk0WoqopOb+DHnZl0NecMO55bZnfvvi8sI6PQNCz55cbUBtXn2R/3EP/sEofjxZWmFZa2m3gLIYSoJcOLQrQB79wwhMKKarqF+QFwf2J37hofj4e7G8HmyfYrD+aQ2DsMg1Fl3dE8ft+XRSdfD0p1Ncy9vD+Pf7+bE3nlDvfef8q0R2SN0Vjv8KOtb7emn/F8VY3Rbj6aEEIIE+npEqINCPb1sAZcFh7upr++I+M7WY9FB3vzwY3DANiXWcyeDNN8rkm9wwj20XLwdKlDT9TudFOZ7JIqZn+zvcF1qi+FRUW1bNIthBDOSE+XEG1c/6hAXp7Rnxd+3k91jZFAHy09w/34d5IpYWpkgBehfp6E+3vx3x0ZDkHXrvTaifbL92c3+Lmluho6+Xo4HK/US9AlhBDOSE+XEO3AlUO7MLl3GPcn9gDAYA6shsQE8cRU09ZDT19i+vPHnZl21+7NLD6vZ5bWs91QZXXNed1PCCHaO+npEqIdCPDS8sUdI63vH57Sk++TM/js9gQ83U3zqy7oE4GHxo3qM2S2t3XPV8n8eTCblNcudXq+VOc8uKqsbtj9hRCio5GgS4h2aMaQLnbJVy3qC7h6hPtRWW0gs6iS6hojHu5urDhw5qHGkkrnPV0V0tMlhBBOyfCiEB3I3XX2d4wI8GTJQ+P5/eEJ/OUC09CkbY4vgPIq50FUSX09XTKnSwghnJKgS4gO5K/T+3Jh33Dre3c3N/pHBaLVuBHub9qK6HRxpd01liBMVVUqbVYmltQ7p8s+6Mou0WE0Su4uIYSQoEuIDsTNTeHeid2t77Wa2pxcg2OC8NC48fOuUxhsgqRc80bbC7ek0feFZdbj9c7psunpSi+oYNSrf/Lx2pQm+wxCCNFWSdAlRAczMr4Tyx+ZCIDGrTboCvXz5LLBnflhewZpBbXbBVl6uhYn2ydFLaqodnp/2zxd6eb7rD6c0zSVF0KINqxRQZeiKNMURTmsKMoxRVGecXI+VlGUPxVF2aMoSpKiKNGNeZ4QomnEhfowMq4Tb1wzyO74HWPjqag28Mx/91iPzf5mB+/9eZQ9GfapJQ6cKmHNkVweWbSTLSn51uM6m54uSwCmacRG2kII0V6c9+pFRVE0wIfARUAGsE1RlF9UVT1gU+wt4CtVVf9PUZQLgNeAWY2psBCi8TzdNSyePcbh+MDoQAZFB7LlRAF+nu5U6g0YjCpvrzjiUHZ7WiHeHhp+23Oan3efsh63BFr/TjrGsWzTXo+2PWpCCNFRNaanayRwTFXVFFVVq4FFwIw6ZfoBf5pfr3ZyXgjRyjx/WT8u6hfBiscmcvjv0wj0Nu3tGNPJmz6R/gD0jwqgqELP7/uyCPXzwDbJfUW1AZ3ewD+WHbYmYrXt6Mop0fHQtzsprnCciF9VY+DhRTvZkVbYfB9QCCFaSGOCri6A7SSPDPMxW7uBa8yvrwL8FUUJacQzhRDNbERcJz65NYHOgd64a9z4fvYY3rtxKKsfT+Txi01Z7W8YEYNWo2AwqkzpE2F3/f5Txdz6+Va7Y4ezSrnnq2SKK/V8tekkv+w+xVt/HOaP/Vkczipls3l48quNJ/l51ym+2XTSNR/WbHd6kcOqSyGEaGpK3X3YGnyholwHTFVV9W7z+1nASFVVH7QpEwV8AMQDazEFYP1VVS2uc697gXsBIiIihi9atOi86nQuysrK8PPzO3tB0WZJGzePjFIjXfwU3krWsT/fyIzuWtZk1FBUdfZ/SyJ8FKL83NiZ4xjgfDnNl1e3VHKk0MjUWHdu7Ot5xns1VfuW61Ue+LOC4REaHhzq1ej7iaYjf4fbv/bQxpMnT96uqmpCQ8o2JiN9BhBj8z4aOGVbQFXVU8DVAIqi+AHX1A24zOUWAAsAEhIS1MTExEZUq2GSkpJwxXNEy5E2bl4+sfncsGAz10wais++03y7NZ24EB9S8yvqvSa7QiW7wnmP0iElhtRS09yxwLBIEhMHn/H559q+ry09yOliHe/dONS+TiU6+PNPUss08vPSysjf4favo7VxY4KubUBPRVHigUxgJnCTbQFFUUKBAlVVjcCzwOeNeJ4QohUZ1S2E/S9NxdfTnf5RAWQW6Xjhsr6UVRkI9fNg4/F8ThVVEurnyfurjpJdUpvpftboWCb1CuPur5Ktx17//ZD1dUll47cS0ukNLN17mquGdkFRFHZnFHE8t9xpOQB9A/ekFEKI83XeQZeqqjWKovwFWA5ogM9VVd2vKMrLQLKqqr8AicBriqKomIYXH2iCOgshWglfT9M/ISF+nnx150i7c9cn+Fhf3zI6loR5K605v24bG0txPYFVTCdvSnTt38R6AAAgAElEQVR6CsurKa7UExfqe151+23PaZ74fje9IvwZ0CWQUl0NuaVV6PQGvLQaazmd3hRs1UjWfCFEM2vUhteqqi4FltY59oLN6x+AHxrzDCFE+7DysYkUVugpqdTTI9yf1DzHXieAnuH+5JZW8eQPu1l5MIdVj0+iW1jD5nwcyykjzN+TQG8tB0+XAKbhQ0vQBXCqqJJuYX7klOrYklJATCdTcFhjqD/oKiyvpqCimu4NrIcQQjgjGemFEC4R5ONBfKgvg2OCAOjk5+FQZkhMEP5e7uzNLGblQVMW+//bmGo9/+m6FBZvS3e4DqBUp+fCt9cw5Z9r2JVexKEsU9CVXlCBqqqUmveKzCwy7S15++fbePDbndZtjvTG+ocXp7+3jin/XHOOn1gIIew1qqdLCCHOl7+n/T8/Wo3ContHM2/JAbvj64/lWV/PW3IQgH+tPMLoMANDR+r5cWcG/ToHcMOCzYBp26IrP9xAqDmom/vrAby0GmtPV2ZhJYezSjlg7gnLKtEBcKaF3KeLLWVUFMmuL4Q4TxJ0CSFaRN3gJcjHAy+thsLy2qSpkQFeHM8t564vtzEwOtB6/HSxjp+K4aeX/6j3/nlltXtDfpecbp2zlVFYyTM/7rWeyyqubHCdS6tqCPDSNri8EELYkuFFIUSLuXZ47Xas1wwzva42ryIM9fNk8X1jmNgrjD8P5fDOyqNnvV+3sLNPurfdzBvgdJGuwfUtKnfMoi+EEA0lPV1CiBbzj2sGMWt0LF07+Vi3G/r7jAFM6BnKrNGxKIrCglnDmbNwB6sO5Zz1fkNjgklxkhYizSZ32C+77dIJcuosPV2WOWAAhRXVdA3xcVquuEJPZlEl/aICzlpPIUTHJD1dQogW4+amMDgmiGBfD9zMm2JHBnpx65g46/Cjl1bDK1cNsF5z+eAop/dyd1OYd+UAZo6ozdn83/vH0iXIm/zyaqfXAGxOKbC+drYf5LjXV1lfF1Y43mf90TzinlnCS7/t54YFm8gu0XH6HIYsz1dxpZ7L3l/H4azSZn+WEKJpSNAlhGj1Ogd688iFPfn5gXG8N3MIG5+5gEvitdYhSYBwf0+8PTQ8NKUnAPdN7Mbw2GBuGtXVWiYq0LTNzxe3j3D6nK82pQJQU0+i1CInQdn7q0zDnv/bmUmproZRr/7JmNdWOZSzqKw2MD/pOFU1jdvrcd3RXPZllvCvFUcadR8hhOvI8KIQok145MJe1tdRQd7c0NuDSZMG8Y9rB3HR22vwNw9PRgV5s+6pyUQHewMwODrIet1Xd42kotpA9zA/NG6mDbstLuwbwSfrUnBzU/hw9THWPTUZd43p/0tHd+vE5pQCCpz0mFWYN8qum1u1qsaAp7vGofzXm1N5Y9khPNzduGt8/Hl+G1jrrtHIakoh2grp6RJCtFmKoqBxU3jh8n48cXFtUBbTycc6PDk4pnbVY49wfwZFB+Hr6c7xV6fb3euhKT0o0dXw5vLDVFQb+H57BoNfMq2OvGZYNO5uCjmlVdRVXu08s/7R7DLr643H8qzJYKvMGfBP5jtPDms0qk6HOeuqqjHdR+smQZcQbYUEXUKINi+xdzgTeoY5PefvpWVOYnc+njXc4dzWv02xvh4UHYSne+0/id9sPml93SXYm54R/tbcXu+uPMrOtEIAKqqcDxMeOGUqazCq3PTpFq74YD2AdX7ZCXMQVlFdQ5HNXLEPVx9j8Mt/kF/mGODZslzjJkGXEG2GDC8KIdq9p6b1cXo83N/L7v33s8eQUVjJyoPZ/Lgj03o8IsCLgV0CWJycwcAXl1NaVcO/Vh7htjGxToccATIKK1i0NY2tqaaJ+iW6GtILKvjSnGHf0hN2zfxNHDxdQurrlwKwdF8WYEpt8c8VR7h6aBcGxwTR82+/8+wlfbhvUncACszpK4yyZ6QQbYb0dAkhOrTLBnWmR7hpT8VB0UFMH9iZnuH+1vMzhkQRF+JLQmwnwJQg1eL/Np205hWrK6PIlITVNnib9s5a6+usEh06vcG6R2SJeZsiS6b+7ScL+c+WNOYs3MHezGIAPlh9zHp9QXmV+Trnw5v12ZdZTNwzSziWI6sehXA16ekSQnRoH9w0zOFYr4jaja3fuWEIiqJwzfBoqg1GvLQafDw0rD6Uw9K9pymvNtA50As3RbHL6ZVR4Jg2orzaQL/OAXQJ9mbFgWy+3ZpmPffU93uYf8swfD1Nk+8tWx4FemvZdDwfgK6danOEWXq6SirPLWHrr+Y8ZSsO5NDDJrgUQjQ/CbqEEKKOMd1DuGlUV2JtJuRr3BRuGR1rLTN9YGcu6BPOhuN59O0cgNGo8vzP+wHw0LhZhxXvGh9PjcHI/206SZ9If5Y+PIEdaYWsOJDNS7/W7jO5bH8W21ILHbZHCvP3ZE9GEVA7eR5qc4ZZesjOlYrrhyULy6vZlV7E5D7hLn+2EK2BDC8KIUQdPh7uvHrVQOv8qfpcMrAz864cyM2jYpk1Js56fHhssPX19IGdiQoypa/o29mUrd62xwrg3ZlDAHhl6UE2Hs+zO1deVWNNgHq6qBLVvDO3ZS5Z8Tn2dGGO6VQV5icd5/e9p8/terMag5F5vx0g18mKzvpM/mcSd3y5jcrqxuUoE6KtkqBLCCGayMAupvQU9yd259rh0Tx0QQ+GdQ2iyBwYWXKHhfh6WK/5+5UDmDGkC7MndWd3ehE6vZFB0YEkP3chVw3tQmZRJScLKvD10FBebWBTSj5Go2oNugrL9U4n01fVGPg+OZ1DWSUcyiqxBkeKOepSVZU3lh3i/oU7rNeoqopO37CAaN3RPD5df4K5v+xvUPkSnd6aXLb0PHvnhGjrJOgSQogm8u+bh3H54ChGxHXiresG89jFvVEUhesTYogP9eXGkabs+LZDiJEBphWUcyZ3J8jHlOA1yMeDUD9POvl6kFdWjarCNebNwW/6ZAuLk9MprtQT7u9JtcFIVolp0+7iSj0L1pqy3a8+lMOTP+zh2vmbmPbOOmZ9tgUAg9E0RFnupLfpjWWH6fP8Mn7bc8rhHJjSWzz5/W6yinXW5KyVDQjSft6VyWqbvTPLqs5t8v/ZmAK6+rd6Ol8bj+eRMG9Fk9dXNM5Lv+63+3lqSyToEkKIJhLTyYf3bxyKt4d9Jvr4UF9WP5FoHWYEsKTXigjwBCDAS2vdniijwLRBd4hfbY/YrTbDl2uP5gIwtKsp235qfjmqqvLf7Rm8uvQQw15ewZYTpjllloDhkHmIstS82jGtoHYTcIC3/zjMR2uOA1hXVNa1eFs632/P4JN1KdZjW08UEPfMEnJKTYGf0ajy6boU8mzyjD28aBcPL9plfd/UQcy411cx5OUVTXpPgLeWHyavrJpD9XwfwvVUVeWLDanc8eW2lq7KeZGgSwghWkCAeduiiIDaXGF9Ik1zvq43b9ptO/crPtSXpQ9NINBby/qjpnlfw7qa5o7d9MkW7vkqmZd/M03ML6828MWGVLvnhZoDOEvQdSK3NiO+wajy3qradBRl5jJlVTUs35/Fyfxy1h3N5ViuKbdYsI+WCnMPlyWAGvPaKk7klbPheB7zlhwkYd5KftqZ4XTos+wc01ycjeUzWea7NRVLj6RkQms9GtKz2ppJ0CWEEC3g6ztHccvoroT5eVqPeXtoOP7qdGabJ/BP6lWbZV/jptAvKoCbR3W15ubqFxVgPb/yYO1wy6PmfSo9NG4M6xpEQmwweWXV6PQG62pHS0Z80+vaLYugNhfZvN8OcN/X25n0ZhKzPtvKwdOm3rKjOWUOE+gNRpXn/7fPmt4C4NHvdlsDIltn6+n6PjmdFQey7Y6VV9Xw8y5TzjOd3mC3b6aFbcqOpmAZBK6ucZ6LTZxZqU7PgBeXs3x/VpPd09mm822JBF1CCNECBkYHMu/KgQ7b+Ghs3vt7aXn2kj68ee0g67EHJvewvg718+S7e0c73Ht8zxAAqg1GfpwzzprqIqOwwhoE2fYY3PrZVrvry3Q1GIwqx3Ptg7HtJ01bH/286xR//+0AdekNRmsZi0Inc63OFnQ9+cMe7vkq2e7Y8//bx8OLdrE3o5g+zy/jyR92O1xnWeXZVNzMPV311XfT8fxzCshsk+E2h6oaA4u3pbeaXQq2niigrKqGfycdb7J7nvNq3VZGgi4hhGjF7pvUnesSYqzvfT3dWfLQeC4b1Jn4UF9GdQvh5wfG2W34PcC8itLPnN3eMpfsxx2Z7EovcnjGqWKd3ftSXQ2PfLeLbamFDmXPZHdGEbszau/voXFjiZOUFGcKumyHCHdk15Y7bu6ZK6o0BXG2mf49NKZfZan5FdQYjDz23S7u+zq58akpzPGv7XCowWha4bk3o5gbP9nMW38cbvDtnvxhD5e8u65BgcNbyw8z9V9r6z2/dO9pa8+fxbsrj/LUf/fwx4Gm61k6X3d9uY27/s8UOHcJ8jpL6Yaz7elKzSvnh+0ZTXZvV5CgSwgh2pj+UYF8cNMwvLSmCfuDY4K4aVRt4lZPdw0LZg3nfw+MBSDc3zSEaelxsGw1ZDG0axCPXVQbtJVV1Vgz158Lnd6ITm/k6mFdGNY1iGqDkTeX1wYlll48Z0OOFra/VN/bWUWNeZslS49SRqHjEKJlo/KMwgrSCyv5cWcmy/dn88ayQw2ue1WNgXdWHiGrWGddvWnpc7QNEp/4fjd9nl9GnnkbpnPpudqcYhp6bchKyw9WH+NwdilGo8qvu085pPKYs3CH3eIEgHTzd1PVCoZD/7RZXWjbpjklOvLLqs57MYUlYNVqFG5YsIknvt9NVY2B3NKqVtPDdyYSdAkhRDsQbE43ER/qC8DF/SOt2/yEB9TOG7tldFfmXTWgzrUeXDW0C0E+WvpHBdj9QtS4Kfw0ZyxRgQ3vrRjaNZiZI7o6HA/390SrUSg/wy/c03V63TYezye/rIqqGlPQYTsXbene01RU11gn9WcWVlrzl3UJ8mbhlpMNnuf1+94s3ll5lNGv/clf/rOTlNwyasy/xN9afphC831/2mnqXSqsZ6Pz+sz+ert1Hlz+OVy7cGsaD367027LKFu2PYOWnj1Pd43Tsi0ly6ZNR776J8PnrWTAi8sd5uWpqkrcM0t4YOEODmU5D2aLzT2dHho3cszf556MYka8spIPbfYmba0k6BJCiHZAURSWPDSeH2aPcTjn41HbszWmWyi9I+33XAzy1hLTyYddL1zM4Jggu8DmpSv6M7RrMH5eDd81LtTXg4m9wrhicJTd8UBvLXqDyr+TjpNZVOmQDf/jNce58sMNdsdu/Xwrl7y7Dr25x8u2bnMW7mDWZ1utv7wzbIKu5y7tS41R5YNVDftFXLcn6YYFm63z00qrarj9C/t5b/tPmYICZwsmF29Ld+jNWmYzmfx0ka7uJXZqbDZRX7j5JFA7v6wu2wDO8hnOtIpz/dG8Rs0r+9eKI/T62+9nLGMJkC1S8sp56ofdDsOqa47Y59qyzDNcsvc0095ZB8Du9CKe+99e6xw/yz3Kqw3W736becutpCO55/GJXEuCLiGEaCf6RwUSYrMa0nmZAHqE+XH10C5cNqgzYErGauFrk2PsuUv7WifhTxtgKnvnuHj626yaBHh4Sk8OvjyNt64bDEB8mC+RgV68d+NQXrisn7VcqJ8nlthh3OuruH/hDtJt8oW99vshqg2OQ2M5pVXW4UXboAuwm7h/4HQJX2w4AZgWKkzuHc63W9P4elOq09WOtiwJZi3qrs7cnVEMgLt5iPSz9abn1N3D8lBWCU/9dw9P/bCn3mc98J8d7Eirf77cKZugzJJfzTYotJ2rll5QQXWNEZ3eYA1azpRW4ZbPtnDJu6aARlVVklMLnAZpBfX0xr3751GqDUa7wLAu2zlwlt0XFidn8J8t9r11u9Jq5/+pqsribekO95rx4Qa+2ZzGigPZ6A1Gp6sX0/JNP0Ne2tYf0rT+GgohhGgyXTv54K5x4+0bhljncc0cWTtRP7ukNtiwTMgHeGRKT1Y/kcgLl/djyUMTePHyfrx0RX82PnMBj1zYE28PDdcOj2b7cxda840B3Dk+nr9faRrODPf3ZMmDE+zqs+VEAU/9sJs/D9qniPjz8UncO6g2gKyodhxetHXLaNNw5kZzyopOvh58cNNQuoX68vzP++n+16Xsyyx2em2Nk1WXzhiNKj51Et9uOJbPJ2trk8VaAo5sm6DN2XCqpafMwmBUrcGPJdGsrdd+P8TH5uS1toln0wsruePLrQx66Q9rMFZf0FU38Ew6nMu1H23iG3NvGpjmzn27NY1hf1/Bjzvqn6RecoZ5ebbD09MGRFpf103IW2TT87V8fzZzf3VcEWsrr565YEeyTYGpp7sGvcHI7V9s5bHFu5o8b1tTkKBLCCE6gLmX9+P2sXF2KSq6hfmR+vql9IqoHW4M8DYNI35372hGdwuxHndzU6zzxQDuGBfPbWPjiAryttvWyFlPm2X+U1iAJ307+1snvoNpYvri5AzrSjeAJ6f2pnuYH2Oj3K2rMi2T7+vrsRoR14m/Te8LmCbWe2s1+Hi4c+f4eGsZ2xxildWmFYgAX28+yTpzwtk3rhno9P4AFXqDw24DYNqoPNtmKyYAjc1oYHphhcM1tt8BwJ1fbuPCt9dQXKG35lKr67XfD7E5Jd9uxV56QQUbjplSVxwwDxtuOp7P3F/2OwQd+WX2vXeW3jzbVaqvLDnAsz/uBWDNGYbrzrQYwHahRNdOPnQPM/3c1F05a9trleHkO6o75JtTUuU0se4Oc4+Zl9aNrGIdSYdz+XFHZqtML9GooEtRlGmKohxWFOWYoijPODnfVVGU1Yqi7FQUZY+iKNMb8zwhhBDn5/Zx8cy9ov9Zyz1zSV++vmsko2wCrsYaFG3qMbugdziKolh7i2JDfOzKeWndODxvGnMSu1uP2WbsPxNvrYap/U29Kp18PayBoGWrJIACc6CwJ6OIq+dv5PIP1rMjrZDf95nmW92QEMMNThYATDQnqd2ZVljvysAXft4HQH6Z6RnubrW/Xo9mlzmUL3GY35TL8dxy7vsmmZLK+nuRZi7YzLt/HrW+dxas/LbnNF9uTOV4rn2voO0Q6j//OGztNbLNpWYbGNkGuEmHc3ji+9rcaPUFNDq9wa43amjXYP58PJEuQd4Oc8ksz92bUcy8JQcd7mWZgG8Zzs4prbIm7nXG011jV6+8sqbfj7OxGj4zsg5FUTTAh8BFQAawTVGUX1RVte0ffA5YrKrqfEVR+gFLgbhG1FcIIUQz8vN0Z0LPsLMXPAeJvcPZ/eLFBJq3PiqvMvVgfHZbAim55bz06wEyiypJiO3ksPIu0mbVZCdfj3rnGnl7aOga4kP/qAC7BLO9bXrxjuWYgp8rPqidrP/5+hPszyzmhoQYXrva1Mv124Pj8dJqWL4/i8TeYRzPLWftkVxmmZPI/mVyD0bGdyK9sIIQXw9+2X3KmpjVMrE9o7CCd1YeYdPxfIceGzAFLVtS8gny8SCmkymPmrdWw+aUArsexjPpE+nPvsz6J8VvSy2gR7if9b3tKsL3Vx3jznGmXkC7FZ42vZa/7TlNZMABnpjam9u/sN/r0FnQtfVEAdd/vIn7JnYD4Is7RjAyvhNgase6K0mLKvTsy6vhrWXrndbfUv7uCfE8+t1uckp1DkO1/ToHWHv4qmuMdvXKL6uy+/ytwXkHXcBI4JiqqikAiqIsAmYAtkGXClgG9wOBc0/8IoQQos2zBFwAX945gozCSnqE+9Mj3J9JvcNYfSjXYYI+1AZNWo3ChJ6h/LzrFJEBXmSV6Aj187D2Zlh6z96dOdQuS7y7xo13bhjCP1ccZsWBbIf8Y7/tMa2gnD6os3Xo1TKXrUe4Kft/Tp1J9QHe7tbeL4C1R/OsQ2WWIbxTxTreWVnbIxXu70lOaRVDuwZx6HQp7686xvvmlZUrHp0IwNXDurBwS5rddbZeuqI/L/6yH4Dlj0zkg9XHzphPbf2xPG4c2ZXp765jWGyQ3TAywKpDpnl0KbnljHp1JdMHdqa0ztDmp+tP4O+lpS5LcLPqUDZxIb50C/PjD/MKzY/Nc9xibfYOjQ3xcZg3V1RZzVvJ9t+tLcsG7IOig1AU8/BinaDLMhwOUF5dYx90nWNaD1dozPBiF8B2qUGG+ZitucAtiqJkYOrlerARzxNCCNEOjO0eyvU2WfY93TVMGxBJTCcfh7LhAV5seOYClj40gbmX9+eyQZ15zDzP6+ph0XQxZ9u39JD1CPez25MS4MqhXXh35lAAHvx2p8MzQv08GN8jtN761k0mW1hnBV2wj5aiSj1Go1pvT9zVw6KZe3k//n3zMIeJ7td+tAmA6QM711sHgAv6hONtTojbLcyXuBDH78tW0qEcdHoDB06X8M3mNIe6peZX0M08Ty+7pIovNqSSkuu4UOFfK484HPt4TQpFFdXc+WUyU95eQ2F5Nd/VWX1om2bkxcv68+mtCTw5tbf1WHrBmXOorTuah6JAt1BfogK9Sckrd5jT9dyl/bjfPBxdUWWw2+ex7hy21kA539n9iqJcB0xVVfVu8/tZwEhVVR+0KfOY+Rn/VBRlDPAZMEBVVWOde90L3AsQERExfNGiRedVp3NRVlaGn1/r6nYUTUvauH2T9m3/ztTGRlXFTVEo0hlZmVbDVT20dsOKzvx2vJofjjoOiw0I1fBEQv1zx9JLjTy/oTZAeHqEF31DaodBl6fq+fZQNR9O8eEf23ScLHGc9/WPid6E+5j6OW5f5nwF5juJ3hwuNDJ/tylYuCjWnWHh7ryxzTQs+PGFPugMkF1hpFewhp05Nby7w1T2seGebMsycCDfQL5OJdpPIaNMxVMD5tFcLop1Z8VJ+6BlWLiGmX08eGqt8wAoMcadpPSzZ48fEKJhX76B6fFalp4wfccfX+SDp8a+TWqMKr+f0JNZZmTz6drg09sdnE1lC/NWeHOSD+/t0LE/30CVAfqFuKEADwzxwkdruv/b23XsyTU4XHtBVy1T49zrzXPWFCZPnrxdVdWEhpRtzPBiBhBj8z4ax+HDu4BpAKqqblIUxQsIBewyoqmqugBYAJCQkKAmJiY2oloNk5SUhCueI1qOtHH7Ju3b/jW0ja9s4P2GjKzmh5dXOBzvGRNJYuKQeq/LKKyADasBOPHadLvVmgD52zP49tBuasJ6cbJkl8P1P84Zy7CuwbUHli2xOz8iLpinpvVhRFwnckurmL97JQCf3D8VgPd3L6Oi2sDUCyfbXTewrIp3d5jKPnTdhaZ7vbISdFXcMqE3r/9+yBpwAZS7BwL5dvcY3rsr10/vx1Nr7etk8crNE1m65zRZJTprbjJb/aMCOJpTxr58A70j/Pnw3gkczy1n9aEcpprndtV1IbBoaxqbf9zLsyO9eG2rjhpVYeHdI9mbWUyPMD/uNidDXTh7Ar0i/NlRfZgd5uHYcf1i+dul/ezu+f2pHezJrU226+uhIbfSwHGdL5MTxzi0WUtpzPDiNqCnoijxiqJ4ADOBX+qUSQOmACiK0hfwAlp/ylghhBDtjiUJrFaj8NZ1g60Tvn09z7xtjr9n7ZwmZ7+8g31N5x9etIuIAE9WPjaRz26r7fiwC7ioTeJp2ag7ppMPI+JME85D/Tyo6/eHJ/DF7SMcjof4eXLTqK58eNMw6zFLGojekf7MntTdrvzG4/YBF0CceXjxm7tGOZwDiAzw4p6J3XjeJsnta1cPZOtfp5D6+qUseWgC1w2PBmBwTCCKotAj3I976gm4LG4YEcP+l6bSM9iNaf0j+fz2EYzrEcrsSd3xMKfTGBEXbJ2HdnH/2nxftjssWI9p7dvwxpFd0bgpPH5x71YTcEEjerpUVa1RFOUvwHJAA3yuqup+RVFeBpJVVf0FeBz4RFGURzFNqr9dbY3ZyoQQQnQI65+ejL+nlkAfLXszivl4bQqXDow64zVnC8qCbTL6z0nsYV0gMLBLoDVxp61VjydSXKlnc0o+L/16wLpxOZiCOnc3he5htcOqsSG+xIb4OtwH4NWrnOcV6x8VwOTe4dbJ6PWJN993fM9Qu5WAAA9N6Wk3ZPt/d46kusbIRf0i7O7x1NQ+ZBXruHVM3BmfZUtRFHw9TcN+H80abnfOaA4TbL+DAV0CeWpab/6x7LDTBKl1k9Y+d1k/Hru4l9MArSU1qjaqqi7FNEHe9tgLNq8PAOMa8wwhhBCiqUQH104+HxgdyPFXp591Lpi7xo0+kf7WLZHqCrVJCDume226h5/mjMVZLteoIG+igrytKSx61klrsO+lqWet09mE+5vmqD10QQ/eW3WM6QMjWbo3CzcFuzrZLl5wt5l/NTw22LpjgcWkXs5TiQT6aPnMSU/c+ZrYM4znL+vHzBExdsctiyacLVY4Ys6FduPIGC437/nZ2gIuaGTQJYQQQrRlDQ1ulj0ysd5zMZ18eHhKTw5nldoFUO6aM8/guWxQZ7y0Gqb0Cbc77qU9c8/amXx2W4JdpvdHL+rFg1N68vn6Eyzdm8W0AZHcN7E7sSE+bE7Jtwu6LD1Mfzw60SG9hCu5uSncZbOTgMXU/pFcNzyah6b0dDh329hYThdX8uLl/Rv1/TU3CbqEEEKIRnq0Tq9QQyiK4jBU11hT+trfT1EUtBqF3pGmICqrWMfgGFOWfssm5hbvzhxKal55iwZcZ+Kl1fCmeVP1uqYN6OzweVojCbqEEEKIdq6nOZCyzfBfV/cwP7t5VKLpSdAlhBBCtHNdgrz58o4RDI0JPnth0Wwk6BJCCCE6gMTe4WcvJJpVY/J0CSGEEEKIBpKgSwghhBDCBSToEkIIIYRwAQm6hBBCCCFcQIIuIYQQQggXUFrbVoiKouQCJ13wqK6YNuQW7Ze0cfsm7dv+SRu3f+2hjWNVVXW+R1IdrS7ochVFUXIb+iWJtknauH2T9m3/pI3bv47Wxh15eLGopSsgmp20cfsm7dv+SRu3fx2qjTty0FXc0lC6NuIAACAASURBVBUQzU7auH2T9m3/pI3bvw7Vxh056FrQ0hUQzU7auH2T9m3/pI3bvw7Vxh12TpcQQgghhCt15J4uIYQQQgiXkaBLCCGEEMIFJOgSQgghhHABCbqEEEIIIVxAgi4hhBBCCBeQoEsIIYQQwgUk6BJCCCGEcAEJuoQQQgghXECCLiGEEEIIF5CgSwghhBDCBSToEkIIIYRwAQm6hBBCCCFcQIIuIYQQQggXkKBLCCGEEMIFJOgSQgghhHABCbqEEEIIIVxAgi4hhBBCCBeQoEsIIYQQwgUk6BJCCCGEcAEJuoQQQgghXECCLiGEEEIIF5CgSwghhBDCBSToEkIIIYRwAQm6hBBCCCFcQIIuIYQQQggXkKBLCCGEEMIF3Fu6AnWFhoaqcXFxzf6c8vJyfH19m/05ouVIG7dv0r7tn7Rx+9ce2nj79u15qqqGNaRsqwu64uLiSE5ObvbnJCUlkZiY2OzPES1H2rh9k/Zt/6SN27/20MaKopxsaFkZXhRCCCGEcAEJuoQQQgghXECCLiGEEEIIF2h1c7qc0ev1ZGRkoNPpmuyegYGBHDx4sMnu15K8vLyIjo5Gq9W2dFWEEEIIUY82EXRlZGTg7+9PXFwciqI0yT1LS0vx9/dvknu1JFVVyc/PJyMjg/j4+JaujhBCCNGyCk7AsZUw8p6WromDNjG8qNPpCAkJabKAqz1RFIWQkJAm7QUUQggh2qxFN8PSJ6A8v6Vr4qBNBF2ABFxnIN+NEEIIYWaoMv1Zeqpl6+FEmwm6hBBCiCZh0MM7g+Dgry1dk3O39RP49KLG3cNogAWJsP9/9ZfZ9CF8ckHjnnMuvr8DVrxof2z+eNi50LFs9n74Z19Y8oTze/ma85SWSNDVYfj5+bV0FYQQQjhTlgNFJ+G3R1u6Judu6ROQsbVx96jIh1M74fvb6i+z/K+Qub1xzzkX+3+EDe/UvteVQPZe+HmOY9ncw6ZerG2fOL+XT4jpz+KMpq9nI7WJifRCCCFEk6mxzIF18dQMgx7K8yCgs/1xowHKsiEgquH3MhrBzUm/SVWp6Tk+nZw8vwYq8qCyyPk9q8shay+oau2x4gwIjG54vepTVQaG6tp6GQ1QloNvWarz4MjSS+UZaPpTVU3lFMV0rYWqmo7Z8g4y3yOz8fVuYm0v6Pr9GdMPRSN5G2pAY/74kQPhktfPWP7pp58mNjaWOXNMUffcuXNRFIW1a9dSWFiIXq9n3rx5zJgx46zPLisrY8aMGU6v++qrr3jrrbdQFIVBgwbx9ddfk52dzezZs0lJSQFg/vz5jB07thGfXgghOrCqkpZ57qp5pt6cJ46Bn81Wfcv/Blvmw1MnnAdLztTowMPH8fhH46EwFeYWO55b9jRs+xRuWlx7TFcMXubA5s+XYctH9tf8qz/M3gCRAxpWr/rMH2vqXbTUa8ULsOkDRgA42/mvxByI+QSb/lz/L/jzJdPryIG15SrywTfU/lpLUFZyunF1bgZtL+hqITNnzuSRRx6xBl2LFy9m2bJlPProowQEBJCXl8fo0aO54oorzjqx3cvLi59++snhugMHDvDKK6+wYcMGQkP/n70zj++jKvf/++Sbb9bu+5LuC4W2tIVSEKQNIJsLiICCioAoer2Iyr2I20+5oBeBey8XFRVUEBQELopUZJGloWwtXWzpRuneJi1tmi5pkmaf3x9nTubMfGe+S5Jmfd6vV16znTlz5jvfZD55nuc8zxAOHDgAwI033siCBQt4+umnaWpqoqqq6pjfryAIQo+ltpNE1+5/6mXpMpj2UW//P/+ol031yc+3LVBRouvgdr2srYS8fv5j6xfq5aGd3r7q/Z7o2r8JhkwFlQXl73lttrzSdtF1KFCecOPzydsbS1e+K7qW/c47ZhteDpcmii5jyWyoznycx5juJ7pSWKTS5WiGebrmzJnDvn372L17N+Xl5QwcOJCRI0fyrW99i8WLF5OVlUVZWRl79+5lxIgRSftyHIfvfe97Cee9+uqrXHbZZQwZor9Agwbp/3heffVVHnnkEQBisRj9+/dv5V0LgiB0U9b+BUafBAPHZ37uppeg32gYfoLerjvStrGsXwjDp8PgSd6+gzt0DNSAcVBfBRMXJJ438kTY9hrsXqlF15ZF2rJV747HaU5+3RorBUKjO0OvvgZWPQpzr/O7G8uWw6SIQHjb7VZzQN/H1hItrqZ9HI4e9Lc3IsdxYMVDMPNyyOmj16d/ynPnNdTCP//gH8uRD2DbYq+v5ibIiiW/T4DD7hjzjKswIj6rsgxGzdbia9dSmHEpNNZ74+lidD/R1YlcdtllPPXUU3zwwQdcccUVPProo5SXl7NixQri8Tjjx49PK19W1HmO40j6B0EQhCCN9fDUtTBgLHyzFeElj16ml8a11VbR9eRV/v4Afn0m1FnbYe69WK5e7l2vl3/4pP+4HasUxpEPvHVjzXntp/DmvdraM/0SiBdqC8/+TdGi69Aub/2o9qjwiBsa0290ovvViK7tr+vJB6XLYe4X9fr2N+CyB/XxxXfB6/+thdKJl+t9j30a9qz2+qo9HO1CVZZo3L9RL5sb/Ra+IEaIPvRRbU07/mIvZURDTfR5nYTMXsyAK664gscff5ynnnqKyy67jMOHDzNs2DDi8TiLFi1ix44dqTuByPPOOeccnnzySSoq9JfIuBfPOeccfvWrXwHQ1NREZWUnmcYFQRA6A5NvKSoAPFOORUxXXUBkHQ4J4m5u0Msoq01zY/JrGIEElqXLdaFV7dNLI1yS3aMduF4TSCBaOBSyAvaY/e9rd2VdlXeOua4tBM0Y6q0QmCN7/X3VmHsIEVJGlALscmdoNhz19xekyXym7ufdeNT7bBq7nqVLRFcGTJ8+nSNHjjB69GhGjhzJ5z73OZYvX87cuXN59NFHmTZtWlr9RJ03ffp0vv/977NgwQJmzZrFTTfdBMC9997LokWLmDlzJieffDLr1q07ZvcoCEIv5W/fhLd+kbrdmqfgqeuO/XhsjIAxqQDaihEk1ft04PnhUnjldvj5yfDct6PPK/kp3Heaf9//XQOrHktsG5bWockVVVH5o1K6F23RdVQvc9z0ROuehj9d6e23rXkHd8CvztD3C7BrCWTnJ/apB5EoupxmeOQiWoTS+y/A8ge942/8r/5szPjt82M5gXtIkiW+qQ7KVsJ/T7NEVG3IGC3+fhOsfMS75s9O0hY50IKtiyHuxQxZs8YzbQ8ZMoS33347tF2yYPdk51199dVcfbU/d8rw4cN55plnWjFaQRCENFnxkF6efkPydn92Bdelv02cqn+sMCKlcGjydmE0hwgZW5B8sEbnfXr9v/R2xWb46F3hfb39y0SL1rqn9Y8hlqvFQ8WWkLG4Vpnqcs8a4zuewr0YZunKdUXXzsA7xZ4ssOkfsHet//isz8DKP+g+7c/o1K94Af+GAWP1viPWbMD1VmLVl92kpideoZd2zFYsHn4PYS5Dpxme/7Z3ndz+2kV4NInoAlj4dU98GmEJXVJ0iaVLEARByJw9q47dS62+2i9KjNUop0CLmagYn7oqz91kaAwZ496AtyDo1mtqTAwmB080tYwzJGbIxBMZoVh72BM19nXCckg5AdHlOHocTY1aKPoC6V3XWTxkBiP4heWupYnHT79Rx1bVHPBm+Z17u57JGAx0v9SdORiWwb58Y+L4lS26gpauA+5nG/EM7WfbZ5gOhk9m6TKEBeeL6OpdrFmzhtmzZ/t+Tj311M4eliAIQtt5oBie+Pyx6fs/R8HvztPrFVvgnQf0+tYS+PlJ2r0Vxh2jvaB5Q/DFW7YSNr/s3xcUXTvfgjvHw6o/+fcHBV2y5JuVZTrG6adj4c17Es8PczEGx7Hi93ocv/8o3FEUcC/WhZ9jsGO6doW4OgsGQf4gbUUyVjGTYiLoXhw5Sy+N286mZn/i+JNZuja/pO/JpLYIYrtY+wzXlq60RFeI4y5McHcyIrqOITNnzmTVqlW+n6VLQ/7jEARB6I4cizIrxkKzZ5Ve7t+U2MZOQRBka4l/Oyi6jGXmsofgU24ZmaYGPWvPsG+DXgYThQYtXclE1+Ey71rv/8M93xJIVfsSzwm6F404NJYq22JlLF1Rub3M53hkr57VN2Sq/3huf8/SZdrmummUggImOxfO/Lfw69gY66B9n0FLVybJzfsM0/eZyr0I4aJLLF2tx0k2ZbSXI5+NIPQwmpth9RPw3nPhL2fQbpg1T7XtxbJzSbioKV0O+95L3N8WyjfCrmXJ21Rs0YWWXWKN1bDE3e4/xmsX5i6Lwv58qvd79fqmXgAjZ+v15kb9M2Cc3jZuPFsgbApYx8CfeiEnUG/34DadgR685J1NDZCdp9ftWX+G1Y/rNtvf1JMagoKlbIV3HZODKmh9A52yoeaA/g6Zz2rqBf42WVna0rVrqc5ED5AbYekCGJPES3P6jXpZVe6OyRKCwXtI+X213YvD3UD6ClKWbAq1dNWGx/R1It1CdOXl5VFRUSHiIgTHcaioqCAvL6+zhyIIQnux5kl4+np4/Er446fC22x7TQe1v/wfrb/Og+fDL+Z6s+oMvz0Hfhnykg2+wOozyPh93zz43UeSt/n5SVByh17vN5oJ2/7kWbUGjPXafbA2Ma4r6v1gu5j+9g2viHNOgecGa27SoqvPML1tZks6TVrU1FbCo5cm9m1nWe9r1VMcNUenOdi1RG+bfpsbodBdPxJSombpr3S5mz9+Cv7xfV0EOkif4e59uaIrGJAfy9VJWPdv1N8hM0FiYnFiXwUDtUDa+He93SK6QuKjsnMT94EWO2M/pNeryxPHZLsX8weG3zfAhPl66YvpcidOVO3VYtO0CR1HRMLVLpY2Iq3Zi0qpC4B7gRjwW8dxfho4fg9wlrtZAAxzHGeAe+xq4AfusR87jvNwpoMsKiqitLSU8vLyTE+NpLa2tscIlby8PIqK2qEgqSAIXQP7xXQwIv9ftRtLUxViMcmUdF9MwZl7mYiuTInn49jJMrOtv9dNdfr+7fqFtkuroRbibnvbshK0shjrSHODFp5G0Nhuw71ro/OD2c+m7wiocK2Gp3wJjv+EjucCr8xOc6N24WXnR4uP0uXJn0fhEDiwxRM2tqVr7nXw0bvhhe94YnXvOn29sGLawRQcUe5F8H/+AOf/J5z2NT2D1cSMGdFlj8m2dOX0DZ+gcPNW2LdOj9mO6cpxx3P0kBZ9V/9NW+Ve/+/EPlSE6Go4Gl4uqZNIKbqUUjHgPuBcoBRYppRa6DjOetPGcZxvWe2/Dsxx1wcBPwLmom2GK9xzQz71aOLxOBMmTMjklJSUlJQwZ86cdu1TEAQhJa/cBiNOhOmfjG5jW56CLztDS9Cya0nY8qrOnaSy4OJf6pfbi9+FT/5KZywfMRNOuNg737ZG2Ouv/sRbf/xz+iXoNOuXedCVZWf83rJI19OLSrcQxbqnYf9mWHCzf39jPbV5lqgylpaB43UQdsUmeO7f9ZjmfhHGfchrW1nmleixhdaQKbrUjcFYYYx70aSksGPVdr2jZyCGcSggugw5hZ7QAm29MmIqlq3FTph7EXSG92QYofTmvbD6MX96h9pD2uKTa5W4q9qrrWs5hYl95QcywxtxkhVPbBv8HmbneSlDWsSba6Xa8aa+D6X8AjJsDKA/EzML0/5Oxd1cYrWHPfEWJgjtawfpYsH06Vi65gGbHcfZCqCUehy4GFgf0f5KtNACOB94yXGcA+65LwEXAH+KOFcQBKHnUl/t/Zc+PeJFDn6rjXnxBDECyLyE/nCJd2zqhbD2KR2IPeuzsPhuvd8uTeObCWe9GBdboum9Z711FYOzvqvXR52kLS6b/uHV0jMlbTIVXWuegj3vJoquhhqUSUFw8X26fiLA4CladC35JWz4m9638e9wy3bvXHvmni26zGf2uaf00nx2TQ3a2pXXXwuUCivOrWpv9Ow5O97OFjpxV1x85o/eDM/tr2uL0/Dp2q0XlSC1oVp/1sH0EQYjlCpLvcz2+YNg1hU6xxYkipvcvjom7sM3aYE9yXVMmZqJo+fqmK3+rmUuHUuX7TY0bkmD/b2xibI4ZWV7Y7atiuaadUcgO4Xoiqqz2MWC6dMRXaMBK1qQUiA0ok4pNQ6YALya5NzRIeddD1wPOhFoSUlJGsNqG1VVVR1yHaHzkGfcs+lWz9dpBhT9D6/D2NeTjX3SlvWYsPHq+maWhbQdVbaWqcDufeW8v2gRxdax99f9kzGl75IPrF3zLjPc/a+9+jKO+9IqrNrOKe7+pW++Fv5H3aKqdD0b31nCycCaQR8l/+huJgOvv/oiTbH8luuXLFoUmjTVHH/t1VdwsoyoyGL2nq3kHz3C2yUlvntoqq2ioVa7LxcfGMq08nKGAbtq8xgDNGxahG2PeWvxIk5311cuW0pVn3KymusZePCfTAeaVTb7dm1jQO5QlpTFoayE7IYjfBjY9P57TG5qZEfpbgrzJzDUSrC5c/s2cuoPYdmxWmg4sq9lDDv3HsBEnf1z/SYO784B+nJ6vD85Da7YbTzKoaoaHJXNwEMhyVNdDvedTP/KjaHHdu2vZLSKkWWJsvrGJt7KOx9Wbwe2U7SrlMnWOZUNipWvvQbZC/RbvwwoK2FU2Xr9HWoexPt558Fi7ZKcVLYHa9oCJSUl5B39ADsX/4b3N7O3sgSArKY6kkRbtXCwuoGBIftfe+MtcuoP8SHAqaloCZlf9977TAeqD+4FHJaVlDB2x04mhvTRePRIqKBZ/vbrVPVNMsu0g0lHdIVNGYiKaL8CeMpxWr4NaZ3rOM4DwAMAc+fOdYqLi9MYVtsoKSmhI64jdB7yjHs23er5/uZsPXtsqPufu4pFj335Q1C6sGWzcMCQ8LZvvgubYNTosYw6+Th4zTs0dfxo2KSFw4xJo8DNBbrg+GE6yBpg2+uwXK+eevIsCEnlZNOHKk6eMwtWwszZc+DQYNgCZ85zZaR7/eIF88ODmkvcMZw+F1Dw0zFw7m0Qb4KGLH2Pr+e2JBeNNddyfNmTAMwvPhv2/xHKYcz0D8HeV4g3+Kt+nP72tS3rJ82aCc98TVvE5uuyPlnZuYwY0h8aB3ifZ20lvAlTJoyFzc2MnzAJsk+Al90Zf9n5jC0aBZUOBEoIktufuBXjNnZWMezSyUPnzDtdB9MDrOwLDV67AQMH69ixQ+9Gftb9T/gILHFFV1bcl6pizMTjYN8iqPeSn+bE8H9Hlm0GS9P1GzIq/Du04Qhsup9Rsz/CqFOt4w2LtIkEYPgMfW7lHrAmjR4//USOn+me4zjwuiJUGljjHzhsdOh9Lyg+R9/PElBWH9NPnAProTDbgXz3ub2xCrYlXia7OWDRKhwK1eXMnXUCjD0t8YROIp3Zi6XgE71FQIRdlCvwuw4zOVcQBKFncnAHHNjmJZJ0msLLwIDnRjNkR7gXjQtNKX/JF9CZ0k0QerWVvPLQTm/9aIR7MYrGOi8VQFbcSl1Q4495SlW0ub4GDmzV6+8+qcdh3H62i84mK9sLsI4XaPfgJ+6NvkZTvZd80yxj2drVZLtrjavKPIusmD81RSxHu0/DnpVxzQHMvBwmWzMz8y17Tixg28jKhnN+6G1/8tfwiZ/52/S3JkbZsyJBu+EKXBejmdEZnH0adAUG3X+GaR+Hz/8FTvly4hgBhk7TwevgTUwItgH9HYyK1wqOPYysLC9o3vCN1Z5Lsf5I6pguOwD/2ud1mSrwinR3EdIRXcuAKUqpCUqpHLSwWhhspJQ6DhgI2AWgXgTOU0oNVEoNBM5z9wmCIHQP9m3QgqktOE1a2NilWaISaxpLlCE7V1sZTKqD9/+hRYrpa/ubiUlKG2q82Vz2LLnKMp32YeML/jil0uWp76Gx1hNHsRwv8Lm+yh/8XL7RSy4KWvTZxZHrq71ZboVD3TI3rpjLDeS6An0fSvlF1/gz4ORrosdq54ky4jQrrsdpiy4Tl2REZ1bcEzSgRVhzY7gotdtNOsefUsEOUFeB12wsDgPHedsDx3kZ38P67htwbMYLPcFrYrCCSVvTFV1KweRztOixMcKmaK43loSYrkD+rahyRPbYks0itIXX0Gl6woS5Rn11GoH0FuNO92ai1lUmb9vBpBRdjuM0AjegxdIG4EnHcdYppW5TSl1kNb0SeNyxkmm5AfS3o4XbMuA2E1QvCILQLfjlafCz2W3ro7lZW0ts0RVWEBkS8yHFC+B/Z2gX5ZZF8Njl8NpdXl/lGxJzSNVVei87O2D7cCks/x386TOw7Hfe/ue/nfoemuo9MROLe1aL+hq/KLn/TP2ZGZY/BM9+y9tuqPZm7sULtKgx/Rox0ccSGi0zDN2oFdvictrXwsdab1k3jBUuFndTSYRYukwQdla2XzC1iK4wS5fdLtsvQmyLXTB/WHBmYCw30R1rp3LoO9x/LKfQ+wyMRSyYlT5BdEVYEKNoETZWhFAs8L0MlvdJZemacp43wSAKU4bI9G0+0+ZGK5A+IjWEwczQNULT/p3rAqSVHNVxnOccx5nqOM4kx3F+4u77oeM4C602tzqO852Qcx90HGey+/NQ+w1dEAShm9DcqGOVaith8GRt/SiNyM4edM8p5e0zrsIDW6LTGIC2jBmCli7jbqvYnP74P3KrXpoXmD3brL7ab+kKEizhUl/tWfmMhcVpdhOUNsHxF8G5VsJXIwCMpct++V9wR7jFy54BZ/JCOY7rXrSsLUppS5pJKxALWrqyoy1dQReiLXTsiQTBWYhB0ZCdm5hjyhZ0fQKWrpwC7x7Ccm9BoujKi7B0RREmbKKsYYYoSxfo+LbP/Z/3XRgVka7JiEMjtmwhm46la/bn4dOP+PvqbpYuQRCEHskHa+GlH0VnMs+Epgad7dyOmbIxMVx1R3SMzvDpuvzKkl97dfkMwazvYTFSjpP8P3jbuuWzdJV595tJ/iITV2auaVu6DmyBp7+aeM7r/61TVgRfevU1nuiqsVI2NjVoi00s7hcNRgAY0RUUBGGfj52A0wiw5kZ9z0FBkpVtWbpiiRas5qbwdARBcRZ0txmC36+ghSg7zNJlCbqglSpe4FkEo3K4Ba2lrbZ0JfndCN5HVIoL8ESl+f0omhferiU5a8DSZa8nE132mHL6AKp7WroEQRB6HL//KLz5v+3zR3nvOljxe3j8s+HHjbWkrlK7PQZN1NaoF27R7sJgW4Arn9BL23XUYkFx/AHyQWqsY3YSztpD/oDjdDEvceO2y4p7Vpbnv+3FaNm8chv88dKQIP8qTxTZ2fSb6rVLNJZD6MvejDuYjiKs9mDtocT15sZESxfol7gRoLYFD7QYMvF4o+fCrCu9Y7alKys70RLUMu4I96IRIrGccEvX5/8MC76TKKBUTCeqPfEzMO1j4de0XagnXwOTzw1vF0U6cVNBkRm0BppyR3Z/F96lx2MnsrXJDbgX7XtPS3RZY8rK0iIu+P3rZER0CYLQO2l0xUxITqmMMS8Cu0CyjZkBV1epXwRZ8ehZfk6T7u+4C3RNO1vQmLE6jpcYMwzzoikcSouAye2nX4ytEl0mSaUrumJxLTqGTE19btAN2lDjxUjZyUWbGvSPib0yGM1iLCnBwPRQS5cluowYaG5yA+mDAeHZ1uzFuP/70OJerIOhx8Elv/aOBS1iUQQ/bzObscVaFWLpyuuvZ0Oe9d1EixLAgDHwqQcSy/gYbLHyiXth+AnR4wsjHdEVbBOMe7v4Pqute38jT9TjiXJFJrgXrXuPpRHTFfyscvuKpUsQBKFLYF7izUncIukSnD3mO9YMOJ57MbevfjlEndPc6L3QsrLhYIjLcv1fk8d0Nbg1EQdN8vbl9ddjyFh0Ke8lbrsXIdpNZGOXqQE9biOEbNdjs3Ev5gRikFzVNXC8XuZZqRrAn+Kh5RohtRKbGxMD6cF1L1qWruCxtX/WAjdocfJZuiwhELRaBT9vY+kaNdu7RlBIqCQB7HZ5oajZgFFux3QJprkIbRMQOEHRNcgq3Re8vyhXbEsgfbKYrkxFV5Lfk04grYLXgiAIPY7mdhRdwTxJNkbcNdZqC1ReP+3Oiipb0tzkdz3ZL41Mxzp4EuxaotfzBsDhXW20dFnpFyBxZl0YwZiuD9aE33tTvbZ0ZcXhuI/CuDN0DT/DBXfqBLOjT/Kfd9b3dKzQur94+8IKVDfV62eR4F6MeyLQiI3rX9PtnvISriadEWjE2rUv+HNsQYjoctt++hFd17FwiI61M5gSRQYjNk74JMy8DMac4h2Lmg0YFIiZYr5/ycIdg7Mwg6Kr/xhtlXSaE8VslCg0gto8B1twpioDBIliLrefWLoEQRC6BEYMJQsAThfbanVol06G2nLM7b/2kL6WcS+GWaqqynWeK/NiSWVNSMUgq2BK/gDX0tWK+zUuuXrLvQjRdSGTsWtp+GzA8o1aoMVcF9/My/R+ExOVUxAew5Sd64+1gnDRZe47NJA+YOkaNRuGTvW7MoPn+WK/3PPGfUi7/nzXDboX3c8ufwBMPc8937LejDvd396Ijew8OP4Tgb4iBEhUQt10Cbpww0j4bgaeaTzPE0FB6192hKXLuEvNPzGh7sU0A+lBYroEQRC6HO1i6bKC3f93BtxrJTg1L3sjsnL66BdHU4iAWvRj2PySF5SdEDcTeLGN+3DycQ0Ouhdr9exBQ1RMkM28L4fHdEHmL/cB43SqijDB+agrshJcS2nMLg262cLciy1tAwlYs2JWctQQ96IhQXT1CW+XQDCQPqStvS9hDEZIJPkcpn3cv91WS1cLgWv60mQEBM4p1+nl8BlWG3ccwXsKukwNZkZoi7i33Yvx8L5sgta3LhjTJe5FQRB6N6nK1qRDMvdisP9YTnhwNHhZ4qMsXXY+rI/9j54J9sCC6AD+/mO82nd5/QHHL0gmnwtnfAN+FTGbbNaV2q23x43LsmcvQuaWLtPeTukQpMWi4V4jnZQewcSc1KZmUgAAIABJREFUYZYuQ79AWZ2Y5V4MvrR9YihgrclNU3QFRX3Ys7ctSwmiy7j6Ij6HH+xL333XVv59E9w+xB1X4D4uuFPX0syKe/9otAilkNxkYZjJCS2xg7boMgIuWUxXwIJ2wR2tc6cfQ0R0CYLQu2mLe7FsJbz/Amz4W3SbsJdu8MXxjx/ol2rQ4hJ8ibxk1ezrM0z3E7Tc2MTztcg4tNOLl7HL/+QU6H6iyM7TVrcWS1cgkD5T0WXuy47zUjH/M2iJ58ng9RSMbapPYt3oNzpxTMaCF3wutpgJunZt4ZB09mI6li47ED/ogEoxuzZMwESJ+nSJmtHrc/cFBWoWZJnvQ7Z/bOkG0hcERFdWFvr+nWhXZdT4IDp5bCcioksQhN5NMvdiKivLb87KvP+seOKL962f6+WImXppXixBa4KNse7YMx2DVrXsPOhX5Ioud9ZbTYW/j/xBMP1TgAPrnvafbwSAL5BeeS/RdEXXgltg2+sw/ZOJJYcKBvnTYgQtXem4F+2AfmPZi+XqpdOsg+KNlTAY6J4V92ek9x2zXvDBrPv2s8nIvRhm6bJFVzukMGmPPlKRVi6vCJdglCUuaOkCt+6mk14gfbJ/ILoIEtMlCELvJpnoskVMazPXBy1psXi0mApaXJJZe4x1J1l8VXYe9HctO/khlq54obYmXP4QjDkt8Xzz8rZjumxhkqz0i82QqfDF58MtD3YKBEjM0ZTO5x6WRqFgkOdasgs+Fwzxn5sV89de9B2ztuuro4+1Jk9XcAxR2AlxuxLpWNOMSzBonYo618QY2rUzzfNPJ5A+nRQmnYyILkEQejfJ3Iu26Gpt7FeoezHixVEfEF2ZWLrCZoRl53lT940wsVNQ2LFQYbEvhUO9fkDXzrMnDSSLHbJFYEsi0BBhmBuoC9hS7DgDSxd4L2VzDTt5qcn/FC9IzByvlDepIVlMV1AcJov3shkwLnBeyDNNajWyEuJ2JaJchGFtEgLpI77XJlC/78jEY+mIrmC8XhdERJcgCL2bZGLKLjGTabqGqP6z4tEWLLugNCR/sRmLjnmJZ+fpHE9nfMNrk52rZx9e/vvEYHPQWdZbCLzUp18CH77J6ycM29J1wU/9x+w8VmasYe7IoJgxIiOTQHqAr6+ET//B+8zs2ojmZW4LMYPtykqI6Yp55xd/J/wYJBcCV/0FLn/Y2w77LJPFKbXWVXjV0/CvEUXV24OM3IsBqZHb1/+ZtLTPhs88CleHxEgmS4563ctwzXOpx9MFENElCELvoWylLnRtk6570bbwZEKCezE7+oVlAulVGu5FYz2KWQJtyrkwxBJS2XnapXfCxeFWqSIr0WbQ0jX3On+OqDDskjpjA+5JO42DcYUGS/BAIPs8VqLSDIPBB4yBEy6y8mBZ6Q2M2ApeCwKiK8K9OPeL4Znso86z6TtCx7IZwlyyUXUbfWRo6Zp0ts411irSsK6lIwazI1JGgP8zsTn+455L3CaZpatoLow/I/V4ugAiugRB6B1UV+jA91+f4bdgpS26kpT6SUZzSBmYdKwEpm0U8aClK9e/BL9oC7Ow2NagkbMC17bOjRJ/toBIlovJWNnCBEfQ0pWQviFDsWFEV5ily7a+GezkmUGhZyYSpHIJpvs8IVx4JsNYIycsyOy8tpAsjmzqBen3k0ZurbqcgZHHfGNosexafZ3gCreOmDjQTojoEgShd1D1gbdu54lKN6YrLJlpOoTl6UompsCzOiWz9hgB0xIDFVKvzsa2VhV/F27Z4T8+Yb7Ow1Q4LPzaVz+bvM8E0WWNI5l7MRjT1RAoyZNpLJP5bO3Er0aAJbgy8WYuQog4MEHcIaLB/nwyEl1pTj4wjJipn8tJX8jsvGPFp/8A396WXtuoQHrDd3ax9NT70+trpKlVafV16W/TH0sXQUSXIAjdm38+qkvIGLaWwOZXEtvZs/bs9WNl6TJiIdS9mCSGR5+kF0mzbxsrjNtXi6UrwpJiW7oKBnuzGW1M7q+wa5uC0za2iEoWLJ0skD7K0pVJRnrf+a6IsuO3jNAJCrwgwXsIzpyzsfNpZZRTrBUlevoM6zrWnOwcvxUxGamC3/P60RyVnT7IgLGJfcXi6Y+liyB5ugRB6N488zX9h/iHbv6pRy7Wy1sDpWaOHghfP1aB9M2N+qUQGkifytKV5GUPMLHY3x94Yiuqrp1vNmFEoWTwxERwjGHxUD73oiUkB02C838CD13ob5eOpctYdDINpDcc2qWXwXxcEH4PNlGiKzS3liWCMrF0tbUuYkcw5Tw9g/D0r7etH/O804pZi2D+zTpVifm8U/7D0rUR0SUIQvfFWKnSSecQZelK6l60jmUaSN9U74quDFJGeIPy2obxhWf8/YEVWJ/r3zZkh8RYhREVxxSW+d6Xld1qf+PK8HapZi9e97JXLzIT65GNcQPbkwTM55mppSvVc4g8LwmtsXR1NIVD4N/ea3s/xgqVyecT5Owf+Lfb0lcXQNyLgiB0X5JZn/ashrsmQtU+vW1nYrfXG2rhnpmw4VlYdAf85Xq9f8XD8Nd/8dplLLoa4MXvw3P/7t+fVkxXGu5Fg+nLxE0ZS1dQWNlux2DZHJsoi0KYhSFda49pFyZebOuTHWTe2kB6gz0DzljawvI/2QQFuImtS/Uceproai/SKaieKd1cdHXv0QuC0Lsx8T9hvPkzLa62LIJZn3GD5906brZ7sXofHN4Jz35LrwN86gHYthjKlnvtWiO63v5F4v6sNGK6wjKpG6593r9tLEJGZBlLVzBg2459SWrpytB9c+nvYMSJmb8M8/pD7WH/i9kes3GtZupevPb5xOzxp31NW/BOuS6x/fWvQdkK/ZkHXZJOiKXrX5fBB+/62yXUS0xCbxJdZtZoXVXydpnQG0SXUuoC4F4gBvzWcZyfhrT5NHAr+t+S1Y7jfNbd3wSscZvtdBznonYYtyAIPZ36Gi2qkgXKJhNdNfsD2wd0seOa/eGB9PaMRoCGo/7toOiqDcSMBTm0I3x/Ju7FsHsfd7p/2/RlrFfG1Rp0B/oC25PMoDMCIixDfRgzL9NL+zNNhz7D9WdoCy3bGpdpRnpD8PMBbUH78DfD24+arX/CaJlFasXJDZ2amP8qkyD3TGcvdmeM6zjV70omZCJwuyApR6+UigH3ARcCJwBXKqVOCLSZAnwXOMNxnOmA/e0+6jjObPdHBJcgCOnxm7PhrgnJ2yTkdLLYWuLfrj2kZ+zlD/QLBNNHc2B2YkPAWhJ0Zf50bPKxlS4P359JIH06M7OC7kUzK3HqedHnhMVnGSZ/RC/D0iskHUdYTcEkNfbMJIV4Psz6rF6382i1h0WjzQInhZt3/JmZd5msdFJPw1hq21N09QJL1zxgs+M4WwGUUo8DFwPrrTZfBu5zHOcggOM4+9p7oIIg9DLKN6RuY4RQOtnLG+t0QHcs7i+oG2UtC1q6GmpSX8Omam/4/kwsXWFlaxKaGmuM61YcOF6XxBmYRLAmEyPn/wRO+xedpiDIzVujrTph93TzJmgKTHK46T3t3vyVm0E8FoeLfg7z/90f35VpRvowbtrQ+qS2EO5etPnsk35XdTr0JtHVUu+zMnm7TOjmoisdO91oYJe1Xerus5kKTFVKvamUWuK6Iw15Sqnl7v6IvP+CIPQqdq+Cra+l1zZZTE+LpSvJH+LX/wtW/kFbskw2+O2ve8cbQkTXP/+o3Zs2h8t0P5A8t5ch6N40hImuESf6t80tp2PpagoRnoMnJZ+mn8y9GIvDoAjBVjg4ekxhzyB/IPQZ6t/Xb6QWV8ayaGpRmlmLLf21g+jKH5B4/YxIkjIC9OcYlpoiGW1Jn9DdyBNLV5B0Rh/2b03wr2A2MAUoBoqA15VSMxzHOQSMdRxnt1JqIvCqUmqN4zhbfBdQ6nrgeoDhw4dTUlKS2V20gqqqqg65jtB5yDPuuhSX6FxaJcXPRLdxl4tffZHmWKJ1oKqqipXLNnAS0NDk8GZJCThNLee1sP99WHgDh/sdT3NWNjn19RRasxd3bt1IgqPwmX+lKSsHX0j5S/8PgOVl9TTE+/OhFPdYvnMjYa/71954i/6H38NEETVl5bFh8MeYYQVn19bWsKSkBBwn4X6C3+nJ27dSBGzevovSphKSMeK4rzNx6x946+3lmQfMp8JpbhlrOr93w4qu5LiNv+CNFetxsjaF9OdweqyA7ROvYncn/R6feKCCQcDqdes5uKdtFqpidxn12aQ63h3JaqrjjKwcNgz9BPsj7ivjv9MZfs+6GumIrlJgjLVdBOwOabPEcZwGYJtSaiNahC1zHGc3gOM4W5VSJcAcwCe6HMd5AHgAYO7cuU5xcXHmd5IhJSUldMR1hM5DnnEXpkQvkj4ft838U2Zp60jwcEkJJ42ZBv+EeG6+7qu+BiIMaP0L4jr/0JFmqCltmT03duRQvy3fJdYcPltx7owp2kW0JHroAEMLwi0aC876COzsA6uB7DxiP9jLjEM7Yd0dLW3ycnO9zyZwPwmfWdUzUAaTjzuByfMCxxIoBn6cKEzbC3es6f3eFQM/IllFwRL1J4qLi2lt2eY2s6M/HIRZs+bApOK29VWiF5GfTarj3ZVzypmR5HCr/k5n9D3rWqRj51wGTFFKTVBK5QBXAAsDbf4KnAWglBqCdjduVUoNVErlWvvPwB8LJghCd2PlH+DPX+q469UdiT5mYroaa+H+BfCzOdFtG2pc96Ipm+NaLoKxW6lorIfKstTtdr4dvl8pzxUYlYg0kzQJZlZlWEFroW2Y59BVSvAI3Z6Uli7HcRqVUjcAL6JTRjzoOM46pdRtwHLHcRa6x85TSq0HmoCbHcepUEqdDtyvlGpGC7yfOo4joksQujMLb9DLS3/bMddLKrrceKy6StizKnk/9dX+eCoTeJ4s7UTUNdNNj6Bi4RnvjfAzLr6EQG1LdF3+MOzfBIt+HDEeV3RFlQwS2oF2EF1XPxs9uQL0czZ5rYQeS1oRaY7jPAc8F9j3Q2vdAW5yf+w2bwEz2z5MQRC6PE2N2uqSLEg7SHNTYqLQuiP+jOl1SYJwM6mHGBRdxjKUqaWrqS792VhRJYaygpauiJp/ANM/qZN3RomuJhFdx4z2tHRNSJFeYrrMM+sN9KJpFIIgHFP+72r4zxRlVoIEM4fX18AdRfDyD719SS1dGQim+mpv9iKEuxejyuPYQeeNdcnHlA5mDFlRoiuQmDRZ0PtwN2Jm4Li2jam9GDi+s0fQfpjn0M0TcvZIBk/u7BG0iu4991IQhK7De89mfk5DjT83k7EgrX7C21ebxKqUiaXLaXItXSamK8S9OOaUxKSqoIPuTT4mI7ryB8Ln/gy/PVvvv2mDFnY1FfDg+cnH0hLTlYZ7EZKXDTrzJph8Dow+Kfk1O4IbVui0Ej0G8xwkpqtLccMKPSmmGyKiSxCE1uE4bXe71FfreKUD27RVYfh0vd+2/KQT05UuWdmJlq4db3rHx56eWnQ1HNVCMLcvFJ3stek3Si/3pJFE1YiolmWKQPpkuYmyYl1DcAEM6Z7Wh0ha3Iti6epSdOPvmXyTBEFoHc2N4fszmXlXXw2/mAuPXQ5/+gwc+UDvt0VGfZJiuZlYukDHPbWIrpAYqLC6feAPcG6o1kIw1yqTc+a/eev9rQw7p98Y3p8KBNJnZQVe7E54e6FjOfUrejmk05JWCD0MsXQJgtA6murDy6M0N6ZfwiUY0xUWoJ7MmpXs2KiT4PpFsPll+OOlel8sJKbL8M210VY1uyROfbUep6kTeGsg0L9gkH/fWz9L7C8sVigr2wuKT7B0iejqFGZ8Sv8IQjshli5BEFpHVE27Jb+CpQ/491Xuhsc/B3UBq1WwqLQRYbYVLZk1K6yEj8G4Pu1ZfVnZiTFdhlhOdK4ruwbiG/foMkJ2LFrGuKIqbgm/rLhXiDohkF7+VAtCT0AsXYIgtI4o96JbLodTr/f2vXKbDrTfsBBOvMLbH2Xp8omuJMKqIqR8TJCYJaRicc8KF7R0xeIQzw/vIx5SAiad+os2l9zvnTNgHJzxTTjpC9b1syE733WniqVLEHoiIroEoTfSHvmHoixdYRhrVSzHc6FBYlFpM1Ox2eo7KLpMbi+nGXa9k3itiWfB1kWedch2ddoxXcHg9Fg8Oh4tLAdW+cbwtlFM+5jnklQKzv0P//EsS/QFh9HNi/wKgqARm7Ug9Ebunw8/GdG2PprCaxMmbZudq5OLGoJB8rVuLJRtRbJdiPs3wW2DYMOz5B/9AGoPJV4rbpKzRrkXo0RXEvdiWIzaoPHhbaNIJZxicT1LEmDULP8xCaQXhB6B/PskCL2RD95tex9R7sUw7KzpjZZYCwaup3IvGuvSP/9AXt5per3faH8txKCLMDvgXsyKyI2VFddtr3wc/nSF/5gt3G5cpXNxDZpIRqQSTlnZOgj/updg6LTAMRFdgtATEEuXIPRmdryVftv6Gn8Oq00vpX+ucS+qmF9EBUWXcS/arks7kN6kbnj/BYpKF+r1AWP9fRjR1RJIb4krOyN90PJkssOP/3Di+E0erQFjYdAEKJqrBVImpBJOWdk6zmzMvMQgfQmkF4QegfwmC0Jv5qELoXp/em3//m/wyMXe9gu3wL730jvXWLqaG/1uyQTR5boLW2K6lF+kWbUMBx9YqVf6jfb3kWNK+RjRFbR0GdEVIYJiIS7GdFNghGFydaUSToMnw5Ap4cfE0iUIPQJxLwpCb6d0ORx3Qep2+0MCx2uTFKO2Mdaq5ga/5SqYl8vuT8Vg9Mn+9mHB+wnuRHemYVjKCJ/oihBSYQLL9JFB3tcWzrtd/6Ti809FH5NAekHoEYilSxB6EiU/zcxlCLBrCbzwPSh/379/08uw9H5vO2wGXzLeuAe2uyV2jHWrqcEfSP/uE/5zbBE2YgYUDPYXtQ6LIwsKkpZAejPugHuxJQt8hJBRKlGQmT6C+bM6CgmkF4Qegfz7JAg9iZI79E8wS3oyylbCtteg30gYapU7edTN4m5KoYRZgJKJkJdv1ctbD/vdi41JZj3axa0HT3Hbh1i6Jp/LJsYz5YQTYc9qfx85gdmLwUD6sFivINm5oPI9EdjZokvci4LQIxBLlyD0FGzXWyb1D2sq9DJV8eiwWCfbCpUMI5xsS1dYjJNt6cop1K5Ce1xGvJ13O2VFH9fJRYMWq6B70bZa2W2TCRk7fQNYVr7W+BfbAbF0CUKPQESXIHRnnr8FbnXFQYMlgI7sSb8PE0j/6o/hqS9GtwtzLzYc1dc3Vq0ofJYuV3SFWY3smK6cPtriZFu6jHvRFlJBQdIyTiO6skKOkTxOKpYLeQP0+oiZVkxXZ1m63HsYPLlzri8IQrsg7kVB6M4s/bVeOo7fInT0EPQblV4fNdbsxbV/hsseDG8X5o4zQu+Ne5Jfww6kb6iJbmfHbOUU6NmKPkuXa82LJbFYmXGGZdu370FlwXUva+uaEVgt7XK0pevzf4GRs3WGe+g80QVw1V9h+PTOu74gCG1GRJcg9ATqjvjFTNBVWL4RCoeG55ZKN8lpmGUoWDsxCiOWmhrTPyenUFvIjGBrrIdSt+xPlMsweCxIsO2YU8LbmTqMk89xtzvZ0gUw6azOu7YgCO2CuBcFoSdw9IC/XE5QdN03Dx48v23XaA5J1xAs4xNFi3uxwRNdsz+f/Jy4FdPlOPD8t2HF7/Uxn5swaOlK5jZMUl/RZsAYnQS15TwjujoppksQhB6BWLoEoTuT20+7x2oqaIlhgvCs7/sDKSHSxRSYtmOrDLWVifvCMElNmy1L14V3QmWpP8u9TU4h1Ltjb6yDnUu8Yz73YoSly3Yv5vTRAjHdtBeffdIf6N/ilhTRJQhC60nL0qWUukAptVEptVkp9Z2INp9WSq1XSq1TSj1m7b9aKbXJ/bm6vQYuCAJadAHUHPQH0tsC6bBVl/DVH/u308FYqRpCZioGM8pHYdxyTY2uG1TpfFq5/aLPySnwZiKu/bM/k33SQHpzzBJdo+aEjDck5suQneuP/+rslBGCIPQIUooupVQMuA+4EDgBuFIpdUKgzRTgu8AZjuNMB77p7h8E/Ag4FZgH/EgpNbBd70AQejMmrcHRA/70Dbalyy4GvfhuePormV3DiJ0wS1ddGvnAHMcTK8a9GC/QM/KSpW3I6QNj3KLW79zvT4nhS3ga6GP8h2Hs6XD+f3r7PnEvTDpb1zVsjbVK3IuCILQD6Vi65gGbHcfZ6jhOPfA4cHGgzZeB+xzHOQjgOM4+d//5wEuO4xxwj70EpFFvRBCEtDCFkWsORFu6KgOWrXTjsAxNbqB9WB6vdCxdweSm9dVefcRk9QjjBVB0Mpz57/DBWq8uIwQC6QOiK6cQvvi8zmhvGDwJrnran3srbHZjFC2WLhFdgiC0nnRE12hgl7Vd6u6zmQpMVUq9qZRaopS6IINzBUEIUr5R57/auz55O1PyJhhIbwuwyt3+c9KdrWhIZula/0zq838y3Ftf/jtY8ZBXLzGZ6DKZ5cecqmPC7MSpdu6tTOsStkY4ZYl7URCEtpPOX6uwfweDf7WygSlAMVAEvK6UmpHmuSilrgeuBxg+fDglJSVpDKttVFVVdch1hM6jOz/jcdsfZwKw4+//w7aJ0bP8TjxQwSBg15b3qNlTxXHu/k3vraWsqgSAyZvWUGSdU115mMIk1zafWbG7veTNxdTmD+fUIwfJjzopXdzkp/XVh3mrpIRp+8oZEdH0nX+uoeb9w6jmLD4U709Og+fKLCkpaXm+o0u3MQU4mjeMzZO/TEWKZz65tJQiYPPmLZTWJW9rKKjeyTygqamB17vpd6o70p1/h4X06G3POB3RVQqMsbaLgN0hbZY4jtMAbFNKbUSLsFK8v93m3JLgBRzHeQB4AGDu3LlOcXFxsEm7U1JSQkdcR+g8uvUzLlkK22HcuHGMC95DbaW2+vQvgh394CCMGTEYho4Dd4LilD5HmTJ/vrYIHXoSLA9jYX4uJMlPWnzCCIjntfymnnbKyTBkMqxQkKJSULrkNNfoZ3PoSdgb3mbeaWdotyBA4Q/g+Zu9MRYXe8/3nU2wGfKnLGDmpd9OffGjL0AZTJ48ickfKk5vwBVbYBnEsrK673eqG9Ktf4eFtOhtzzgd9+IyYIpSaoJSKge4AlgYaPNX4CwApdQQtLtxK/AicJ5SaqAbQH+eu08QhLQIcYU9dCHc42Ymb3ZTMTTU+pOjrnoU3vxfvV4bCHYPy7dl88tT4d5Zie0ba2H4zPSHngzjsgyLqxo9Vy/tRK79k0QlmLiyPsOj27SVrpAcVRCEbk9KS5fjOI1KqRvQYikGPOg4zjql1G3AcsdxFuKJq/VAE3Cz4zgVAEqp29HCDeA2x3EOHIsbEYRew961etlY58VnNdT4Y7oAylboZTDYvSmF6Apix3RNXACff0qLkOpynXS1LZiYrrP/H7x6u17//J/1GPOtic79koiuKtdU1ndkphdPv6kE0guC0A6kFYHqOM5zwHOBfT+01h3gJvcneO6DQEQxN0EQQjFC53AZLPk1nPZVvb3xea9NZZkluo5q4ZWd76WOyM7Vy7pAAtN0y/AY1j/j9n9UB8D3daOwkgXBp4vJsWVbtfIHJLbrX5S4z2CKe/eNig4L0paUEWLpEgSh9UgZIEHoipi0Du8+Di/c4iU0/dMVXpvK3Z7oajwKRw96KSQAYkZ0BSxdduqFaR9PPZbX/9stIeR4syXBE3Wt4cK79dKke3Ca4eRr4Kzvh7cvGAxDp4Uf+/C3YOB4nYcrHU75kq5DeUIw800SJCO9IAjtgJQBEoSuSLC8jtOU6No6XObl0Go4qkVYv1Geuy07QnQZLv2dtnq996x//9jTtbVp43OJ59gWqXRL6gS58nE47kK9bqxlzc06gWkUSsFX34TbByceGzUHvrE6/esPmQI3b06/PYilSxCEdkEsXYLQ0exdB3dNgiMfRLcJugQbanUCVJunr4d967zjlWX+2CcjaKLqI8bi4daqsadFC6p8S3QlyyafDLsPM0ZTmzEZyQpZH2tMnq7CoZ03BkEQuj0iugSho3n7l1CzHzb9I7pN0DrVUKOLQ0fRUKMtX3bsU0ONDkhvPOq5BQuHecez4p64Ovc2uPAuOOdHsOCW6ISjtqUrjAnz/Rarc29L3keL6OriFqSsLLj4l3DdS509EkEQujEiugQhFUcPZh58blO5x3MNVu72guSN9aSuSl/DHIdE0XVgS/JC1Qe2QP0R7V401Fd7/RgLzdhTvSLTsRyvoPSwE+DUr8CZN+kcXZGiK8S9ZzP78/60Emd8I7FNqKWri4sugDmfg0ETOnsUgiB0Y0R0CUIq7hwPPz+5dedWbIH/mQZv3qsF1f8cD2ue1MdMcPbPZutrbHhWH9+yCKr3+/t56ouw9FeprzdoordeX+3l6DI1BwuGQB/X2hXL9sRYMN1ClCsvP4WlK5btnRsl3OzZiaPm6GVUkLwgCEIPQkSXIKSDSUuQKYd26uWWVxKTlJrEoNXlernjTb3cuggO70wUQtsWJ7/W0Glw3Efh5q0wfIZ2Lx494L9WwWAviajjQNFcuGG5vzg0JBFMA8P3G3L6WvFPw8Lb2LFgMy/T159ybvJ+BUEQegAiugThWNLiPnMSk5IGk5k2uttvujFRH7ohs2tN+5gWNIWDof8YnXaixnVbGvddwWDP0lW9X4uxIVMS+zLCySZeANkpZizm9vVcsX0iRFeQsOsLgiD0QER0CcKxxC5z03DUf6wxuF3v3z7pC5ldy463yimAesvSdfqNenn8J+D0r+v1cR+K7ivM0hVPo9x1Xj9dpzErDuf80H9s+iUwsTh1H8mYdDbM+mzb+hAEQegkJE+XIBxLTAC94ySKrIaj/txbjZbl6+JfagFz8xa4e1J617LjrXIKtcXJpJmYdA7c6ro3B4zx1qMISweRyrUI2tKVPxB+uD/x2CUPpLaUpeKqp9s/IcxtAAAgAElEQVR2viAIQicili5BaC3VFfDbc+Hg9ug2LcWlnURL1/svwiMXedt2wWqTWT4d65Khj5VDKl4IVR/obPYQXlonGbEQ92JeGn3k9kvcZ9JShPUpCILQixDRJQjJaE6SyuDdx6H0HViSZFahcRk6IaJr++v+4Hg7+WluX73MDoiuvqPgwzfBkKnevjmf17m1Jp7l7Rs43n9epolMjXsxO18Xo4b0hJsZt81XFuscYCqDAtOCIAg9EHEvCgLoXFk5hX5h0NSQPD+XmXVYOCS6TVOduxIiuoIc2e2tG/GSFfi/KK8/fORHsO01b1+/0XDW9/ztxsxLfq1UmED602/wstynY+kKE3fDjtc/giAIvRyxdAlCzQG4YzS8dpd//2/PgTvHRZ9nRFdBEtHls3TVRLcDOGxlnM/tH94m1N0YYkEaMTNxXyYMdS1pgyZ5bsuxp7WtT0EQhF6OWLoEwSQiXfMkFN/i7d+ToohyVXnqvo2ly2n2AuW/vAgeudirrzjrSlj9J39W9jA3HYSLrrC6hbE4fG2p7jOqr2RMv0SnnRh9srb+fekVvS4IgiC0GhFdgtDaUjTG0tXUALtXaaFTtU8nKe3nJjZtdEVXYy2sfESvjzhRu+zKK/X68Rdp0WWTFxKQDuGiqzmiWPSwNmZ5L5obvi4IgiC0ChFdgmDEVqaiq/aQXjbVwQMLvP19R8K/vafXjej64F3veCxb1zcEHUcWJqRMTUSAwZOhYnPifkNzY2bjPhYUzZPZiYIgCCkQ0SUIpgB1pqLLZJhvCiQ1tUsGtQTSB4gX6GWU6LID+r++AtY9Df93jXeeTVcoFv2llzp7BIIgCF0eCaQXhBbR1crzgpnkbaKOZaewdAUx2eYzcS8KgiAIXQqxdAlCay1d9TX+80P7jrB0FbjZ4+OF/lxcn30SKssS25ts86GB9J1o6br2BShb3nnXFwRB6EaI6BJ6F83Nibmv0hVdjqPbmMD7BjeHV7JcXsGi1gaT+yqe7xdSU88Pb1+QTHR1oqVr3IeS13AUBEEQWkjLvaiUukAptVEptVkp9Z2Q49copcqVUqvcny9Zx5qs/Qvbc/CCkBGVu+G2gbDqMf/+xjRFV1MD3DkB/nipno1o2r9zf3j79QthaUS2+v5FetlwVLsYQddHjCJ/kE5YmheSv6srBNILgiAIKUlp6VJKxYD7gHOBUmCZUmqh4zjrA02fcBznhpAujjqOM7vtQxWENrJ7lV6u/QvM/qy3P11LV+0hqDsMW17xXIvJWPcX//Zn/ghDjtPrfYZ7fRYMgqv/BqOTpGWI58G1z/nL/xgkpksQBKFbkI57cR6w2XGcrQBKqceBi4Gg6BKEro1J8RCsIdgSk+VG0tcehrKViefvWuqt11elvl5wpuG4Mzw3Yf5AvTzqjmnC/NT9RZX26QqzFwVBEISUpONeHA3ssrZL3X1BLlVKvauUekopNcban6eUWq6UWqKU+mRbBisIbaKmQi+N4DEELV3LH4I/hHxVjaUMlbqkD0B2rn/bvu6wE/Ry1mdS9xOGY021PP6i1vUhCIIgdCjpWLpCCrslTK7/G/Anx3HqlFJfBR4GznaPjXUcZ7dSaiLwqlJqjeM4W3wXUOp64HqA4cOHU1JSksk9tIqqqqoOuY7QeQSf8aTNSxkD7Nq9hy3W/hF73mUa0FBfz5slJUzd+BajQvrbvXkNo9Bf/pVLFpOsKE5JSQnTdm1lhNle8Fd47TV/owV/hSMKWvE9POnIEfoBK+fcReWePNiTeR/dHfkd7vnIM+759LZnnI7oKgVsy1URsNtu4DhOhbX5G+BO69hud7lVKVUCzAG2BM5/AHgAYO7cuU5xcXHaN9BaSkpK6IjrCJ1HwjPe+zsAxgwbxBh7/7ItsBHi2THdvuy+0P5GDciBPaBwOHnHb5Jeu3jnPbC3xNs+66zW3UQUm/rBETjp5JN7bYke+R3u+cgz7vn0tmecjntxGTBFKTVBKZUDXAH4ZiEqpUZamxcBG9z9A5VSue76EOAMJBZM6CxMrcSga9Bkljcuu8rdhFJzwFuv2JT8WltLvPWP35P2ENPmkvt1oeyRs9q/b0EQBOGYkFJ0OY7TCNwAvIgWU086jrNOKXWbUsoEk9yolFqnlFoN3Ahc4+4/Hlju7l8E/DRk1qMgtC+N9f6YJ4OJ6Qrm1QrGdB0uDe+3piJ8P8D5d/i3x56ulzl9YO4Xk4+3NQyZApf8WuodCoIgdCPSSo7qOM5zwHOBfT+01r8LfDfkvLeAmW0coyAkZ9vr8PRX4Gtvw5534eGPw4lXMH/NU6Bu0UWnX/8vKBii2298Dp6/BS50veAma3z9Efjr1/Qsx9z+Oj2ETfl70WPoM8y/fdpXYedbXhJUQRAEodcjGemF7s++Dbp0TsVmTxi9+7g24y76ideuZr+3vvTXluhq8PavelQvL7xTW5Hi+ToR6lOutWrch2HGJVA4FFDw5FV6/4gTvT4ue0jPKPzCQhg8qR1vVBAEQejOiOjqDjgO7HxbF0keOk27x44ehKFToXo/VO3Vmc0HTYSqfTBsGuxaBqNPgqxYZ4++bexZDYOnQI6V82rnUi9n1aaXYNcSvX64DOqOpN936QoYPl1byoIMGAPjP6zX3/u7t99phlO+lNi+cIi3PuNTejlxQfpjEQRBEHo8Irq6A2v+D/7yZb0+41LY8RYc2QM/OgQPXQj73/e3/+I/4MHz4OwfwPybO3687UXNAbh/Psy8HC79rd5XtlLf2xcW6pI4j13uta/MUHT99mzI6avdikFst6Ap2QPR/ccLYMr5sOnF9K8vCIIg9CrSqr0odDK7/+mtb3xBCy6Ag9sSBRd4x1uSeXZTzCzCXe94+w5s1cvqcji4PdC+DOoqM7uGLbj+bSMtaen6WZm6Rs7SZXogMc7LkJ0LVzwG3/8gs+sLgiAIvYbeaen669c4oWw7lP++s0eSHrboaLBm3j17U3h75QqHrlQIuaoc3voZnPPD5DPuHAcW3w0nftoTXYd26AD3837szSysq9QuVZv1C3Xb1tJ3hHY3Vu1LzCZvah5GWbqUgli2/hEEQRCEEHrnG2LfBgqr98He8s4eSXrkFMJoN/95w1Edp/XBGti6KLy9SW1gB4h3Nn//Fmz4G0w6CyadHd3u0E4d/L5+IZxipVpY9aiuXWiEWG2lFke+c/2CqyG7D/FRM6FshZcW4mP/Ayt+r9c/eDfx+qd8SY8hSOEwOP4TMO8r/v2f+o0/J5cgCIIgRNA7Rdf1i1jW3bPg3jMTDrviYMZlsPYp79iRvXrZ3IVE1143PVtthHvOYApJ1x3WgfE2pe/oiQOgLU6VgeMBqgvHMuCLL0D5+3DfKXrnnM/DKdfp9T9/ScfL2cy9NryzrCz4zB8T95/4af0jCIIgCCmQmK7uyrDjvfXCof5jJqarKeBefOIqePRyeOAseP47cPtQ2BqoB5gOTQ3ws5Ng9eN6e8dbcN+pfkG19H64d7aXpNSMKZjtfe86+M8iuLU/3DneE1WHdurcWjYrfg/vPavXNyyE9X9NOkxHuf9T5Pb1dtpuQztAXhAEQRCOMb3T0tUT+OQvtQBpbtQ5oZb+yjt2xA3mbgzEPG2wqjftXqmXKx/OPLXB3rVwYItOSDrrCtjxps6PtXMpTD1Pt3n+23p5eJd2zZnSO0HrVdlKL5j96EEvUD7IOT+EV27zts0EgrN+AIt+HHqKo9z/KfL6hfd58rWQlQ2DJukUEYIgCIJwDBFLV3elcAicfI2OQSoY7D9mrEpHD6buZ9jxUL5Rrx8u09aqxnqo2KLPr9zjtT2wVWd337XM34cRUqXvQHMz7HvPS7mw8hEdU2XY/z5sfgUObNOzD7e/4e9rw9/Cxzn1Qhgwzr9v4lkw5SORt9Zi6YoXhDcYOE6n1Zh9pZeTSxAEQRCOEWLp6gkEE6AaS1d1klqBhpV/gFd/DFc/q8vnDJygE7C+/7yuG1hfBbce1glZf3k6nHsb7FrqnV9V7sVW7VoK7z4Oz/wr9Bmu9y2+W/+Atiptfkn/RLHlFf/2sOmwb51O4aAC/yOMmQe5IVasocdD+QYqBp/MYPBmc44/M/XnIQiCIAjHCBFdPZFqd1Zf/RE9yy/MvXbp7+DP13kz/va71q6D2/QPeEHtoK1ZjUe1Fa3USmFRs9+L0ypdAX1H6qztR/ZA0TydamGVG4A+7eMp47B8XP57mPYJOHoA8gd4+7PzdGmeoOi6aQPEcvS+mgp2r3iPqebYt7dFW7wEQRAEoQMQ92JP59AOePlW+Ns3/funng/Z+d52qvQSlW5+rDf+Rwe5T71Ab9cc0LmzCgbrHGLrrbixETPguAu97Wkfy2zso+fqvFfBYtKDJnnH7SD5fqO02zU7B/qN9CxcAAWDIJ6X2fUFQRAEoR0R0dVTmHMVzPqst913pF6u/TO8cQ+seMg7Fi/UYsWeyZcslUNTY2IA/Kwr9PJwKdQe0jmswB+8nz8Ixp+h3ZWTP6KFWtE8GDzZP86P/hf0H+vtGzBWF5A292D4xP/C8Jk6f9esz2rrVzxPZ4z/1G+ixy8IgiAIXQBxL/YULv4F1FXB6sf09vRLYMkvYd3Tetu45ADi+d4+Q7Kg+7pKf6qHeddDkZv3yiQYHXs6bHxeF982FAyC/IHwr1YM2Jdegj9/GSo2w0U/h5O+oPef8iX4D9eF+M014eOYWAz/8obX3vCVxdFjFwRBEIQugli6ehJ2zNLxF+nA84PbdVyVXUvQlOGxLV1HD0X3W3fEcy+CtmDlD9LrH7gCqf9oLcSysr04q+CsSkPhEL3M6ePts12BgiAIgtADEUtXTyIrCy68SycYHTNPr+9br916L/+H1c4VXXErpuvogeh+6yr97sWCQZBToC1le9fqff1Gw4JbtJsxrz9sWwyTzw3v76zv6YSux1/k33/5wzqNgyAIgiD0QER09TROtWoDzvuyt15yh7duijLbli7bLZgV95cQCpbcMRas/EFwxHU79hul+xt5ot62A+iD5PaFM0OKdU//ZPQ5giAIgtDNEfdib8HOcWUsXXZMl8ntBYmzBeuO+GO68gfqpXETFg7zCzhBEARBEBIQ0dVbsEVXWEyXbekK1nI8XKpdjIYCN55r5Cy9HDWn/cYpCIIgCD0UEV29BWVlrc8y7sWIvFXGgmUof8+/HS/UyyFu6lEjwgRBEARBiEREV2/B515MIbry+vu3d76tl2d8Q5/Tv0hvT/+kLvdz2tfad6yCIAiC0ANJS3QppS5QSm1USm1WSn0n5Pg1SqlypdQq9+dL1rGrlVKb3J+r23PwQgbY9RljITFdALOu1Es7yzvotBDZeXDWD+AHe/XMRdBJTP/9fS94XhAEQRCESFLOXlRKxYD7gHOBUmCZUmqh4zjrA02fcBznhsC5g4AfAXMBB1jhnpskE6dwTLDzYBlLVjD4vd9ovbTzZxlGzdHldQRBEARBaBXpWLrmAZsdx9nqOE498DhwcZr9nw+85DjOAVdovQRc0LqhCm3CuBdHnKgzwYPf0nXp76C5Ua8HLV3gZaAXBEEQBKFVpJOnazSwy9ouBU4NaXepUmo+8D7wLcdxdkWcOzp4olLqeuB6gOHDh1NSUpLW4NtCVVVVh1ynq3DiwUMMAt4d+kkOLF8PrGfSnnLGAAcGzuHdiiFM2rGNMcCWnbtxS0rTGCsgu6mGtYcL2d/NPq/e9ox7G/J8ez7yjHs+ve0ZpyO6wuqzOIHtvwF/chynTin1VeBh4Ow0z8VxnAeABwDmzp3rFBcXpzGstlFSUkJHXKfLUDoUDsKJM2fA1GK9z3kLSmHQ4CH6s+i7HUqfYdK8C2DrwwBkjzoRSpcx48IvJubv6uL0umfcy5Dn2/ORZ9zz6W3POB3RVQqMsbaLgN12A8dxKqzN3wB3WucWB84tyXSQQjtg3ItOs7dv+HS93P++Xp50NQybDmMsV+JpX4VBd3U7wSUIgiAIXY10YrqWAVOUUhOUUjnAFcBCu4FSaqS1eRGwwV1/EThPKTVQKTUQOM/dJ3Q0ZvZic5O3r2ieXh7aoZdK+QUX6OzzJgmqIAiCIAitJqXochynEbgBLZY2AE86jrNOKXWbUspULL5RKbVOKbUauBG4xj33AHA7WrgtA25z9wkdzcnX6uWo2d6+fiN1otMPfyux/dgP6WX/MYnHBEEQBEHImLQKXjuO8xzwXGDfD6317wLfjTj3QeDBNoxRaA+mnge3Hk7c//3difsArnkOnCYvp5cgCIIgCG0iLdEl9EKyspCCBYIgCILQfshbVRAEQRAEoQMQ0SUIgiAIgtABiOgSBEEQBEHoAER0CYIgCIIgdAAiugRBEARBEDoA5TgJVXk6FaVUObCjAy41FtjZAdcROg95xj0beb49H3nGPZ+e8IzHOY4zNJ2GXU50dRRKqfJ0PySheyLPuGcjz7fnI8+459PbnnFvdi8e6uwBCMccecY9G3m+PR95xj2fXvWMe7PoCknPLvQw5Bn3bOT59nzkGfd8etUz7s2i64HOHoBwzJFn3LOR59vzkWfc8+lVz7jXxnQJgiAIgiB0JL3Z0iUIgiAIgtBhiOgSBEEQBEHoAER0CYIgCIIgdAAiugRBEARBEDoAEV2CIAiCIAgdgIguQRAEQRCEDkBElyAIgiAIQgcgoksQBEEQBKEDENElCIIgCILQAYjoEgRBEARB6ABEdAmCIAiCIHQAIroEQRAEQRA6ABFdgiAIgiAIHYCILkEQBEEQhA5ARJcgCIIgCEIHIKJLEARBEAShAxDRJQiCIAiC0AGI6BIEQRAEQegARHQJgiAIgiB0ACK6BEEQBEEQOgARXYIgCIIgCB2AiC5BEARBEIQOQESXIAiCIAhCByCiSxAEQRAEoQMQ0SUIgiAIgtABZHf2AIIMGTLEGT9+/DG/TnV1NYWFhcf8OkLnIc+4ZyPPt+cjz7jn0xOe8YoVK/Y7jjM0nbZdTnSNHz+e5cuXH/PrlJSUUFxcfMyvI3Qe8ox7NvJ8ez7yjHs+PeEZK6V2pNtW3IuCIAiCIAgdgIguQRAEQRCEDkBElyAIgiAIQgfQ5WK6BEEQBEHovjQ0NFBaWkptbW3Ktv3792fDhg0dMKq2k5eXR1FREfF4vNV99ErR1dDcQKPT2NnDEARBEIQeR2lpKX379mX8+PEopZK2PXLkCH379u2gkbUex3GoqKigtLSUCRMmtLqfXulePPPxM1l4cGFnD0MQBEEQehy1tbUMHjw4peDqTiilGDx4cFrWu2T0StGVG8ulwWno7GEIgiAIQo+kJwkuQ3vcU68UXfGsuLgXBUEQBEHoUHql6MqN5YroEgRBEIQeSp8+fTp7CKH0StGVE8uhAXEvCoIgCILQcfRa0SWWLkEQBEHo2TiOw80338yMGTOYOXMmTzzxBAB79uxh/vz5zJ49mxkzZvD666/T1NTENddc09L2nnvuaffx9MqUEbmxXKqd6s4ehiAIgiD0aO58507eO/Be5PGmpiZisVhGfU4bNI1b5t2SVtu//OUvrFq1itWrV7N//35OOeUU5s+fz2OPPcb555/P97//fZqamqipqWHVqlWUlZWxdu1aAA4dOpTRuNJBLF2CIAiCIPRI3njjDa688kpisRjDhw9nwYIFLFu2jFNOOYWHHnqIW2+9lTVr1tC3b18mTpzI1q1b+frXv84LL7xAv3792n08vdLSlZMloksQBEEQjjWpLFLHOjmq4zih++fPn8/ixYv5+9//zlVXXcXNN9/MF77wBVavXs2LL77Ifffdx5NPPsmDDz7YruPplZYuydMlCIIgCD2f+fPn88QTT9DU1ER5eTmLFy9m3rx57Nixg2HDhvHlL3+Z6667jpUrV7J//36am5u59NJLuf3221m5cmW7j6d3WrrEvSgIgiAIPZ5LLrmEt99+m1mzZqGU4q677mLEiBE8/PDD3H333cTjcfr06cMjjzxCWVkZ1157Lc3NzQDccccd7T4eEV2CIAiCIPQoqqqqAJ1F/u677+buu+/2Hb/66qu5+uqrE847FtYtG3EvCoIgCIIgdAC9UnSJpUsQBEEQhI6md4oumb0oCIIgCMeMqFmD3Zn2uKc2iS6l1INKqX1KqbURxz+nlHrX/XlLKTWrLddrL3JjuTTSSLPT3NlDEQRBEIQeRV5eHhUVFT1KeDmOQ0VFBXl5eW3qp62B9L8HfgE8EnF8G7DAcZyDSqkLgQeAU9t4zTYTj8UBqG+qJy+7bR+gIAiCIAgeRUVFlJaWUl5enrJtbW1tm4VMR5GXl0dRUVGb+miT6HIcZ7FSanyS429Zm0uAto22nciN5QJQ31xPHt3jYQuCIAhCdyAejzNhwoS02paUlDBnzpxjPKKuQ0fGdF0HPN+B14ukRXQ11XfySARBEARB6C38f/buPKyqan3g+HcxCQcQEBAUUZzFeQDHnDW1rprmnM1pv5vNmc1ZVxssGyw105vlrczMIYc0zRTnERNnUQEFRBFkOsxw9u+PIxuOYKEIR+H9PM992sPaa699ll3f1lgh63QppXpjDrruus79icBEAB8fH0JCQsq1PBHGCAC27tyKp51nub5LWI/RaCz3P0vCeqR+Kz+p48qvqtVxuQddSqnWwH+BQZqmJZaURtO0+ZjHexEUFKT16tWrXMuUEZHBj9t/pF1wOxq4NSjXdwnrCQkJobz/LAnrkfqt/KSOK7+qVsfl2r2olKoLrAAe1DQtvDzfdSN8nX0BiEmLsXJJhBBCCFFVlHXJiJ+A3UBTpVSMUupxpdT/KaX+72qStwFPYK5S6pBS6kAZy3tLNK3RFIXieOJxaxdFCCGEEFVEWWcvjv2H+08AT5TlHeXB2d4ZbztvCbqEEEIIUWGq5Ir0APWr1edg/EHyTfnWLooQQgghqoAKmb14Owp0CmRvwl76L+tPoGcgAdUDeCDwAWq71LZ20YQQQghRCVXpoMvT0ZPLmZe5HHOZbWxj47mNDKg3gNFNR+Nf3R+AlOwUqjtURyll5RILIYQQ4k5WZYMug42BX4f+yoX0C2TnZ7P5/GZWn13NouOLWHR8ERNaTSDPlMei44to6N6Ql4Ne5krWFbrW7oqHo4e1iy+EEEKIO0yVDboA3B3dcXd0B6BdzXa82OFF4tLjeHvn2yw4sgAAJzsnTiedZuIfEwHwqObBJ70+Idg32GrlFkIIIcSdp0oHXddSSlHbpTZz+81l/8X91HapTTXbaqw4vYKMvAx2xO4gMiWSxzY8RgefDjwQ+AAp2SlsOrcJd0d33unyjmygLYQQQogSSdBVAgdbB7r5ddPPn273NADPtHuGAxcPcODSAZaFL+PFkBctnmvp2ZLudbrj7+qPjaqyE0OFEEIIUQIJum6Ak50T3et0p3ud7jzV9im2x2xn6aml7I7bDcCM/TOYsX8GAAMCBjCh1QTqVa8nrV9CCCGEkKDrZlWzrUa/ev3oW7cvC44soKlHU3498yt2NnZsi9nGztidbIjaAMCEVhNo7d2all4t8XLysnLJhRBCCGENEnSVkVKKia3Ng+x7+vcEQNM0ErMSeW7Lcxy+fFgflB9YI5BXOr5CsxrNcLZ3tlqZhRBCCFHxJOgqB0opvJy8+PGeHwFYeXolb+96mxNXTvDI74/g7eTN3QF308SjCcMaDZM1wIQQQogqQIKuCjCs8TAG1R/E0F+HYqNssLOx48cT5oAsLSeNh1s8jKZpEnwJIYQQlZgEXRXE0c6RVfetwqSZSM1JZfnp5eyL28fcQ3NxdXBlzl9zMNgbeK79cwT7BuNWzc3aRRZCCCHELSRBVwUqmMVosDcwqe0kBjcYzH2r7mPqrqnmBJnwQsgLNHJvxIohK6TlSwghhKhEJOiyorrV67Jo4CJyTDk09WjKiSsneDHkRc4kn+GJjU/Q3a874wLH4WDrYO2iCiGEEKKMZAVPK2vl3YoOPh1wcXAh2DeYlUNX4mTnxMFLB/kk9BNm/zUbgDhjHJqmWbm0QgghhLhZ0tJ1m/Fy8mLzyM0Y7A1M2zON7459R6wxlo3nNgLwUY+P6Fe3H7mmXAz2BiuXVgghhBClJUHXbcjFwQWAl4NeJi49jk3nN+n3pmybAoCvsy/LBi+TAfdCCCHEHUKCrtuYwd7AvH7zMOYYqWZbjei0aBafXEyMMYadsTsZsWYE79/1PsG+wdYuqhBCCCH+gQRdd4CClq8G7g14s/ObAHxz5Bs+P/g5j214jJFNRjK88XBaerW0ZjGFEEII8TfKNJBeKbVQKRWvlDp6nftKKfWFUuqMUuqwUqp9Wd4nCj3e6nG+6P0FAL+E/8IbO94gOSuZhMwEcvNzrVw6IYQQQlyrrC1d3wGzgf9d5/4goPHV/3UCvrr6T3EL9K7bm3XD13Ei8QQvbX2J7j93B8DJzonvBn5HeFI4HXw64O/qb+WSCiGEEKJMQZemaduUUgF/k2Qo8D/NvNbBHqWUu1KqlqZpcWV5ryjk7+qPv6s/n6vPCUsIQ9M0vjv2HaPXjtbTvNv1XQY3HIwxx4iHo4cVSyuEEEJUXeU9pssPiC5yHnP1mgRdt1jfen3pW68vAAPrD2RHzA6OJh4lJDqEqbum6qver75vNfXd6luzqEIIIUSVpMq64ObVlq61mqYVG8WtlPoN+EDTtB1Xz/8EpmiaFnpNuonARAAfH58OS5YsKVOZSsNoNOLi4lLu77EmTdO4lHeJ5VeWczLrJAD1HOrhaefJI16PVPpthqpCHVdlUr+Vn9Rx5VcZ6rh3796hmqYFlSZtebd0xQBFBxTVAS5cm0jTtPnAfICgoCCtV69e5VwsCAkJoSLeczvon9mfE1dO8Hno55xKOsW5nHO81fYtGnk0snbRylVVquOqSOq38pM6rvyqWh2Xd9C1GnhaKbUE8wD6FBnPVfE8nTy5y+8uFIr/2/R/AAxbPYwmHk3oWrsrI5uM5HTSaTr4dMDd0U5LmoYAACAASURBVN3KpRVCCCEqpzIFXUqpn4BegJdSKgaYCtgDaJo2D1gH3AOcATKAR8vyPlE23fy6sWPMDh5a/xARKRGEJ4UTnhTOd8e+AyCgegDLhyyXDbaFEEKIclDW2Ytj/+G+BkwqyzvEreVWzY2PenzEZ6GfYWdjR486PVh5eiVJ2UlEpUYxYeMERjcdzbLTy5jbdy6Odo7WLrIQQghRKciK9FVQ0xpNmdd/nn4+qukoAN7d/S7LwpdxMP4gACvPrGRss7+Nq4UQQghRSmVakV5ULm91fsvi/NMDn/LFwS+4nHHZSiUSQgghKg8JuoTORtnwTLtn6ObXjV+H/kpzz+YsOLKASX9OIjs/GzAvQ7E3bi8mzWTl0gohhBB3FuleFBYmtp6oHy8atIgt57fw7JZnGb5qOAMCBuDv6s/bu97m454f075me2oaalqxtEIIIcSdQ4Iu8bd61+3N+3e9z5qza1hwZIF+/eWtLwPwQocXeKzlY9YqnhBCCHHHkO5F8Y8GNxzM/Lvn08a7DWBeWqLAj8d/JNeUy7GEY1YqnRBCCHFnkJYuUWqf9fqMkJgQBgUMYl3kOhKzEpl7aC5j147lVNIpmns2x72aO4MbDube+vdW+m2GhBBCiBshQZcoNW+DNyObjATMy0ykZKfw/fHvOZV0CoDjiccB2HVhF43cG9GsRjOrlVUIIYS43Uj3orhpbtXcmN5tOvc1uk+/tm7YOgBCLxXuaZ5nyqvwsgkhhBC3G2npEmXSp24f+tTtw5CGQ6hmWw3/6v7Ucq7F75G/sy1mGy08W7DgyAI+7/U5fev1tXZxhRBCCKuRli5xSwT7BtPauzUAT7Z+krDLYey6sEuf8bjizAprFk8IIYSwOgm6xC13f5P7mdd/Hv3r9devbYvZxpStUxj661AOxR+yYumEEEII65DuRVEuutbuStfaXTmddJqlp5ay5NQS1ketB+DB9Q/yXPvnaOHZgt0XdvNChxdkpqMQQohKT4IuUa4aezTmjc5v8Ez7Z/jkwCesOG3uZpx1cJaeprlXc/xd/Gnh1cJaxRRCCCHKnQRdokJUd6jOu13f5a3Ob5GQmcDaiLVEpkSy+uxqfXV7H4MPz7V/jnvq30NSdhJeTl5WLrUQQghx60jQJSqUnY0dvs6+PNHqCQDqutbl22Pfkp6bzqWMS7y+43W2x2xnfdR6do3dhauDq5VLLIQQQtwaMpBeWNWTbZ5kz7g9fNTjI/1awdivN3a8wfQ909E0zVrFE0IIIW4ZaekSt4VB9Qfh5eTFYxsKN8/eEr0FgOaezQmoHoCGxo8nfmRGjxnY29hbq6hCCCHETZGgS9w2gn2DCRkVQlx6HJ+Ffsa+i/sAmLprqkW6f6f8Gyc7J7wN3lSzrWaNogohhBA3TIIucVvxdPLE08mTr/t/zamkU+Tm57L4xGICPQP5NPRTAIavHg7AfY3uY1q3adYsrhBCCFFqZQq6lFIDgVmALfBfTdM+vOZ+XWAR4H41zauapq0ryztF1WBnY0cLT/MSEm1rtgVgSMMh9FraS09T0P0ohBBC3AluOuhSStkCc4D+QAywXym1WtO040WSvQks1TTtK6VUc2AdEFCG8ooqrIZjDYvzlOwUvgr7CpNmIiM3AzsbO2o516JfvX4oZLFVIYQQt5eytHR1BM5omhYBoJRaAgwFigZdGlD96rEbcKEM7xNVnFKK6g7VSc1JxdnemfTcdOYemlss3Xt738PPxY9XPV+1QimFEEKIkpUl6PIDooucxwCdrknzDrBRKfUM4Az0K8P7hGDLqC0opTiZeJI5h+bQrmY7wpPCeabdM2yN2crMAzMBiDXGkumRCUB8RjwRKRF0rtXZmkUXQghRxZUl6Cqp/+baBZXGAt9pmvaJUqoL8L1SqqWmaSaLjJSaCEwE8PHxISQkpAzFKh2j0Vgh7xHlZ4z9GEiCpjQl6q8osjKzLO4viV+Ctlnjo7iPSMxL5NO6n2KvZKmJykL+Ha78pI4rv6pWx+pmF568GkS9o2nagKvnrwFomvZBkTTHgIGapkVfPY8AOmuaFn+9fIOCgrQDBw7cVJluREhICL169Sr394iKE2uMZeDygQAMbTiUVWdXFUsTMioETyfPii6aKAfy73DlJ3Vc+VWGOlZKhWqaFlSatGVZkX4/0FgpVV8p5QCMAVZfk+Y80PdqoQIBR+ByGd4pxHX5GHwAaOXVilc7voqjciyW5o9zf7Dg8AIOxR+q6OIJIYSo4m66e1HTtDyl1NPABszLQSzUNO2YUuo/wAFN01YDLwELlFIvYO56fESTPV1EObGzsWPZ4GXUdqmNi4ML7/q9i30je14MeVFP897e9wBo7d2a1zu9TlOPptjZyHJ1Qgghyl+Z/ra5uubWumuuvV3k+DjQrSzvEOJGNK3RVD822Bq4y/8unm77NNn52aw6u4r4DHPP9uHLhxmzdgyvBL/C+Obj2Xx+M4uOLWJU01HEpMXwZJsnrfUJQgghKin5T3xRqdnZ2OkB1KS2k8jMy2TjuY361kIz9s/gYPxB/jj3BwAH4w8C0KxGM3r697ROoYUQQlRKEnSJKsPWxhYXBxcGNxyMp6MnZ1PO8lnoZ3rAVdTTm58moHoAT7Z5knxTPn3q9sHVwdUKpRZCCFFZSNAlqhx7G3t6+vekR50ejGk6hoTMBBYcWUCeKY+wy2FEp5mXn4s1xvLa9tfMD+2E+f3n06V2FyuWXAghxJ2sLLMXhbijKaUw2BuoW70u07pN44PuH7Bu+Dp9EdX7G99vkX533G6L89z8XP575L8Yc4wVVmYhhBB3LmnpEuIa79/1Pnvi9uDv6s+SU0v0698e/ZaedXpS06kmADsv7GTWwVnkmfL4vzb/B0CeKQ9bZYtSsvejEEIISxJ0CXENb4M3gxsOJjMvs9i9R35/RD92tDWvA5aTnwOYA657VtzDuGbjeKTlI8WeFUIIUbVJ0CXEdTjZOXHk4SMA7Ivbx6Lji9gWs02/n5Vv3nZo0/lNpOWk0a9eP+LS4wi9FCpBlxBCiGIk6BKiFDrW6kjHWh3Jzc9lafhSlp5aSkRKBACRKZFEpkRyLPEYAKeTT6Npmt7FGGuM5UTiCfrVk/3ehRCiKpOB9ELcAHtbex4IfAAXe5di944kmFvFYo2xPPL7I+SZ8gCYFzaPyVsnk2vKrdCyCiGEuL1I0CXETSgIoD7p+Qm/DP6FbrXNGy/0qNMDg52Bg/EHeW7Lc5y8cpLQS6Hka/mcTT5LYmYiOfk5JGYmsubsGpn5KIQQVYh0LwpxE57v8Dxv7niTrrW74uLgwjtd3+Gd3e8wOWgy9d3q88XBL1hwZIHFGLCRa0YWy+e59s/RpVYXWni1qMjiCyGEsAJp6RLiJnSt3ZXNozbj4mDuZvR19mVev3nUd6sPwLjAcaXKZ9bBWYz5bQxPbHiC44nHmXNoTomzJoUQQtz5JOgSohx4OXnxaa9Pi11//673aeXVigcCH2BIwyH69b0X9zJ67Wjmhc1jWfgy1pxdA8DF9IssOrYITdMA84Ks88LmSbekEELcgaR7UYhy0r9efwYEDCArL4utMVtp7tmcwQ0HM7jhYAB2xe5i9dnVxZ77aP9HALTwasEHez9gT9weutTuQhOPJvx5/k/mHJpDcnYyr3Z8tUK/RwghRNlI0CVEOZrZcyYACZkJxWY8dqrVCYBB9QdxNOEo0WnRVHeoTmpOKmBeGywtJw2A/x37H9O6TSMlOwWAqNQoAHZf2M2hy4f4d5t/V8TnCCGEKAMJuoSoAF5OXsWu2drYsnfcXuxt7TmTdIY1EWuwt7Fn4dGFAHxx8AvScs1B16qzqzifdp6/4v8CIDYtFk3TmPjHRMC8T2RMWgxtvNtga2NbQV8lhBDiRkjQJYQVGewNAAR6BhLoGciW81sAaOXVirj0OD3oAvSAC8wtXfPC5unnz295niMJRxgfOJ5XOr5SQaUXQghxI2QgvRC3kTY122BnY8e9De5lxZAVAEzrNo2pXaZyT/17AOhWuxsDAwYyN2yu/lzBwqyLTy7WB90LIYS4vUhLlxC3kRqONVg5ZCW1XWrjYOtA2ENh2CjzfxuNaDKCqV2mYm9jT76Wz+9RvwMwt+9cnvrzKQBMmolvjn5D51qdWXN2DUopxjYbS73q9az2TUIIIcwk6BLiNhPgFqAfFwRcBQq6I+2xZ+2wtdjZ2FHDsYZ+P7BGILMOzmIWs/RnfzzxI+1qtuOBwAcYEDCg/D9ACCFEicrUvaiUGqiUOqWUOqOUKnH+ulJqlFLquFLqmFJqcVneJ4QoVK96Pfxc/HCyc9KvdfDpAEC7mu1YN3wdM7rPAMzjwZacXEJGbgZpOWkcuXzEIq9TV07xyYFPpGtSCCHK0U23dCmlbIE5QH8gBtivlFqtadrxImkaA68B3TRNS1JK1SxrgYUQxU0Omoy9jT3/avgv/F39GdV0FHY2dvgafHmr81tsjt7MztidjFgzgjxTHnHpcbwc9DLGXCP/bvNvJmycQFJ2Eo+0eARPJ09rf44QQlRKZele7Aic0TQtAkAptQQYChwvkmYCMEfTtCQATdPiy/A+IcR1PNziYf246BZEtja2jGo6isSsRHbG7iQ6LVq/9/GBjwFo692WpOwkAK5kXdGDroTMBFKzU2ng3qAiPkEIISq9snQv+gHRRc5jrl4rqgnQRCm1Uym1Ryk1sAzvE0LcpJFNRupdjwCu9q768ZObntSPz6WeI8+UB8CI1SMYumpoifmZNBNRKVHlU1ghhKik1M2O4VBKjQQGaJr2xNXzB4GOmqY9UyTNWiAXGAXUAbYDLTVNS74mr4nARAAfH58OS5Ysuaky3Qij0YiLi8s/JxR3LKljSybNxHPnnwPgSe8nae7UXD8vqoZtDRo7NmZv+l792ow6M4jOiWZF0gpe8H2BZVeWsTd9L9P9puNm5wZAjikHBxuHivkYpH6rAqnjyq8y1HHv3r1DNU0LKk3asnQvxgD+Rc7rABdKSLNH07RcIFIpdQpoDOwvmkjTtPnAfICgoCCtV69eZShW6YSEhFAR7xHWI3VcgkXmf/Tr3I9mNZrx2onX+GDfBxZJruRfsQi4AOwa2rEydCUXci/g0MiBvVvM9+u1rkfbmm2JNcYycPlABgUMYnLwZGoayn/4ptRv5Sd1XPlVtTouS/fifqCxUqq+UsoBGANcu3vvr0BvAKWUF+buxogyvFMIcQsUBEXjAsdx6MFD+kKsAA3dGhZLv/jkYhIzEwGYvme6fv1c6jkOxR9iWfgyANZHrefxDY+XZ9GFEOKOddNBl6ZpecDTwAbgBLBU07RjSqn/KKWGXE22AUhUSh0HtgAva5qWWNZCCyFuzpud3sTH4INHNQ/9mq2NLY09GuvnK4eu5NEWjwLQx78PL3Z4kdBLoWTlZwFwOfNyYX473+TB9Q/y3yP/1a9FpUax5uwavvzrSzRNI84Yxx/n/rAoh6ZpsjyFEKLKKdPiqJqmrQPWXXPt7SLHGvDi1f8JIaxsdLPRjG42usR7s/vMxtvgjVKK/vX68+2xb3m05aO0rdmWjr4duZhxkV51etH2+7bXzX/Z4GWMWDOC13e8DkCPOj14ddurxBhj2DNuD872zgBM2DiBGGMMv9//+63/SCGEuE3JivRCCAB6+vfUj1t5t7LYgqiFVwta0AIwr3p/4soJPe3sPrPJ1/JxsHWggXsDHGwcyDHlALD27FpijDEA/HrmV/JMeVxMv8jei5Zjxq5n5emVdK7VmVoutW7JNwohhDVJ0CWEKNG1WxAV+G7gdxhzjWyP2Y6DrYNFsAbQtEZTfQPuowlH9esf7vuwWF7nUs8x6+AsYtJiGNNsDFuit5CZl8nTbZ8moHoAb+96mwZuDVh136pb+GVCCGEdEnQJIW6Iwd6Awd7A/U3uL/F+B58OhUFX4tES0xT418p/6cdTd03Vj88mn+XjHubFWyNTIq/7/JbzW9gRu4NJ7SYBWOxDKYQQt5sy7b0ohBDXauPdBgCDnUG/5udSuG6yr7MvXWp1+ds8EjITeHSDeTC/hsb2mO3k5ueyPnI922K2AZCv5fPslmdZGr6Unj/3pOfPPfnp5E9M2TqFjNwMPg/9nK3RW2/15wkhxE2ToEsIcUv19u/N5KDJ/HDPD/q17wd9T6danQBoXqM5U7uaW7UCawSWKs+n/nyK6XunM2XbFCb9OYkVp1fw/Pnni6V7f+/7rI9az4aoDXxz9Bue3vz0LZ8lGWuMZW9c6cakCSFEUdK9KIS4pWxtbPW9IAcFDMLOxg5vgzcL+i/gl/Bf6F+vP+7V3Hm7y9v09u9N76W9LZ7vUaeH3ppV1IrThWuJFe2KLMmppFP68aqzq7iv0X0cTThKRm4GHWt1LMvnMWzVMDLzMjny8JEy5SOEqHok6BJClJuPen6kHyulGNV0lH4+ssnIEp+Z3m06O2J3kJiZSCOPRvx7078BcLZ3Jj03vVj6Oi519BmSBXbE7tCP39r5FsvClxF2OQyAl4NepqahJn3r9cXexv6GvykzLxOArLwsHO0cb/h5IUTVJd2LQgirmt5tOk+1eUo/93D0YHDDwTzS8hG61e6mX185ZCXPtS/cK3JUjVHM7jObYY2HATCx9UT93rnUc0BhYFcQcAF8fOBjXt72Mr2X9iYyJZKc/Bw+3Pchp64Uto6VRmKWrPMshLgx0tIlhLCqoY2GAhBjjKGJRxOLe0opXu/0OjUca1DLpRZPtHqC5jWaczTxKE2uNKGnf0+61+lOv3r9MNgZmH94vsXzo5qO4pfwX/Ax+HAp45LFvZTsFFadWYW9rT0/nviR/Rf3s3zIcgCiUqJ4aetLfNrrU+pVrwfApfRLrDpbuHRFQmYCfi5+HLl8BD9XP5k5KYT4RxJ0CSFuC+/d9V6J18c2G2tx3tWvK139uhISEgKY1xNr4NaAXFOuniagegBRqVE08WiiL/KalJVEj5978FrH1xjTbAyj1ozim6Pf6M+EJ4WTkJnApYxLzAubR3hSOHvj9hKXHseMfTM4k3zGohwJmQmsObuG13e8Tn23+vxwzw/Ep8fjbfDm5JWT7IzdiZeTF+MCx2FnY/6/2u0x21l8cjFf9vmS7PxsDHYGlFK34ucTQtwBJOgSQlQK9jb2jGgygh5+PQj2DSbWGGuxwKuHowcHxh+gmm01AP2fbbzbMLH1RCb9OanYoP5D8Yf44q8vSMlOKfa+57cUzp6MTImk20/diqUBsLOxo5VXK1p5t2Ly1slk5GWwI3YHz2x+hhc7vMijLR8t87cLIe4MMqZLCFFpTO0yld51e+Pi4ELTGk2L3S8ItAAmtZtEt9rd+GbAN/pyFgX8XPxo6NaQNRFrSMlO4fn2zzOm6ZibKtMH+z5g3LpxZOZlYqtsAZh7aC5gOSOzwJ/n/iQhM8HiWnJW8k29Wwhxe5GWLiFEldS1dle61u6qn49rNo7aLrV5qPlDKKWYtnsaZ1PO4mTnxGMtH0MpxZJTSwB4otUTZOdn09i9MR/t/whjrpFRTUZxKukUYZfDaO7ZnOOJxy3eN3XXVNJy0wD0vSuLBoFgXgPs+ZDnebTFoyRmJZKZl8ngBoN5dsuzfNLzE+4OuBuAxMxEVp5Zyb8a/IvzqefLvAyGEKJiSNAlhBDAa51eszgvGNRfzbaaPu7qv3f/F3sbe9r7tNfTmTQT7+x+h7HNxvL14a8JuxxGp1qdigVd6yPXU9+tPr4GX3bH7QbM64m9tfMtJgdNxq2aGztjdwLw/YnvyTPlAfDHuT8A2HVhlx50vbL9FfbG7WXWwVkAHH7oMOdSzxF2OUyfmCCEuP1I96IQQpSgsUdjALLzs/VrnWp1sgi4AIY3Hs6WUVto5NGImoaaALTxaqPfr+lUUz++y+8u6lava/H8r2d+5dczvwLmwArQA64OPh30dDbKhrPJZxm9dnSxFfHTctP4+vDXvLnzTf4892eJ37M8fDnzwuaV4stLJy0njdFrR3Pyyslblmd5iM+IZ0PUBmsXQwhAgi4hhChRQdDVrma7v02nlMLLyQuASW0nMbXLVPrU7YOjrSNjm43lz1F/4mPwAaChW0PcqrkB5u2SCpy6coptMdvYG7dXH/elUHzV7ys9zQXjBf5v0/8Va0EDSMhIYN/FfQD8Z89/uGC8UCzNO7vfYc6hOX/7LfmmfHLyc0q8Z8wx6sEgQERKBMcTj+utc7eriRsnMnnrZLLysqxdFCEk6BJCiJK4OriyaOAiPurx0T8nvspgb2BEkxEopdg/fj+vd3odQN8WqbFHY+yUeVRH0VasNRFrmPTnJIy5Rp5t/ywAgxsOxsnOSU+z88JOLqZfLPG97+99n/iMeMY0HcOVrCsMWD6ATec2kZKdwpd/fWkRhGmaxrHEYxar9hd4fcfrdPihA2GXw4hIjuDTA58SeimUuYfm0uWnLhbbLxUM9o9MieTw5cMcij9U6t+pwMFLB4lIjrjh525EVGoUQIm7GQhR0WRMlxBCXMe1XYk3a3zgeLr5daOBWwPqu9UnLTeNkU1G0sa7Dc9ufpak7CRaeraklXcrHm7+MOOajdOf3T12N98e+1Zf+LWmU03iM+OZ03cOkSmRzDwwk70X99LauzVTOk7BYG9g4dGFbI/dzg8nfiD0Uig/nfhJzy8xK5Exa80zMdcOW8uUbVN4otUTHLh4gHWR68zlXTceO2VHnpbHt8e+1Z9dfXa1vp5aYqZ5Rf7IlEgeWPcAwN/uR5mdn81zW57j3vr3cpffXbhXc+fh3x/+x+ciUyKxt7Gnjmud0v/gReRr+QBk5Gbg6eR5U3kIcatI0CWEEOVMKUUDtwaAuQVtSvAUANrWbMuKoSsw5hgJcAvQ09va2OrHLg4uPBD4APMPz2d44+H8u82/iU6LJtg3mDbebZh5YCYAAwMGYm9jzwsdXuBE4gl9OYqCIK1A0bXIpu2exvHE47wY8mKxMudpecWugbmlLE/LIz7DnOfp5NP6vYzcDAz2BgD2xO2hrmtdarvUBsytWjtjd+rdkSuGFF8uoyRDfh0CwB8j/mD+4fn0q9uPrn5d/+Gp4oy5xht+pqj1keuZsm0Km0duxtvgXaa8RNUl3YtCCGFFXk5eFgFXSWo41uCPEX/wRqc38HX2Jdg3GIDqDtX1NK29W+vHBeuO3V3vbjaM2EDnWp0t8isYr7b3onlAfi3nWrjYuwBwb4N7+U/X/1y3LBP+mED779vz9eGvgcINwMG8qn+uKZeXQl5iwsYJjF83Hk3TAHMQVtT/jv9PPy46WaHAx/s/ZtbFWfr5lugt/BL+CzNDZ163bEVl5mWy+uxq/bysQdcPJ34ACvf1FOJmlCnoUkoNVEqdUkqdUUq9+jfpRiilNKVUUFneJ4QQVZWvsy8Otg4W15RSzO07l6ldptLaqzDoerTlo2weuZmZPWdiZ2PHxz0+ppNv4QKwK4as0FveBjcYzMYRG3moxUMANPNoRvc63a9bjmtnThb14PoHGb9uPBvPbQTgcuZlfjr5EzP2zWDh0YUWaQtmbAKERIfox8YcIxuiNvC/4//jTHbh1kuXMy4DlDjQPzc/l+l7phOTFqNfe37L87yx4w39PCM347rlLiopK4mlp5bqwWKBgoH4OaaSJxoIURo3HXQppWyBOcAgoDkwVinVvIR0rsCzwPX/TRVCCHFTutfprg/eL2CjbPA2eOvX3B3deb/7+4B52QpA36uyR50eADzc/GEeafEII5qM0GdjAnw7oHBM17UKWtcCawTqe2QWzK78/f7fAfOK/AWtRNcaVH8Q1R2qM/PATHLzzeV5e9fbTN46uVjaGKM5oErKSgLM3Zxbzm8hMy+TIwlH+PnUz7y5803AvJxFwfIbBYq2dOXm5/LWzrfYf3F/sfe8vfNtpu2ZxsKjC/nyry8xaSaWhy/nStYVAFKzUwG4mH6ROGPcdX+b20VmXiZnk89auxjiqrK0dHUEzmiaFqFpWg6wBChpVb5pwEeAzNcVQggrqWmoyZy+c/ik5yeAeX0xgC61uwDmmZcvBb2Ei4OLxXNBviV3UIwPHM/cvnPxdvKmS+0uvBL8CttGb9Pv+7n48WrHV7m/8f36LM4Fdy/gh3sKA7CxzcYysfVELqZfpP0P7Vl0bBGbz28u8X3rI9cDkJqTyuMbHmffxX08u+VZpmybwk8nzRMFotOiWXh0Ifevvr/Y80VnL244t4Ffz/zKYxseK9a1GZduDqQ+P/g58w/PZ9/Ffbyz+x19tmZytnlLpv7L+nP38rtJzExkxr4ZJS5JYdJMzDk0x6IFrqQ0ReWb8jmXeo6svCw90CuL6Xumc9+q+0jNSS1zXrfCtS2IVU1ZBtL7AdFFzmMAiw3MlFLtAH9N09YqpYr/p4sQQogKU9CqBfBYy8cY22wszvbOJab9dsC3RKRYLufwYfcPca/mTuilUH1pi2VDluFi74KtjS0ejh7M6TtHD2QeCHxAf3ZgwEA8HD0s8mvp1dIi6CmYFPBP9l3cp68ZVrRrMj4jns9CPwPA1d6VutXrcizxGGBe5yzOGEctl1psjNqoP3P48mF9jFyuKZesfMvgacLGCRbnydnJFntjPvz7w5xLPUcj90YMbzzcosXxeOJx5oXNIyw+jK/6fcX7e99nVNNR+r6gS08tZca+GbT3aU8j90b4ufhxJesKC44soI13G8Iuh7Fr7C5cHVzJN+Vja2PLxfSLRKREWGxhtSx8GZl5mTzY/EH92vLw5QS4BRB6KRSAbTHb6O7XnUPxh+jp37NUv3N56LS4E8G+wczp+/drxlVW6majTqXUSGCApmlPXD1/EOioadozV89tgM3AI5qmRSmlQoDJmqYdKCGvicBEAB8fnw5Lliy5qTLdCKPRiIuLyz8nFHcsqePKTeq34jxz7hkAvqz35S3JLyo7ipT8FNoY2pCen86rMeYhwXe53MUOY/H1w66np2tPvv5+UAAAIABJREFU9qfvJ8NkHq/V3bU7oemh+Nr7cr/H/aTkpzD/8nyLZ8Z7juf3lN/xtvPmZNZJBrgN4F73ezmXfY658XP1vK7VsFpDzmafpYOhA9E50cTnxRdL46gcCXQKpLZ9bTo4d2DB5QXE5cbhYevBQ14PMevSLKrbVue9OuZlN6bGTCUlP4V88vU8XGxcMJoKu0K7uXRjsPtgXo15lY7OHdmXbl4Ed1bdWaTlp3Ex9yKz42cDhfVj0kw8d/45AAIcAojKibIo53S/6bjZmRfp3Zm2k5icGEZ7jv7b31rTNFLzU/Xn/i5d0cDz2nvPnn/Woqy38t/jfC2fI5lHaOPU5rplKA+9e/cO1TStVGPWyxJ0dQHe0TRtwNXz1wA0Tfvg6rkbcBYo+NPjC1wBhpQUeBUICgrSDhy47u1bJiQkhF69epX7e4T1SB1XblK/Fee3iN/YE7eHad2mlUv+oZdCaVajGc72ziRnJfPkpifxNfiyOdrc1Tin7xz2xO3Byc5JX6+sV51efN77c3JNuayPXI9JM3F/k+Ldill5WQT/GFzs+qS2k9gWsw1bZUtXv67MPTT3b8t4+KHDDFw+kAvpF6hmW427693Nmog1N/W9hx48REZeBj2W9ODhFg/z08mfyMgr3UD/Ahvv38i7u99l54XCHQEGBAwg2CeY4FrBDP3VPNqnfc32HIw/aPHstwO+pY5rHTZEbdBbF/eOM+/lGeQbRP96/QE4nXSazw9+zsyeM/kt4jfe3f0uywYvw8XBhS//+pK3Or9l0VJ6LPEY434bx+MtH9dbQou6nHGZPr/0AcxLgPwW8RsNEhrQu3fvYmmvfS7GGPOPu0N8d/Q7Pgn9hJk9ZzIgYABxxjhcHVyLdZnfakqpUgddZele3A80VkrVB2KBMYC+op+maSmAPhrz71q6hBBC3L7ubXAv9za4t9zyL7o6v7ujOz//62cAvtvwHf/q8S+8nLzoUacH0WnRzD88n9c6vsbopqOxtbHF1saWYY2HXTdvRztH/fjLPl/yzGZzq11j98Zk5WXxzdFvOHTZvJr+6KajMeYaCYkOKbaCvVLK/Jd3unkCwLPtnrUIupYNXsaINSNK9b2Pb3xc7/araaiJk52THnR5OXnxQOADzDo4iw+7f0hNQ01WnF7B2oi1FnnEGmP18WUFNkRtYEPUBj7u+bF+LSEzATtlR6BnIEcSzIvQRqVGMWP/DIt9M9dGrGXxycUsPrmY8YHjOZt8lrj0OKJSo1hweAELjiwAzAHyscRj/BbxG0E+QYxoUvjNf136C5Nm4ocTP5QYdBVMhgCY9OckwpPCedfvXeYemmtetsTBhdBLobwS/IpFS9Ujvz/C+bTz/PXgX9jZFIYtKdkpRKVG4WvwZdP5TZy4cgJAX0Nu5oGZHEk4wob7N1Roy9ffuemgS9O0PKXU08AGwBZYqGnaMaXUf4ADmqat/vschBBCiOsLqBZgMZPS39WfA+MPUM222g3ls2roKtwd3XG0LQzAgnyDcHVw5Zuj3+jXJraeSE1DTWbsm2Ex4zKgegBgnnyw9NRSxjQdg7fBm7CHwpi8dTJ96vahaY2mfNnnSxYdW8SBS+a2hWGNhrE3bi8X0i33wiwIuAB8DD50qd1FD6p6+/fm8ZaP08GnA629WmNrY0uwbzBJ2UkW+1zGGmP1QfjVHapbDJQ/cLGwbeN82nnGB46nXvV6hUFXSlSx7ZeKjnO7drZpQcBVUPZtMeYJEytPr8RgZ+CeBveQkp3CqrOrAPOG7cvCl3Ex/SIGewNjmo7BYG8gOq1wGHh4UjgAl3Iv8VXYVxQV5BNEN79uGHOMJGcncz7tvP7N9arX09M9tekpDiccpkutLuyO261fN2kmsvOz2RG7g3sa3HPbBFxQxhXpNU1bB6y75trb10nbqyzvEkIIIW404AJo4N5AP+7t3xt/V3/cqrkR7BvM94O+x9/Vn+z8bGoaagLoWw41cm/Eh90/pL5bfcA8MaDo5AAbZcOnvT7Vz3v596KXfy8e/f1RDlw6wP1N7i+2rtmcvnNIzEzk7V3mvyp9nH2Y2mUqQxsN5WTiSUY1HYVSqlhXWsFG6AUKlscY2WQk3f268+yWwpaltRFr8XPxI9YYC4Cnk6fFArx74vYUW2+sYKHcAj4GHy5lXCr2WxaswQZwOOEwh7cfpptfN6bumqq3nOWacnl397t6uqSsJIY1Glbi3qER2cX33vwt4jeWn15ebH/QiOQIi6DrcMJhi38WyMrLYs+FPWTkZdCvbr9i+VuTbAMkhBCiyviizxf6sVKKtjXbFkvj7+oPwBOtntBnGt6IqV2msvPCTlp7tebT3p/yW8RvjGg8gtScVP19i08u5uSVk3g7eeNo50jnWp2L7RxQ1LVLSxTQ0CxaA8G8PMa3A74lJSeFP6L+oF/dfhbB6qmkUyXmNbzxcH37qFFNR/HlXyVPnKjlXIuOvh31lq1jCcfYGrO1WLqA6gF4OHrw3bHv+O7YdwTWCCyW5tqgK8gniL1xe0nLTSuW9mzKWc4eOcvxxOP6wr95prxiXcFJ2UlsOr8JV3tXOvp2LPEbrEWCLiGEEKKINt5t6OjbscSArDQC3AL0lqUWni1o4dmiWJrZfWazOXozPs4+pcqzIOiaHDSZTec26ePQ+tXtp7fQATT1aMrk4MkEepoDnKKB3PRu02nk3oj39r5Hcnay3t23YsgK/Fz8SMhM0IOuia0nMj5wPI52jmTmZdJ5sTmfAQEDeKrtUxbdkd+f+J48Ux7Pt3+ewBqBPLnpSfP77pqODTY89edTJGcn62OuwDx2LSEzgYgsy6BrWONhFjsJFDXrYOG2UGGXw6hmW01fOsTF3kVfAPfHEz8CcE/9e7C3tS/Fr1txZO9FIYQQogi3am58M+Ab/Fz8yu0dPs4++ir+pfFoy0cBGNxwsD4bb0rwFLr5dbMI3BYOXHjdFrOhjYbSwqsFi+9dzG/DftOvN/ZojMHeoAdvBd9tsDdgo2xwtnfm5aCXWXLvEmb2nEkDtwZ4OxVu+r0jdgfVbKsxptkYmtRool9v5N6IVt6t2D5mO56OnhZl6VGnB3bKjjzyaO5ZuJlNUw/LlkVvJ29cHVwZ2WQkYN7A3U7Z8Xvk7xZdrr39i8+A7Fu3b4m/gzVJS5cQQghxm+tcqzNHHjYPhLdR5vYSb0Nh4DMleAorTq/A1d61VPmVNLjc0c6Rz3p9RkuvlsXuFezNWaDouwG61u6Ks70zzvbOfN3vawz2BovlJJrWaMquC7uoaahJfEY8/er201vVBjcYTGJmIr7Ovvr4OYCFAxbqC9eaNBPDGw+nlnMtXt/xOotPLrZ4f0//nhazSR1sHPQtr24nEnQJIYQQd5BazrUALAKsB5s/aLEifWm83ul1ixYrgH71SjfwvGDzdUdbR2o41uCFDi/o97r6dS2Wvn3N9uy6sIu23m15t+u7uDi40K5mO05cPsGwxsMYF2hecaogoATLpURslI0eDDbxaKLvrVmvej0cbR0J9g2mS60utK3ZlrHNxuLi4IK9ze3VtQgSdAkhhBB3lBc7vEgj90b6vpk360a6N6/V1rst3fy68VKHl2js0fgf099V5y5mH5pNZl6m3j36df+v2bV9V7GtqBYOWIidjZ1FAFbU+MDxxBpjOZt8lvfuek8PxubfPb/E9LcTCbqEEEKIO4jB3sCYZmOsWgZHO0fm9ZtX6vTNazRnctBki3FWTnZOxZbCAPQuxevxcfaxWKrjTiJBlxBCCCHKlVKKh1s8bO1iWJ3MXhRCCCGEqAASdAkhhBBCVAAJuoQQQgghKoAEXUIIIYQQFUCCLiGEEEKICqA0TbN2GSwopS4D5yrgVXWB8xXwHmE9UseVm9Rv5Sd1XPlVhjqup2ma9z8nuw2DroqilLpc2h9J3Jmkjis3qd/KT+q48qtqdVyVuxeTrV0AUe6kjis3qd/KT+q48qtSdVyVg64UaxdAlDup48pN6rfykzqu/KpUHVfloOv236RJlJXUceUm9Vv5SR1XflWqjqvsmC4hhBBCiIpUlVu6hBBCCCEqjARdQgghhBAVQIIuIYQQQogKIEGXEEIIIUQFkKBLCCGEEKICSNAlhBBCCFEBJOgSQgghhKgAEnQJIYQQQlQACbqEEEIIISqABF1CCCGEEBVAgi4hhBBCiAogQZcQQgghRAWQoEsIIYQQogJI0CWEEEIIUQEk6BJCCCGEqAASdAkhhBBCVAAJuoQQQgghKoAEXUIIIYQQFUCCLiGEEEKICiBBlxBCCCFEBZCgSwghhBCiAkjQJYQQQghRASToEkIIIYSoABJ0CSGEEEJUAAm6hBBCCCEqgARdQgghhBAVwM7aBbiWl5eXFhAQUO7vSU9Px9nZudzfI6xH6rhyk/qt/KSOK7/KUMehoaEJmqZ5lybtbRd0BQQEcODAgXJ/T0hICL169Sr39wjrkTqu3KR+Kz+p48qvMtSxUupcadNK96IQQgghRAWQoEsIIYQQogJI0CWEEEIIUQHKNKZLKTUQmAXYAv/VNO3Da+7XAxYC3sAVYLymaTE3+p7c3FxiYmLIysoqS3EtuLm5ceLEiVuW341ydHSkTp062NvbW60MQgghhKg4Nx10KaVsgTlAfyAG2K+UWq1p2vEiyWYC/9M0bZFSqg/wAfDgjb4rJiYGV1dXAgICUErdbJEtpKWl4erqekvyulGappGYmEhMTAz169e3ShmEEELcmUw5OaRv345r377WLorVaXl5pG3Zgmu/frcsPihPZele7Aic0TQtQtO0HGAJMPSaNM2BP68ebynhfqlkZWXh6el5R/ygpaGUwtPT85a23AkhhKgaEr78kphJT5O+Z6+1i3LDtJwcEuYvwJSdfUvyS/j6a2KfeRbj1q23JL/yVpbuRT8gush5DNDpmjRhwP2YuyCHAa5KKU9N0xKLJlJKTQQmAvj4+BASEmKRiZubG0ajsQxFLS4/P5+0tLRbmueNysrKKvat4tYxGo3y+1ZiUr+Vn9RxydxCD+IIHNm+jaysTGsX54Y4hYRQfcnPRJ45Q/o9g8pcx9X37cMJOLZnD3dCM0ZZgq6Smp20a84nA7OVUo8A24BYIK/YQ5o2H5gPEBQUpF27ZseJEydueVegNbsXCzg6OtKuXTurlqEyqwzrv4jrk/qt/KSOSxa7Zi2pQLPGjXG/w36fhNOnuQzU9fTEFBJCdGYmHWfMuOn8YlevIRUIbNEStzvgtyhL92IM4F/kvA5woWgCTdMuaJo2XNO0dsAbV6+llOGdQgghRJWm7GwBMGVk3PK8841GtLxibSO3Ju+UFJTN1bDDlE/ykp9xXbUagNgpU7g04yMAjNu2kb5nT6ny1PLzy6Ws5aUsQdd+oLFSqr5SygEYA6wumkAp5aWUKnjHa5hnMt6x7rvvPjp06ECLFi2YP38+AL///jvt27enTZs29L06qNFoNPLoo4/SqlUrWrduzfLly61ZbCGEEFflxMSQl5Rk7WKUjY056Mq/xd+hmUyEBwUT9847pX4mOyKC/NTUf0yXn5bGmT59Sfl1lfld+SaL+1mHj5BxMBSA+M8/5/Lns0pX5qsBYnkEoOXhpoMuTdPygKeBDcAJYKmmaceUUv9RSg25mqwXcEopFQ74AO+VsbxWtXDhQkJDQzlw4ABffPEFly5dYsKECSxfvpywsDB++eUXAKZNm4abmxtHjhzh8OHD9OnTx8olF0IIARDz76eIv9qicqcyXR3HlX+leNCVFR5OZliYOV1ODucfe4yMgwdLl296OgApy4o3FJx/YgLJK38tdj3inns53av3P+adefgwpvR0sk+fBkDLzS327rzLlwHIT04mJ+bvV5e6NOMjzvTtR+bVbQOLBl2pGzeSb+Ux29dTpnW6NE1bB6y75trbRY6XAcvK8o5rXXz/fbJPnCxzPnn5+VyxNf/XQrXAZvi+/vo/PvPFF1+wcuVKAKKjo5k/fz49evTQl32oUaMGAJs2bWLJkiX6cx4eHmUurxBCWEvW8eNknzmD25AhXPrgA658/wOBx4/d8veYcnLQcnKwdXH557SZ5sDDxsnpht6RFx9PtsHymdyLF0n9bR01Hnv0ls+ST/z2O+JnzKDZkcOov1mXsWBWn+ejj2DzDxtAm1LNAUXSjz/i2rcPji1bEt6xE7VnfMiFV14FIPDkCXIiI0nftRtDcDCG9u3Nz2Znk7jgv3g+9ig2BgMAV374EZfud6HsCkMCTdM41boNnv/3JF5PPkn6jh2k79hB3GuvUWfObFz79kUzmVurtIwMssLDcWzSpMTy5huNZOzfb3ntSuF8uvzkZEzp6Zhyc9FMJkzJKZgyMjClp5f4W6Tv3ceVb7+1/E0yzAFjTnQ0sc8+h0uvXvjP++pvf0drkBXpSykkJIRNmzaxe/duwsLCaNeuHW3atCnxX1BN0yrN8hZCCBE5/H4uTHkFgCuL/gcmk/4X7q10/sGHCA8KLvHepY8/JiM0VD8P79KV8G533VD+mqaRn5ZGbmzh8OPUjRs506s38R9/TNqGDeY0RiOxU6boLS9lkTB3LgDRTz5JfnLyddNlHDpEwuzZpG0J+cc8i7biJC35mdwL5u8pCLgAcuPiyImMBCCvSItYyqpVJMyeTcKCBSR++x3Jy5Zxafp0okaNtugmzLt0CS03l4QvZxfrPrzy/Q8AmIqUI2rMWLJOnULLzyfurbfJPnNGvxceFEzivK8t8siJiS2837mLuaUqN5e8y5f1VqucmFhM2dlceOVVsiMiyTxqDvSzjhwGoFqzZnoepnTzM9nh4QDFgrzbRZlauqyhNC1SpXGjsxdTUlLw8PDAYDBw8uRJ9uzZQ3Z2Nlu3biUyMpL69etz5coVatSowd13383s2bP5/PPPAUhKSpLWLiGE1aWuW4dz167Yurvf1POaVjhB3WQ0Ylu9+i0pV9rmzTi1bat3i114803svLygbVvzu7KzufLNQq58s5DAk+adRLSbWOfQlJ4BJhP5CQmYsrLIPHyY2Gef0+/HPv8Cvu+8Q35KCqmr12DrWh2ntm2o/q9/Xfc/pAt+k6L3cy9eJO71N3AdNBDl4ABA+q7dJH6zkJovvVhiPvmJ5paf3JjoEu+bMjNJ+3MzKCyCwZzoaPJTio+pyjh4kNzz5815X7kCQOoff+jHiV/Ns3x/Sgr5qYVBVE5EROG9a8aOadnZ5BuNnO7eA8Bcd4cOkbxsOR6jR5H8yy9kHvqLBmvWFOtGLJAbXfJ3ZoefLnIczpWF35CyajUpq8xjwQKWLyM7IhI7b29c+/Qh+6S55yttwwYy//oL+1q1zL9XejpXFi2ixsMPl/gea5GWrlIaOHAgeXl5tG7dmrfeeovOnTvj7e3N/PnzGT58OG3atGH06NEAvPnmmyQlJdGyZUvatGnDli1brFx6IURVl5eYSOyLLxE5ctRN56Hl5OjH+SnmiejJy5eXaWHK3AsXiHlqEhdee02/lrJsuUXLSEFAUpITzQKJHDmKtM2bMe7cyYlmgeRcDTb0/FatIuPgQXKiovRrOZGRnH+o+F/ImUcOk3PuHGDuvrvw8hSyjhwp8d1afj4R99zL5U8/1a+df2ICZ3r1Jn3XLpKX/GzRpZgbG8uZAQOInfxysbzyEszfmHO+MBjRNI28y5fJPHaMU+3ac2HyZC68NJm8uDjcR4/G+8UXyT5xgozQA8Xyy42OJltv6Uok+8wZYp959m8HqF94rbClLPtsYdB1/rHHLb87O5usw4f1Pw+eT07EuUd30rdt08eFZZ8+w6mOnUjfvVt/zqFePf3YdJ21NwvGfAFcePllUlZZzM/DGBJCTkQEDg0a4D5qZOH3xsaS+ddfpK4rHPGUtOTn636rtdxxLV3WUq1aNdavX1/ivUGDBlmcu7i4sGjRoooolhBClEpB11ZudDSm7GxsqlW74TyKDlbOT05B8/Mj7o03AWi0+U/sa9cm99IlyMvD3s+vVHlmHPwLgMxDYddNk/bnZovza5cJyDpyhJinJuFyddJSZlgYDnXr6veLdrsVuN5fyFpWNnnx8RbXjNu349S6tV5ep1YtUfb2ZOzbR05kpHmM1OOPk7jwW9J37NCfy4mOxtbNzeI899x5cs+dx2/mxxbvyLs6xqloC1DSTz9x6T/TSiynrbs77iNHkDBnDon//cbino3BQO7Fi+RERgHmAffpu3aVmI9FGS7E6ccF3XRg7mosypSdbdEqZuvujnOXrsRv224RNJlSU0n6eal+7vPWW0Q/8YRFXjkNGuBQpFUt/qO/n+SQ8OVsADzGjcPe15e6/1tEzNPPYCrSBVr93ntxat2KSx98SE5MLA51SvdnsSJIS5cQQlQBFuN1Ll4s9XMFLRfXHif98L3eVfX/7d13eFRV+sDx75mWTHoPJQQIvQpSLFhQRAVFbCiirh0L2LtrR111sa6Iqy52xbrKKjaUYPmJoiIoTUIRQk1CEhLSppzfH3fmZiaZ0JJMyOT9PA8PmTtn7j3DZZI357znPWCMNADkHT2SvFHH7fG8ZV99xdrTTjdzb7yl9Us4On7/nZIP/su2B2sXvueNOo5d338f8pyencY5PCXG397KStZPOjdkW//oXOc33yThlHG177GiAndhYVDbSl9guPOzz/hr0iRK3n8f7fVS8MwMs03x7NkU+UoJmefauTPoXIEjZsWz3zaf85SUUPzKq4ARmPntWvBNyL4D2NtlYktOxtGlC7pOuQR75864t2w1R/Y8O3YEbRkU1bMnVt/CL7+4OoVFyxcsIOaQQ2h33331ru3eupXqNbU5W9bEJJz9+xmv++bb4PN8ZewE2OPbb4g9ZHi9c5WfdmoDb7D+ooNOz9eOfiaedhoAscOHE9W9e1A7R7ccon1Bck1APw8EEnQJIcQBwlVnhGVvuAsLzbyZ4nfeofKPZeiaGtwBARFAzdp1tdfZsoU9qVi8mI1TprJqyFDz2JrjRptfl340J2ha0V0UfL09yb/6GmNq7KefzGOOnJygNskznmVLnTxe16ZNbJx8echzVv5sJNpXLv4V7fVSuWQplQ2US3Bv3YqKiSHm4MF0eOgh83jV8uX1RnbchYWs6N2HTdddDxhTgDXr1lH5yy9k3nE7jm7dGpy205Wht+nZeu+9rD97IjvnzuXPI48yRxHdW7eyoncfY0XfbvYntGW2AzBzmALZMzOpWr4cb1kZlrg43MXFQQGfLSOj3krK9GuvAd+KfjBWeUb370fy2fWno70VFeaIE4A1KZGoPn1BKcq/qQ0Ubb6+2Tq0x5qWhrLbcXTvhj1gFNLdKbDGeq3ogCR5v9jDDyfnf3No/9BDOAf0N4/7VzhafbnTCWPGYM/IAPbvM9WcJOgSQogDQPmCBeQddTTl339Pzfr1xjTdXlh9xJGsGXsSWmu23n0P6888k5UDD2L14SPMsgo7585ly9//br7GtXkLlX8sM0e/KpcsYdMttwRN2/11ziRzlKIh1XlrzK89xTuoCpiSAmMaatMNN1A2fz75114XvArOt/rRv8IOIO6oo/bqPe/JzrmfUvrhR1QuXWoey7jlltoGvtII/oUAgaUS3Nu2BU2jOrp0qZcjtmPWLErn/A+AqO7diT300Hp9cHTrBpbd/4h1bdrEphtuhBDJ5iUf/NdMEgdjyiyQvV2m8XcHI7CxpqfVvr12mWayfdzIkeB2ByXfO7I70fGJx4k96sja82Vl4Rw0CEtiIgljxwKYZSaCWCwkjDs56JA1IQFrXCyOnBxzgUPcqFGkT51qXK9zZ3OhQbePP6bzKy+br9XR0fUukTZ1Kgknnhh0rPPrr6FsNqJ69CDp9NOC/y06dgAgdsQI+qxcQVTXrljT0wGaZAVqU2o1OV2RVoYhcBWQEOLA4f9eoz0e1p4ynvSpU0jw5W1WLF6MJSqK6L5993ie9eeeR/yoUaRefNEe25Z99RX5U4wfUDXr17PxkktRDge9lzac5wS1BSZdGzeGTPZef/ZEnEMODpoWBCNZ3D+C1G3el6w/eyIAjqwsHF1ziAkxDRRK1YoV5tfuwiLWnTI+qG/l8+ezc+6n7Jxr5MPGHnYYyRPPbvD7n3PQQXt13YZ0nfMRhc/MoOyLL6j87TfcAQn4lvg4IwjyeonKyaH6zz/3avVlVM+eQQn4fkX/Nqa6rMnJRPfvX+95R6dOoHXQKsC6ks89F9emTZT7NnxOuegis/6UP7fJmpaGp7AQa2JwX23t2vn+NoIuS0wMHiDu2GOxt+9gtku99BJ2fvwxAComBl1RgfPgIcQcfDDZzz/Pit59jNfHxZF25ZVUr1pJysUXk3r55UT17AEYAU/Fz7+QNOFM0NqooVVWjjU1BXu79mbQ6uzfj5o1a7B36ECnGc+gXS6qli0jybfILLDvKRdeSMK4k9lWUIAlLi4osT7l/PPAYmH7P2vz3mKGDqUhUTndjC8C/l9ZHA6sycn18vNaWqsY6YqOjqaoqChiAhWtNUVFRUSHiPCFEC1n0823sOogo0yBu6CAmjVr2HxH7QjRX+dMYt3pZ+zVuSp/+aVeUrBr2zZzNKl63Tq2P/4EW6c9YAZcAN4y44ePrqlBe73miFfRSy9TtSp4JClw5CgwZ8ev+s8/KXlrdtDIjSU+nvKAxPTAKcPCZ2ey+eabg/qzO/6gSzmdQTW0ALY/8SRlX3wZdKxy8WIKnplBdUCwFsjeqVPIXB4wgp9AzqFDgh53mD6d6J496fjYdBxdu+LassUsQQFgjY2l3T33gM1GdB8j0AgMujq98Dxd3p5drxhn3euqOt+3rcnJRPc1zpcwdiwZt9xC5h130P6hB4nu3ctok55G+4f/4TuBIuWCC3AOGUK7u+4k46YbAbAkJIQM0BNPNkaVbBmZ9a4LYM80ptHiRx1HryW/kfX0U0R17xbU/45PP0WnF54n/hijcnzM4EH1rqOUIu6IEaRecglKKaJpvOWRAAAgAElEQVR79TQHOmKGDiXtisuxpaZiS0vDkZ1Np5nP0uGBB0ifOiXgWr7368sXU3Y77e6+i+hePetdK/O2W3H2M/LA2t13L1gs5r+tNTERa3w8vX79hdgRI4g7blS9/gayZ2UB9Utb2DIycG+Xka59lpWVRX5+PgVNOExYVVXVokFPdHQ0Wb7/KEKIA8PO/xlTRp7ycly+bUhCrfLb08i7t04Nqco/llH1x+9svfc+0q66kpjhwyl46mkqFy+u99rAJPHCGc9SOGMGOXM/Yfsjj6Cioui95DfjGhUVbLjoYrPt7opBBhYDdXTtSpVv2q3Tf15k56efUrVseVAg1FCJBL/u3ywgb9RxeEtLsSQmYktKoqLOBsU7Zs3CmppKdL9+VC0zilr6ay0FTikCZN55J7u+/ZboHj3o8tqrbJ/+GBU/B5dByLjxBjZefgUAiaefTuqll7B2bO2Um7IY90PZ7UT36cPOzz4zpzDByPtJGDuW5LPPonCmUancErCyMO5IY6pNOZ0QMDLo6BT8fTr1sktxb91GiW/bN2tSEvZ27ch6biaxhx6KJeDnisM3ApMw+njijz2WLUDiGaeTGVCawdG1K/HHH0/ypHOwpqWRMHaMOTIIkDr5MmKGDyfuiBEU+Go/dn7zTfP/X/yJJ5IVG0vcMceg/Lus9OoV8O9iIeH44wFwHnQQSWeeEbSytP2DD1C1PHQQvK/iRx9HeW4u7R8IveKyIYknnUTiSSfh2rYtKJ/OEhND9n9e3OPr/UFm3ZFSW3r6ATfS1SqCLrvdbm6101Ryc3MZPHhwk55TCNGymioNoWr5crPKd92RDQD35s3YO3ZEe70oiyXoutrjCSpWqT0e1p99NvhGuAqfnQnPBm9P0u2Lz1FRUeQdPTIoePJPNZXNM3KrdHU12596ivSpUyn76qugZf0VP9Yf6fILDKjsHTpQtXQp9k6diBsxgrgRI3AXFbE6RHX31MsuBWWptyrPlpKCLTUV99atRj5Pair4alsF8hQVkThuHAljx7D9n9PN4zs/+YSo3r3NnKXEcSeTcp6xytA5aBDZr73Kyj7BU7jOg2p/oHZ4yFjNmDP3E6qWr2DzTTcR5ZsmA1+l8rlBO9RhCdhayB90hJpetDideIDMO25He7z1VvlZ4xOCAnF/kBVfZ/Uf1NalchcWYk1IoNtnn9YrpaGsVrKerk3C7/j440FBly0lhfhjg/c2jDm49meXJSqK+OOCV4vaO3QgFGtCArGHHRZ0LOmMM2DvBm/3yJGdTefXXt3v19szM7FnZu65YYjrdvvsU3PEyy9m2DBcWzY38KqW0SqmF4UQkcG1dWuTbB9TNOslbCE2xF3Zpy9bpz2At6am3rJ/7fWy/amngrYfqctfU6n4rbeoXrkKwKwoHqg6L4+a/HxW9u3Hzi++YPMtt/LnEUdS+r+PWTV0GFV/1I4U5Y0ebQZcoSiHA0d2tvEDp84PZP+0YNm8ebXvfeZzrOzXn6o//jCPRffrF1S4FIwfOJ1ff63e9fyr3QJXh1kDdsxod/99xB9/vDEyNG6ckQtVt882G7bUVOO1CQk4Q0xX+Tk6Z5N6ySWkXXUlUX1rA6OYgweDzWZMJQWMOAEhA+dQVfSjcnJIPPkkei35jaic2l/M/YnWge8rcNpwd0GX01cFP+7YY0m96EJsvoRssx+JCUEjSbtjb2/kXflHbxxduux2/0W/7Fn/ofMbr9PLN6rpFzdy5B6n2sAY3cp65l90/fC/e9XPSODo0iVoQQRA2uWTaX/vvS3ToQa0ipEuIUTr59q2jbyRx5B21ZWkX3MNFb/+SnTfvuZIQfWaNVji4s0clYZ4ynex/dFHiT5uFJx3Xu1xX35T8Rtv4NqyhfKvv6b3iuXmD/CatWspmvkcu775lq7vv4enfBc1eaupXrOG6rVr0TUus8p62aefmef1lpYa+8kF5HZ5ysrNKbji1143R6e2TpuGrqw09if0CSw4WZeKiaHb/2orbluTknBt2oRyOIKCqKqAVXh+gddIOPlkcwrPvyULQPTAgcSPHk3c0UfhrarGs6MIa5IRiET1qQ26VMAqu+SzziL5rNoyAXWnDf1sacZqOUtCPAljxrLjP7NCtvOXB0i/5hrSr7mGFX37gdeLo3t3rImJe11EFSD9uuuwOOuPPNadAralpdH5rTexZ2aSd9xo8HpDjnRZEusHXe3vv4+k007F4Rs1ierViw7Tp7P51lvB48ESn0DsIYfsVX+jBw4k7phjSJsyZc+NA8QefnjI4/uygXPd0S9xYJCgSwgRFu4CY+SpbH4uSRMn8tekc0kYO5aOjz8GwNqTTgaLhT7LjeBBaw1aBwUEULs3naWsHO12m7/d+otzKrud8q+NRHFdVYVyOin7+mszR8u/NcrmW28NWRIh9bJLKZ79trmZr6e0lJ0ff2zmIxnnrcTlS9p1BRQa9VfFDqw9tTtxRxwRFHT4R3OcQw6m4oeFvq+HUOlLUk+aMMHMJQqUcPxotj/yCGCsiKv87TfQGovDQda/ng5qW+b7t4kOmI4DaP/AtHqjOlA70mds81Jb+NKa5h/pSsTZvx85cz+h4IknKPtyHunXXUvCySdT9OKLxNRJ42g/7X62/P1OYoYMJSonJ2jT4j1JuyJ0fa5QzOv6ViwGjnTZMjNJvfKKemUJwJheDAx6lFIknnwSJe+9R8XChagoB8rhoMM/HwV2P5VtcTjoNPPZve6ziHwSdAkhwkK7fCM3Xq9ZQbte8rfXS8369ZR89BHVy1dQvmABPb7/zgiurFZsaWlmxW7njz+ydtwpdPvUyN2p8QVV1pQUczrHs7MMi9NJ/lW1Iw26ooLy77+n8uf6+9UBWJNTiD30UMq+rF15V3cbme1PPYUlJgao3bbFmpq62z0C2//jH1T++gvl332PPSODyiVLsKYkB7Wx+QIZW3JtHlHmzTdRNOsltMdDzPBhZtCVefdd5hYxtowMrElJeEpKsPnqNWlCr/aOPeIIMu+4g7gjg3O4ks48M2R7f+2s9ClTSLvsMnN6zJbqG+mKM4KZqJwconr1puzLeTgHDcKRlRVyaifpjDNIGDsWi9NJ9kuzoJlLAcUMGkTFzz8HBV1KKTKuvXY3r9qzxHHj9txIiDokp0sI0aS8FRVsnDrVHFEyj/vr8Hg9eHyrw7wVFbg2bw6q97T1wYcomvmcWe189YgjyDt6JKuPMFaXuQI2BK5Zt47Sjz5i4xVXmnu+BebxeMt21ltJCLDj5VeCcrVyPp1rbiticUab54gJUfQSwFNQiOuv4IKZGTfdZF7ff+4Oj9Umj8ePHk37adPoMf9rnL6ik3WrlSefcw4QXKYgqlcvsp5+ik4znsHRxchbanfP3aRMmmTWLlJ2OzmfzqXzW2+C2v23dYvDQcrfzt+r3CIwkrL7rFyB86CDiBk2zMx58k8v4q0N7tKuuJxOL74YslhoUB+cTqPfNpu54q6uvc2b2pOsmc/S+a03sYTIzdsX7e78O7FHHknMkCF7bixEA2SkSwjRpMrmz6d83lfUrM7DW1VF9ksvEZXT1Zyuq16dR+UvxtYs3l27WHPimKD8JctuSrmsHDSY+NGjg475R6H8BSwDk2m3/3N60FY1YJQbKJ8/32xn79QJR5cu5tSeZ2eZOQIVlZODdrvQlVW48vPNnC+/7FdfYcPfLjDOe+p43Nu3EzNsGDtefpmyr74iYcwYorp2pXzBAqxxtSMtKeedy46XXiKmzkoy56BBdJv3JbaMDKpWraTs08/MAAXAOaA/3T7/zMyT6vTiC+ZKSVtyMrbkZFzbjCXySac2sKddE7EkxAME3TtlsxF3xIgmOX+Xt97kuy+/5CCrzRxV3B/W+Ph6U5z7I6p7d7JfeH7PDYXYDQm6hBBNyj/FVuMrIbDtkYfp9NxzVC1fbrbZFrDXXd1Vd4HTenXpqip2ffddyOf8QVdgIdDAgMvWoT2xhx9OdN++lH7wgXk8acIElFIkTTiTHa+/Tvzo0ZTPN/KelN1G55deAqWMTZwDgq5299xNzLBhxAwbRvyYE1FKkXb5ZONaGekknHgCymIhum/fehXs7R070nvpkpArI/0J3B0fewymT6//vK8MARgBat0g1Z6ZQe9lfzQ4gtRU/CNHde9fk50/JgZvYiKJIUoxCNFaSdAlhGhS/oR2v10LvqHoxRcpevE/TXL+ulWn6/KPqNWV9a9/4ezXj5oNG/CXX8x+5RVifVveROXk0Od3Y5Vg+fzaPCP/NFzd6ThLTAxKqZB1iRxZWWbw1JBQAVfQ83vYt2+3r23mgAvA0a07YJSmEELsHcnpEqIN0lpT/O67uHfsMI9tmDyZrdMeMJ53udjx6mshRzGq8/IoC1j1V7l0KWtOOtmceqsOsU9dwRNPNqq/7abdv9dtG9rg1pZmrMxzZGeTNeMZ2t17jxlwNSRw67G6QZdqxJRXJIju1ZNu8+aRfP55e24shAAaGXQppU5USq1SSuUppW4L8Xy2Umq+UmqxUmqpUmpsY64nhGga1StXsvWuu9l6732UfvwJO157nV3ffEvxG2+gtWbHG2+w7aGHKH77HdyFhWYNLHdREWtPHhe0N1/lH39Qs2YNlb5inZ4dtSNRtnbtjHycBgqi+nOT9iSwGjkYdam8AblOWTOfxdG1a4P1jQBsqbUrAuNHjSJ54sQG28afcDzK4Qha0Ve38GJj8owihSOrY5PsACBEW7HfQZdSygrMAMYAfYFzlFJ96zS7E3hHaz0YmAhIwRIhDgD+LW6q8/LYfNNNbHvwQfO5mrVrcW00yi9oj5vVRxzJn8MPofL334O2inFt3sxfF11ElW9T4Zq8PKC2VhWANSUZR05Og/1wDhgQ8nja1QEbLttstSvlfJLPmUjBE4+bj+OOPJJun84lxle0MmnCBPO5Lu++S5d3360XNO2OIyuL3kuXEB2wirBuRXQJuoQQ+6oxI13DgTyt9VqtdQ0wGxhfp40G/CV/E4EDaxMkIdqYmvx8Sj78ENcWo6CnO6Cwp9/ak06m5J13gOCVhOsnnBXUbtvDj1Dxw0JKPzIqqlf5SjZ4/KUhMOpNRXULDrp6fPuN+bU/OOry/nskTzLKJaRccjHpU6bQ7csvAEi74op628T4t7Dp8s7bZN51pxlQeX2lKGyZmbS75266vD0b54D+OAf038O/zJ51mD6dtKuuMh9bYmJ301oIIeprTCJ9R2BjwON8oO7eCPcCXyilrgZigZD7EiilJgOTATIzM8nNzW1Et/ZOeXl5WK4jWo7c4/rSbr8Da3ExFUccQQzgqaoKWVNbu1wArP7tN+IbOFfZF18EPS745Vf+nD+fjNJS85yFNTW4bXbzHDtuuonvli3Dv6XtoqpKmPks2woKsPbpQ4rTyZ/Z2azw37fnZhpJ799+C8/NJPOKKwH4ZtEiysvL+RGgY0fwtU9Y9gdOYE1pCVX9+0Fxsflckxg4wOz7T78vxXuAbaYbaeQzHPna2j1uTNAV8nt1ncfnAC9rrR9TSh0GvKaU6q+1Dkrw0Fo/DzwPMHToUD0yDEuEc3NzCcd1RMuRexyseu061vpW/iXl51MDKK+33j5/gbJsNkpDPlNf9PbtDHU42Oh2175+yMEkjBnLuvffB2DEpZcA4C+FWu/+BEwLhlJ0661Y4mLpM3JkyPtb070H2x+bTq/rr2+26T9/3w8/9lhsKSm7bSsaRz7Dka+t3ePGBF35QKeAx1nUnz68BDgRQGv9g1IqGkgDtjfiukKI/bB2bO06lpqAFYa2jAxzX8LUKy6n6Ll/h2wXiiUhwczh8u7axcZLLgUgedI52NLTSfnb38xVfikXXmi+LvulWXhKSvb5PaRedOFun3dkdSTriSf2+bz7Q3K6hBD7qjFB1yKgh1KqK7AJI1F+Up02G4BRwMtKqT5ANBB6PbcQotloj6fB5wKDroQTTsC7s4ziN98EoGb9X/Xaxx19tFl0NLpnTypC7GHoHDKExJNOMh/3XrE8aJVbbJ1K7K2Riopq6S4IIVqZ/U6k11q7ganA5xgj7u9orZcppe5XSp3ia3YjcJlSagnwFnChDix8I4RoUtWrV7PujDNZe/rpVK1aZR6vWbu2wdfYMjLAV4PKmpBAxk030uXdd4jq0wdPYSEAOXPnYuvQHoC0qbUrCxvaH8+akBD0OBLLCkTiexJCNK9GVaTXWs8F5tY5dnfA18uBptmISwixR4XP/ZuqZcsA2P7II2TPmkX12nVs9W2703XOR2y89DLc22tn+G0Z6UT37UPVkqVYEhOxxMTgHDCgdoNqwN4uk+g+fSnfvAVrQjzKbke7XEEbMwfa3f6JrV2X99+jeuWqPTcUQog6ZBsgISJIYGkFj698wl/nn2/uh+jo0gVrSkpQ0GXPyCBt5kwqFy/GGhdnHndtNBYnd/3gfSwxMXR4+B/s+u47HJ07Y0tPx7V5M1E9uofshyXgPJHG2a8fzn79WrobQohWSLYBEiKCuH3BFUDVsuVULV9uBlxgbFJsTfYV+fRNKdoyMrClpBA/alTQuWKPMAqhRvXpA4A1Pp6EMWMASDr7bOMUHTuScsnFdH7tVeJ8r+/y9myifa8RQghRS0a6hGhh3spKVg0+mPYPTMPRtSuu/HwSx9fWGV572ulEde1Cx8drK7BrrfGWlZm5U+ULFqDsdlxbtuAcNIiOjz/G2vGnUvTyy/WuZ0tOBoxNkbXLhS09PWS/smY8g66pCZm7lDr5MpLOPANbaiqZN98MGFv1eCsr6xUyFUIIYZCgS4gW5i4yNp3ecudd5jF7VhYxQ4YAUL1iBdUrVtDx8cdxbdmCcjgo/WgO2x99lO4LFmDLSGfj5VcAYE1LI27k0dg7dCC6Xz92zvkfAMrppN1dxvnTrrqKqhUrcQ4cQOlHc4xE+hAsUVHQwAo9pRS21NTgYw4HVoejEf8SQggR2SToEiKM3IWFVK1aRdwIY33JlnvuDZl0XrHoZ6pX57Hrx4XmsfJvvmHj5MtBKTOB3bVpE6UffWS28RQWEtXdyLOK6tmDioULsSQm0vO7b1G+6cSo7t3p9ulcCv71DECDI11CCCGalgRdQoTRhosuonp1Hr3/+B2sVko//LBeeQUAT9lOCp58MujYxsmXG19ojfZVff9rUt3SeBB76KEARHXtCkDyhDPNgCtQ4vhTsKWlhry+EEKIpidBlxBhVL06DwDPzp2gFLq6GndB/XrB1StWYO/QAdfm0Hv7abcr6HFU795Ur1yJNSnJHAVLPPVULHFxZvJ7XY7sbBzZ2Y15O0IIIfaBrF4UIgx2LfwR16ZN5mNPSQnuLVuC2kQPGFDb/v9+CAq47HWCI9dfG4IexwwbZvx9yCEoi/GxtjidJI4bh7LJ71ZCCHEgkKBLiGZU/u13lOXmsuHCC1k7/lTzuKekBNfWrUFt7R07Nnie7Beex9auXYPP+5PuYw89pJE9FkII0VzkV2AhmtHGyy4zvw6s8O4pLq4XdNVdDQjG6Jc1Pg57hw6ogJWBziFDiBk6lKJ/G5tTx408mo5PPkncscc09VsQQgjRRGSkS4gWsOOll4OmF5XDEXID5fjRo8meNQtlt5M04UzzuCUmhozrryPuOKMgqSU6moQTT8AiJRuEEOKAJSNdQjQTt2+z6FAqfv45aENqbDaUJcQGygGHUi+9FGt8AlvvvRdLTAwAWU8+iXa56r9OCCHEAUeCLiGagdaa1Uccuds23rKywBdAiMrvuqbG/FopZY6G+au+K5tNEuWFEKKVkOlFIZqA1pqSD/6Lt6qKbQ8/wqZrrt2n1zuys4k97LB6x2OGDA16nHDiCSRNmED6dft2fiGEEC1PfkUWoglULv6NLXfcgbLb2BFiv0M/a0oK3eZ+wl/n/43q1auJO/ZYdv3wA+2n3Y9z4EB6/foLnrIyyhcsIPHkk81pRD+L00n7afc387sRQgjRHGSkS4gGaK+XzXfeSeXvvzfYpmz+fLY/9jjVfxr5Wbt+WBj0fNwxwasJY4YOxZqURPzxxwNGonzvxb/iHDgQMBLk7ZmZJJ91Vr2ASwghROsmI11CNMBTWkrpe+9T9uU8ev0YHEwVPvdvynNzqfztNwCSzjoLgPJvvwlq1+6eu9mRnU3V8uVULFqEI7sTAOlXTyXhpLE4OncOwzsRQghxIJCRLiEaoGt8qwLrrA701tRQ8OSTZsAFsOu77wDwFBgrFq2+mlu2jAwyb7+NuGOPBSD6oIPM10Tl5KCs1mbrvxBCiAOLjHQJ0QBdXWX87dtcGsC1aRP5115Xr23glj2WxERy5nxEzYYN5pY8Keedi6NrF+KOPrp5Oy2EEOKA1aiRLqXUiUqpVUqpPKXUbSGef0Ip9Zvvz59KqZLGXE+IcPJW+oKumhqKZ89G19Tw14UXUfXHH7t9nT0jHVtqKjGDB5vHlN1O/MiRqBBlIYQQQrQN+z3SpZSyAjOA0UA+sEgpNUdrvdzfRmt9fUD7q4HB9U4kxAHKP9IFsPXe+4ytezZubLC9PTsb14YN2NLTw9E9IYQQrUxjRrqGA3la67Va6xpgNjB+N+3PAd5qxPWECCv/SJdf2fzckO1ijzqS+NGjSTrT2KbHtXVbc3dNCCFEK9SYnK6OQOCv/fnAIaEaKqU6A12BrxtxPSGalXa7wWIx87ACR7oAqpYuBbu9XmJ9xo03Et2rF57yXRQ8/jgJJ58Utj4LIYRoPRoTdIVKTtENtJ0IvKe19oQ8kVKTgckAmZmZ5ObmNqJbe6e8vDws1xEtZ1/vceYVV1I1eDCll1yMpaQU+4a/SKrTpqZzZxx5eUHHFm7eDP7Nq//1NNtsNpD/W81OPsORT+5x5Gtr97gxQVc+0CngcRawuYG2E4EpDZ1Ia/088DzA0KFD9ciRIxvRrb2Tm5tLOK4jWk5ubi5HHXII+VOmkHnHHUR1795gW++uXawCohcvpsOin9nxyitk3HIL2+u063jSWAqeehqA9OuvxxIbS586BVBFeMhnOPLJPY58be0eNyboWgT0UEp1BTZhBFaT6jZSSvUCkoEfGnEtIfadx0PFokXs+r8f2PbQQ2TPmkVN/iYqfvoJb0UFyedMRLtclLzzLtH9+5svK/vyS+Pvr78yj3V8/DFsmZlEDxhgBl1pl08O7/sRQgjRqu130KW1diulpgKfA1ZgltZ6mVLqfuBnrfUcX9NzgNla64amHoVoFplTprI5PQ0wNqQG2HDBBbg2bQLAmphIzbp1FD77LDFDazeW9tfcqvz5F/OYc+hQ7BkZAOTM/QRXfn5Y3oMQQojI0ajiqFrrucDcOsfurvP43sZcQ4j94Q+y/BXi/dmG7oICs427oADXtq0AVPz8c4Pnyn75ZTPgAqOSfFROThP3WAghRKSTbYBERNLV1cEHvF4ALLGx5iFPcTHe8l3mY0fXroCxKXXccaPM4zGHDG/GngohhGgrZBsgEZG8lZXBB3wjX5a4ODzFxQDs/OwzlN1uNkm/5mrijz8eZbVSOmcO5fOMnC6pIi+EEKIpSNAlIpKuqKhzwBd0BYx01a0uHz96tLkBdfSAAc3bQSGEEG2OTC+KiFR3pEujyb/2OqpXrqzXNvP22+i58AeUrfZ3EEeXLs3dRSGEEG2MBF0iItXdwse1aTNln39uPs649Vbz6+gBA7AmBZdBVUqROnkyieN3t7OVEEIIsfck6BIRwbNzJ+vPnkj12nUAeCuDpxfd/orxQOL48aRedCFWXzkJfwJ9XRk3XE+HRx5uph4LIYRoaySnS0SE8txcKpcsYe3YsXT96EN03UT6QHbjv33nl16i/NvvsCUnh6mXQggh2jIJukTEWTf+VFIvvaTB53WVUU4iqnv33W4NJIQQQjQlCbpEq1by/gfsWrgQ50EHBR0vevE/Db7GW7WbUTAhhBCimUjQJVq1LX//OwD2jh32+jW6TpK9EEIIEQ6SSC9aLf8eiQA1a9bu9eui+/Ruju4IIYQQuyUjXaJV2XLvvdjbtSf18snkHVu7VU/V8uW7fV3OJx8T1a0blcuWEd2zZ3N3UwghhKhHgi7RqpTMfhuA6P79g467Nm0K2T76oIEou52obt0AcPbr17wdFEIIIRog04uiVdp46aX1jiWOP4U+K1eYj3dcdy1d336bLq+/Hs6uCSGEECFJ0CUOeK5Nm1h3+hnUbNiw23bWtLTg1/WW3C0hhBAHDgm6xAHLvWMHAEWzXqJq+XJ2vPJqcAOLhfTrrjUf2lKDgy4hhBDiQCJBl2hRWmsqFi+ud7xs/nxWHz6CXT/+hGvbVgA8xTuCGylF2hVXYPVVlLelpQKQcvHFpF52WfN2XAghhNhHEnSJFlX8+hv8dc4kyr/73jy28/MvKP3vhwBsuOACyud9BUDlsmVBr00571wALLGxANh804uZt9xMxo03NHvfhRBCiH0hqxdFi6r45RcAajb8BYygZsMGNl17bci2rr+MnK6EsWPIvOMOc4TLEhNj/O0LvoQQQogDkYx0iRblKS4GwJVvlHyoXLJkj6/JuPlmbGlpKKsVgPYPPoBz6BCievVqvo4KIYQQjdSokS6l1InAU4AVeFFr/XCINmcB9wIaWKK1ntSYa4rIUv3nnwDUrFnDphtuYOfcT0O2y7zzTqp+/x2sVmwZGUHPOQcMkLIQQgghDnj7HXQppazADGA0kA8sUkrN0VovD2jTA7gdGKG1LlZKZYQ+m2iLPKWl5khX5bJleAoLG2zr7N/PzOESQgghWqPGTC8OB/K01mu11jXAbGB8nTaXATO01sUAWuvtjbieaKU8JSVUrVwJwK4ff2LrtAcAqNmwEQBH5867DbgArGnpzdtJIYQQopk1JujqCGwMeJzvOxaoJ9BTKfW9UmqhbzpStCHa62XTDTew7tTT2PXTT2y44AKK33gD765dVP+5CoDYEYcHvabu9GHKxRdj79A+bH0WQgghmkNjcrpUiP/JB3cAABJpSURBVGM6xPl7ACOBLOBbpVR/rXVJ0ImUmgxMBsjMzCQ3N7cR3do75eXlYblOWxa98EcSX37ZfLzhbxeYX//wxhukPP4EAOviE0gCXFlZVA0fTsUxI0Fr4t97H/u6dawYPowV33yzz9eXexzZ5P5GPrnHka+t3ePGBF35QKeAx1nA5hBtFmqtXcA6pdQqjCBsUWAjrfXzwPMAQ4cO1SNHjmxEt/ZObm4u4bhOW+UpKeHPK65s8Hl/wJV2zdXknDiGtf/+N5knHE/mzTfXNjr++Eb1Qe5xZJP7G/nkHke+tnaPGzO9uAjooZTqqpRyABOBOXXafAgcA6CUSsOYblzbiGuKA5D2eNC6dpCz4tdf2XDZ5L16bdqll+LonE3KBReQPGFCc3VRCCGEaHH7HXRprd3AVOBzYAXwjtZ6mVLqfqXUKb5mnwNFSqnlwHzgZq11UWM7LQ4cuqaGlf36U/jss+axvyada5R32IPE005DORwoq5XM22/D0aVLM/ZUCCGEaFmNqtOltZ4LzK1z7O6ArzVwg++PiEBVy40KIYUzniV9yhS8NTXmc86DD6by11+D2neYPp3KX38lZthQEsaMCWtfhRBCiJYkFelFSN7qana89jreqqrdtqv4xQiqLHFxeHbupHrFCvM5a1KS+bWy242/HXba3X2XBFxCCCHaHAm6REg7P5nLtgcfpOCpp9nx5puUf/stAJ7yXWx98CGqVqzAW1ND+YIFAHh37uTP4Yew/uyJ5jmi+/UFmzGYmnn3XSi7nZjBg8P/ZoQQQogDgGx4LUxVK1dSNu8rPKWlKIcxMrXj5ZfBlyTfZ+UKSud8RPFrr1H82mvEn3ACFYsWEdW3D9XLVwSdq+O/niZ+5EiKX38DT3ExiWPHSqK8EEKINk2CrjbMW1WFJTrafLzu1NPqN/KvSrRYWDfhrKAE+bLPPwcg86ab2HDxJUEvSxg9GgBrQgLa48ESG9vEvRdCCCFaF5lebKNcW7eyatBgSt5/HzAqx9flz8MCwOsNuSLREh9PzCGHNHgdS0IC9nbtGt9hIYQQopWTka42yp+jVfTSS7gLCsyE+ECpl10WVArCmpZG5i034xw8mMKZz1H6wQfEHHwwymolZ+5cqpYtY3NgcVMgcfz42tEyIYQQog2ToKsNqFq1is033UTy+eejq6pxFxVR9O9/A1CTt4aCJ58Kap94+unY22WScNLYoKAr6dTxJJ5ilGCLO+ooSj/4gPRrrwEgKqermQcWKOW8c5vrbQkhhBCtigRdEcK7axfbpk8nfcoUbGlpANTkb8KWmkLhzOeoXp3HtocfQVdUAOAcPJjEU0/FtXUL1sREtj/8iHmu6F49SbngArw1Ndg7dSLjhuvxlJaSePrpZpuEE08gfukSlMNhHvNfVwghhBD1SdDVirm2b2fzLbfSftr9lOcuoOSt2Viiokk8ZRzeqmr+mjQJW3o67oICADPgAmj/wDSiunUzHwcGXVF9+gBgcTjo/uUXDV4/MOACsERHkzxpEvHHj26S9yeEEEJEEgm6WhHXtm2Uf/01CSedxPpzJlGzZg0AO15+BU/ZTsCoEL/jtdfA4wEwA664Y46hfP58ANKunhoUcAXq+uF/ie7de7/72O7uu/b7tUIIIUQkk6CrFdl8y61U/PgjW++7P+h4ybvvon1BVsVPP9V7XYfp04kZPow8X9CVPmVK/Tb/fJSiF14kqmfPZui5EEIIISToOkDpgBV/FQsXUvq/j6n48cegNqlXXI6ntJSSt2YD0O7++9h69z0kn38+aVdegWvDBrw1NcQOHw5Axm23oiyhq4QkjhtH4rhxzfRuhBBCCNGmgy5PSQmWxESUUk1+bndxMdakpJDn9pSVYXE6cW3aRP7V12BNTsaR05WKhT8SP+pYlMNB4bMz93iNtKuuQldXUzZvHqkXXkTyWWcRN3IktpQUlM2GLSUlqH3qhRc21dsTQgghxD5qs0FXzJfz+PPKq4jq2bPJV915KyqoXLyY6L59sSYno6KiwOvFedBAqlauonzBAizxcXgKCs3XVK9ahaekhKIX/xN0rqgePYgZNhR7hw6UfjKXuBGH4y7agXa7sTgc4HDQIzcXfCNY9oyMJn0vQgghhGgabTLoqlq5krgPPsCWlobF6cRbXt7k14geMABlteItL6fy++8BKM/NxRITQ1T37iibjahjR5E0YQLO/v0Ao8TD9kcfJe6YY4ju3QtbZmbQaFXqpZeGvJayWpu8/0IIIYRoWm0y6KpeswalNdkvzSKqe/dmv17l0qVU/PorsYcdhr1dO6yJiSHbObI6kvX0UyGfE0IIIUTr1iaDLn85haC9BZuRc+BAnAMHhuVaQgghhDgwtckNr7XbCLqwts2YUwghhBDh10aDLhcAyia5UEIIIYQIjzYZdJnTi5KALoQQQogwaVTQpZQ6USm1SimVp5S6LcTzFyqlCpRSv/n+hF5+F2bm9KJNpheFEEIIER77HXUopazADGA0kA8sUkrN0Vovr9P0ba311Eb0sclpjxsAJUGXEEIIIcKkMSNdw4E8rfVarXUNMBsY3zTdamYyvSiEEEKIMGtM0NUR2BjwON93rK4zlFJLlVLvKaU6NeJ6TUamF4UQQggRbo2JOkJtWKjrPP4f8JbWulopdQXwCnBsvRMpNRmYDJCZmUlubm4jurVnsXl5xAHffPeduX2OiDzl5eXN/n9JtBy5v5FP7nHka2v3uDFBVz4QOHKVBWwObKC1Lgp4+ALwSKgTaa2fB54HGDp0qB45cmQjurVnBUt/pxA4+phjmmWza3FgyM3Npbn/L4mWI/c38sk9jnxt7R43ZphnEdBDKdVVKeUAJgJzAhsopdoHPDwFWNGI6zUZ7XajLRYJuIQQQggRNvs90qW1diulpgKfA1ZgltZ6mVLqfuBnrfUc4Bql1CmAG9gBXNgEfW407XGDJNELIYQQIowalUmutZ4LzK1z7O6Ar28Hbm/MNZqF24OWoEsIIYQQYdQms8i1xyMJ9EIIIYQIqzYZeRjTi23yrQshhBCihbTNyMPtQVtkelEIIYQQ4dMmgy6ZXhRCCCFEuLXNyMPjRsv0ohBCCCHCqE1GHtrlBpleFEIIIUQYtc2gS6YXhRBCCBFmbTLy0B631OkSQgghRFi1yaALt0dKRgghhBAirNpk5GFML8pIlxBCCCHCp00GXXiMDa+FEEIIIcKlTUYe2u2RDa+FEEIIEVZtM+jyeGSkSwghhBBh1SYjD+12SSK9EEIIIcKqbUYebkmkF0IIIUR4tcmgS3s8UqdLCCGEEGHVJoMuPG6pSC+EEEKIsGqTkYeW4qhCCCGECLM2GXkYqxdlelEIIYQQ4dMmgy7cMr0ohBBCiPBqVOShlDpRKbVKKZWnlLptN+3OVEpppdTQxlyvqWiPTC8KIYQQIrz2O/JQSlmBGcAYoC9wjlKqb4h28cA1wI/7e62mJtOLQgghhAi3xgz3DAfytNZrtdY1wGxgfIh204BHgapGXKtpuVwyvSiEEEKIsLI14rUdgY0Bj/OBQwIbKKUGA5201h8rpW5q6ERKqcnAZIDMzExyc3Mb0a09S6+upsbrbfbriJZVXl4u9ziCyf2NfHKPI19bu8eNCbpUiGPafFIpC/AEcOGeTqS1fh54HmDo0KF65MiRjejWnlXNfoufli+nua8jWlZubq7c4wgm9zfyyT2OfG3tHjdmji0f6BTwOAvYHPA4HugP5Cql1gOHAnMOhGT66N698aaktHQ3hBBCCNGGNCboWgT0UEp1VUo5gInAHP+TWutSrXWa1rqL1roLsBA4RWv9c6N6LIQQQgjRCu130KW1dgNTgc+BFcA7WutlSqn7lVKnNFUHhRBCCCEiQWNyutBazwXm1jl2dwNtRzbmWkIIIYQQrZnUTRBCCCGECAMJuoQQQgghwkBprffcKoyUUgXAX2G4VDawIQzXES1H7nFkk/sb+eQeR75IuMedtdbpe9PwgAu6wkUpVbC3/0iidZJ7HNnk/kY+uceRr63d47Y8vVjS0h0QzU7ucWST+xv55B5HvjZ1j9ty0FXa0h0QzU7ucWST+xv55B5HvjZ1j9ty0PV8S3dANDu5x5FN7m/kk3sc+drUPW6zOV1CCCGEEOHUlke6hBBCCCHCJqKDLqVUoyruCyGEEEI0lYicXvQFWw8DduB/Wut5Ldwl0cSUUmcBWcD/aa0XtnR/RNNTSp0GpAJfa63XtnR/RNOTz3Fkk89wfRE30qWUUsDTQHvgJ+BWpdQUpVRUy/ZMNAWllFUpdTdwq+/QC0qp01uyT6JpKaXsSqmngb8DPYFZSqlRvudUi3ZONAn5HEc2+Qw3LBKn3+KBQcAJWusypVQhMBaYALzeoj0Tjaa19iilegE3aq1zlVLrgalKqRVa6xUt3D3RBLTWLqVUGnCe1nqlUupvwFNKqaFa66qW7p9oPPkcRzb5DDcs4ka6tNY7gfXAhb5D3wOLgcOUUu1aqFuiEZRSf1NKHa2USvId2gYkK6VsWusPgOXAWW39N6jWTCl1hlJqkFLKopRKAdxAlFLKqrV+FVgHXOdrG3Hft9oC+RxHNvkM751IfeP/BQYppdprrcuB34EajClH0QooQ3ul1HzgAuBcYIZSKg4oBAYAcb7m/wJOBySobkV897izUmoRcBXGVMS9wE6Mz+torbXH1/xO4HqlVLTW2tsiHRb7RSnVTimVi3yOI458hvddpAZd3wFF+Ea7tNa/AMMAZwv2Sewl329GGmOqeJPWehTGB7oEeAp4FhgBDFRKxWitVwErMKaQRSuglErw3eOOwCLfPb4TSAHuAu4HLvJ9Q7drrZcAucDJLdVnsW+UUh18U0zxQL58jiOLUirO9xnuAPwon+G9E5FBl9Z6C/AhMEYpNUEp1QWowhjuFAcopZRNKfUQ8JBS6migF+AB0Fq7gauBcRg/qN8EJvoe42v3Y9g7LfaZUmoK8I1Sqi/GyjX/CPQa4FGM0Q4NzAZuAwb6nrcDS8LbW7GvfNNLDwELgf4YObaAfI4jQcD36f8qpc4DxgMJvqflM7wHERl0AWit/w/4BzAG+Az4UGv9U8v2SjTEF2T9AiQDecA0wAUco5QaDuAbkr4P+KfW+hXgC+BvSqnFGItCfm+Jvou9E5CrE4/xS9Bk4H1gqFJqsNbarbXeALyK8Y36H8Bq4C6l1B9AGbAx/D0X++h8oDdwkNY6F/gEOEI+x62fUioZI1BOAp4ETsUIko9TSg2Sz/CeRWSdrkBKKTugfb9hiQOUUupIoIvW+jXf42cxvvlWAldrrYf4ki8zgGeA67XWG32LI2KkBkzr4LuHjwG/AscC72DU8Tlfa32CUsoKHI6R+3Oj1nqXUqob4JBVbQc+X2A9DZjnW5V4GEaC/NXA8Vrro+Rz3HoppToB72uth/sev4aRizcMo2LAKfIZ3r2IHeny01q7JOBqFX4B3vF9YMFYdZqttX4ZsCqlrvb9hpwFuLTWGwG01lvlG3XroJSy+O5hIbALY4TjPIzflAcqpSb5km5jgGit9S4ArfUa+WbdOvhyfNKA05VSV2MEVs9hTD8N8pUOAPkct0q++1WhlHpZKTUPI7i6HWNWYoRSaqJ8hncv4oMu0TporSu01tUBK11GAwW+ry8C+iilPgbewhglEa1MwIqlAcDnGNP+AzGmK54FzlFKveP7WvJ6Wq8ZwBCgn9Z6CHA3sAHjF6uBwByMey6f49ZpAvB/wGatdTeMwDoOI0n+NN9neCbyGQ4pEoujilbMN9KlgUyMb85g5AHcgZGUu05rvamFuieaxhKMwGoQUIzxW/J0rXWlUuoUjCmJNp330cqtBv4E/Dlcq5VSx2AsbnoaOAZYJZ/j1klrXaCUqsEYsUZr/ZVSagzwHvARcBzyGW6QjHSJA40XY4VLIcaU08cYy4+9Wuvv5Bt1RPDn9FyjtT4KYwTkGgCt9Rz5Zt26+SqO34aRFnCGUqoPxgpFlzZ8LZ/jVi8PyFJKHaqUysAIsC2+GQv5DO9GxCfSi9ZHKXUoxvD1/wEvaa3/08JdEk1IKeXUWlf6vlZAhtZ6Wwt3SzQxpdQRGIslTgZe0Fq/0MJdEk1EKRUNXIlR6iMDeFpr/XzL9qp1kKBLHHCUUlkYy84f11pXt3R/RPPwbf8ii1winK/YsWfPLUVro5TqilH41tXSfWktJOgSQgghhAgDyekSQgghhAgDCbqEEEIIIcJAgi4hhBBCiDCQoEsIIYQQIgwk6BJCCCGECAMJuoQQQgghwkCCLiGEEEKIMJCgSwghhBAiDP4fouDlyqU1orQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x1080 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# The history attribute from history object is a record of training loss values and metrics values at \n",
    "# successive epochs, as well as validation loss values and validation metrics values. It can be used to plot graphs\n",
    "# which let us understand how good the training was performed over the epochs.\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue>Testing Accuracy [Software 2.0]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeLabel(encodedLabel):\n",
    "    if encodedLabel == 0:\n",
    "        return \"Other\"\n",
    "    elif encodedLabel == 1:\n",
    "        return \"Fizz\"\n",
    "    elif encodedLabel == 2:\n",
    "        return \"Buzz\"\n",
    "    elif encodedLabel == 3:\n",
    "        return \"FizzBuzz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 32  Correct :68\n",
      "Testing Accuracy: 68.0\n"
     ]
    }
   ],
   "source": [
    "wrong   = 0\n",
    "right   = 0\n",
    "\n",
    "testData = pd.read_csv('testing.csv')\n",
    "\n",
    "processedTestData  = encodeData(testData['input'].values)\n",
    "processedTestLabel = encodeLabel(testData['label'].values)\n",
    "predictedTestLabel = []\n",
    "\n",
    "for i,j in zip(processedTestData,processedTestLabel):\n",
    "    y = model.predict(np.array(i).reshape(-1,10))\n",
    "    predictedTestLabel.append(decodeLabel(y.argmax()))\n",
    "    \n",
    "    if j.argmax() == y.argmax():\n",
    "        right = right + 1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "\n",
    "print(\"Errors: \" + str(wrong), \" Correct :\" + str(right))\n",
    "\n",
    "print(\"Testing Accuracy: \" + str(right/(right+wrong)*100))\n",
    "\n",
    "# Please input your UBID and personNumber \n",
    "testDataInput = testData['input'].tolist()\n",
    "testDataLabel = testData['label'].tolist()\n",
    "\n",
    "testDataInput.insert(0, \"UBID\")\n",
    "testDataLabel.insert(0, \"amlangup\")\n",
    "\n",
    "testDataInput.insert(1, \"personNumber\")\n",
    "testDataLabel.insert(1, \"50288686\")\n",
    "\n",
    "predictedTestLabel.insert(0, \"\")\n",
    "predictedTestLabel.insert(1, \"\")\n",
    "\n",
    "output = {}\n",
    "output[\"input\"] = testDataInput\n",
    "output[\"label\"] = testDataLabel\n",
    "\n",
    "output[\"predicted_label\"] = predictedTestLabel\n",
    "\n",
    "opdf = pd.DataFrame(output)\n",
    "opdf.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
