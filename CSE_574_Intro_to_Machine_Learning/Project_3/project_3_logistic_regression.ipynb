{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAccuracy(VAL_TEST_OUT_PRED,ValDataAct):\n",
    "    accuracy = 0.0\n",
    "    counter = 0\n",
    "    \n",
    "    VAL_TEST_OUT = VAL_TEST_OUT_PRED.argmax(axis=0).T\n",
    "#     print(VAL_TEST_OUT.shape)\n",
    "    \n",
    "    for i in range (0,len(VAL_TEST_OUT)):\n",
    "        if(int(VAL_TEST_OUT[i]) == ValDataAct[i]):\n",
    "            counter+=1\n",
    "    accuracy = (float((counter*100))/float(len(VAL_TEST_OUT)))\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sigmoid function return values from 0 to 1 as well as added the linearity\n",
    "# in the logistic regression model\n",
    "\n",
    "def softmax(z):\n",
    "    \n",
    "    numerator = np.exp (z)\n",
    "#     print(numerator.shape)\n",
    "    demominator =  np.exp(z).sum(axis=0)\n",
    "#     print(demominator.shape)\n",
    "    \n",
    "    return numerator/demominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_logistic_regression(_loop_range, no_of_classes, _TrainingTarget, _TrainingData, _ValDataAct, _ValData, _TestDataAct, _TestData):\n",
    "#     W = np.random.rand(_TrainingData.shape[0],no_of_classes)\n",
    "    W = np.ones([_TrainingData.shape[0], no_of_classes])\n",
    "    W_NOW = np.transpose(W)\n",
    "    learning_rate = 0.05\n",
    "    \n",
    "    L_Acc_Val   = []\n",
    "    L_Acc_TR    = []\n",
    "    L_Acc_Test  = []\n",
    "    \n",
    "    _TrainingTargetVector =  (np.arange(np.max(_TrainingTarget) + 1) == _TrainingTarget[:, None]).astype(float)\n",
    "    \n",
    "\n",
    "    for i in range(_loop_range):\n",
    "\n",
    "        z = np.dot(W_NOW, _TrainingData) # 10 x 50000\n",
    "        predicted_values = softmax(z) # 10 x 50000\n",
    "\n",
    "        diff = np.subtract(predicted_values.T, _TrainingTargetVector) #need to check np.substract\n",
    "        \n",
    "\n",
    "        Delta_W = np.dot(_TrainingData, diff)/_TrainingData.shape[1]\n",
    "\n",
    "        W_NOW = W_NOW - (learning_rate*Delta_W.T)\n",
    "\n",
    "        #-----------------TrainingData Accuracy---------------------#\n",
    "        TR_TEST_OUT   = softmax(np.dot(W_NOW, _TrainingData))\n",
    "        L_Acc_TR.append(GetAccuracy(TR_TEST_OUT, _TrainingTarget))\n",
    "\n",
    "        #-----------------ValidationData Accuracy---------------------#\n",
    "        VAL_TEST_OUT  = softmax(np.dot(W_NOW, _ValData))\n",
    "        L_Acc_Val.append(GetAccuracy(VAL_TEST_OUT, _ValDataAct))\n",
    "\n",
    "        #-----------------TestingData Accuracy---------------------#\n",
    "        TEST_OUT      = softmax(np.dot(W_NOW, _TestData))\n",
    "        L_Acc_Test.append(GetAccuracy(TEST_OUT, _TestDataAct))\n",
    "\n",
    "    print ('----------Softmax Regression Solution--------------------')\n",
    "# #     print (\"E_rms Training   = \" + str(np.around(min(L_Erms_TR),5)))\n",
    "# #     print (\"E_rms Validation = \" + str(np.around(min(L_Erms_Val),5)))\n",
    "# #     print (\"E_rms Testing    = \" + str(np.around(min(L_Erms_Test),5)))\n",
    "    print (\"Accuracy Training   = \" + str(np.around(max(L_Acc_TR),5)))\n",
    "    print (\"Accuracy Validation = \" + str(np.around(max(L_Acc_Val),5)))\n",
    "    print (\"Accuracy Testing    = \" + str(np.around(max(L_Acc_Test),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "== MNIST Dataset ==\n",
      "=========================\n",
      "TrainingData : (50000, 784)\n",
      "TrainingTarget : (50000,)\n",
      "ValidationData : (10000, 784)\n",
      "ValidationTarget : (10000,)\n",
      "TestingData : (10000, 784)\n",
      "TestingTarget : (10000,)\n"
     ]
    }
   ],
   "source": [
    "filename = 'mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "__training_data, __validation_data, __test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "TrainingData = __training_data[0]\n",
    "TrainingTarget = __training_data[1]\n",
    "\n",
    "ValidationData = __validation_data[0]\n",
    "ValidationTarget = __validation_data[1]\n",
    "\n",
    "TestingData = __test_data[0]\n",
    "TestingTarget = __test_data[1]\n",
    "\n",
    "\n",
    "print(\"=========================\")\n",
    "print(\"== MNIST Dataset ==\")\n",
    "print(\"=========================\")\n",
    "print(\"TrainingData : \" + str(TrainingData.shape))\n",
    "print(\"TrainingTarget : \" + str(TrainingTarget.shape))\n",
    "print(\"ValidationData : \" + str(ValidationData.shape))\n",
    "print(\"ValidationTarget : \" + str(ValidationTarget.shape))\n",
    "print(\"TestingData : \" + str(TestingData.shape))\n",
    "print(\"TestingTarget : \" + str(TestingTarget.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Softmax Regression Solution--------------------\n",
      "Accuracy Training   = 87.962\n",
      "Accuracy Validation = 89.28\n",
      "Accuracy Testing    = 89.01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Accuracy Training   = 83.802\n",
    "# Accuracy Validation = 85.65\n",
    "# Accuracy Testing    = 85.07\n",
    "\n",
    "execute_logistic_regression(500, 10, TrainingTarget, np.transpose(TrainingData), ValidationTarget, np.transpose(ValidationData), TestingTarget, np.transpose(TestingData))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
